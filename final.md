#Orange Street

##Contents

-	[Server](#server)
	- [Overview](#server_overview)
	- [API Spec](#server_spec)<style>
	.todo{ color:red }
</style>

#Orange Street

## <a name="contents"></a>Contents
* [Client Interaction](#client-interaction)
* [Sensor](#sensor)
* [Hub](#hub)
* [Server](#server)
* [Visualisation](#visualisation)
	- Clock
	- Website

<p class="todo">REFERENCE MINUTES THROUGHOUT</p>

### <a name="client-interaction"></a>Client Interaction - [cont.](#contents)

####Aims
Our client interaction brought to light these main issues to consider in our project. 

**They do not want to think about the noise:**   
The user talked a lot about having to worry about remembering specific times they were caused inconvenience by the noise outside and then provide evidence of those inconveniences. Therefore the project needs to store data and visualise it in a way that could be presented as evidence of their inconvenience. Also from this we can gather that the user does not really want any real interaction with the device as it would mean them thinking about the noise. The point of the device should be that it runs autonomously (to create peace of mind for the user) collecting data for the user to visualise and use as evidence at their discretion.

**Solution needs little to no interaction, running in the background:**  
The user expects the device to have a maintenance level of a device akin to a router. They expect some general maintenance but they do not want to be too involved with it, ie worrying about battery life all the time.

**A long term solution:**  
Along the lines of the other two themes before, the user wanted the system to be robust and sustainable. During the meeting the user said that this year so far wasn't as bad as last and didn't want to complain this year if it was to change next and get worse. Therefore the end result of the project should be something that the user can maintain on their own.

**People should be aware of their own noise levels:**  
The client talked a lot about wanting the people in the street to know how noisy they are being. Points being brought up suggesting signs that had the decibel reading on them so that people can visualise the noise like a road sign that turns on when you are going too fast. Although, as we wouldn't be able to enforce the sound level it could possibly encouraging even challenging people in the street to be loud to try and make the sign go off.

<p class="todo">DO WE WANT TO INCLUDE A LIST OF GOALS TO ACHIEVE?</p>

#####Meeting ONE

We had to speak with the clients before we started to formulate a solution. We had to know what they wanted, so that we could make a solution that best filled their needs. To prepare for this we researched proper interviewing techniques by reading: *“Interviewing users: How to Uncover Compelling Insights (Steve Portigal, 2013)”*.  

The main lesson we took from the Portigal book was that we needed to let the client talk. We did not want to steer their answers in any direction. We organised roles amongst ourselves, with a leader asking questions and the rest taking notes. If the note takers had any questions we made sure they were asked at the end of the question so that the client did not lose track.

Our intended outcome for this meeting was to have an incite into our clients perception of the problem they are having, whereby we can devise a method in which to solve said problem. We had an idea of the client's problem before we went into the meeting, based on what we were told in the project brief. Therefore, in preparation we made a list of questions that we felt we needed answered to gain a better understanding.<span class="todo"> REFERENCE ORIGINAL QUESTION SHEET</span>. We then trimmed down our question list intending to allow our client to talk as freely as possible. <span class="todo">REFERENCE SECOND QUESTION SHEET</span> 

<p class="todo">INCLUDE RECORDING</p>

#####Meeting TWO

We spoke to another client that was meant to be present at the original meeting but was unable to make it. They are a landlord of Orange Street tenants living next to a popular club called ‘The Ballroom’. In this meeting we followed the same layout as set in the first meeting, making one person take the lead and the others taking notes, we also followed the same structure of questions.

<p class="todo">INCLUDE SEB RECORDING AND QUOTES</p>

<p class="todo">DO WE INCLUDE PHOTO OF THE RESIDENTS HOUSES ON GOOGLE MAPS?</p>

<img src="images/OrangeStreet_dist.jpg">

#####Vendor Communication

We also tried to speak to other people, pubs and bars in the area to try and gain a greater understanding of the issues that were present in the street and what people were doing to try and solve them.  

A message was sent out to three of the main purported culprits of noise on the street: The Maori Bar, The Seven Stars and Ballroom. The message said: 
>Hello, three other Kent students and I have undertaken a project whereby we are looking into sound around Orange Street. We were wondering how you deal with sound i.e. keeping it contained or if there is a way you try and stop it from spilling into the street. 
>
>Thank you  

The Maori Bar responded with: 
>Hello Matthew thanks for your message, our building is soundproofed in the walls and we make sure the door is kept shut so to trap and muffle as much of the sound as possible. We also monitor our sound levels regularly with a decibel reader.  
>
>Orange Street is a very busy street especially on a Friday and Saturday night and attracts a lot of foot traffic. Of course telling people to keep quiet is near enough impossible as they pass between venues. We don't have live music or DJ's but The Seven Stars and The Ballroom do. We are a small venue with only about 40 people in at one time on average. We would be interested in your findings in your project. Keep us posted.
>
>The Maori Bar team.

This shows that there is an awareness that the street is loud but it can be hard to police outside of the venue. It was also interesting that they mentioned keeping the door closed as the door being opened and closed with the occasional noise leaking out was cited as a large source of annoyance by the clients.  

The Seven Stars allowed us to come and talk to a manager. They said they maintain the noise by trying to keep the doors and windows shut as much as possible and they have a set of double doors so that the sound is muffled when people are coming and going. They also said that they had decibel readers that they checked to make sure that the inside noise was in accordance with the set sound levels. They know that people are noisy when they leave the establishment but he said there was nothing that could be done about that as it is a problem that comes with the clientele.  

Unfortunately The Ballroom did not get back to us.  

####Noise Law

We looked into noise laws. We did this so that we could understand, firstly, if the way we were collecting data was legal and to see if the data we provide to the client would be of any use to them.  

The main thing we found were that there are noise laws in place but they only apply to residential premises according to the ***Noise Act 1996 - Non commercial only. This law only relates to noise that is coming from a residential premises such as neighbours, it does not affect licensed premises.***  

We also found that police can close a premises based on the ***161 Closure orders for identified premises - (1) A senior police officer may make a closure order in relation to any relevant premises if he reasonably believes that: (a) there is, or is likely imminently to be, disorder on, or in the vicinity of and related to, the premises and their closure is necessary in the interests of public safety, or  (b) a public nuisance is being caused by noise coming from the premises and the closure of the premises is necessary to prevent that nuisance.***

The following email is from the Environmental Health department of Canterbury County Council. This is the department that handles any noise complaints regarding both residential and commercial premises. We enquired to them about noise laws.

>Dom  
>
>In response to your enquiry each premises is based on its own merits, hours of operation and location so we don’t have any set levels for Canterbury District. Two documents which may be of use to you are the Control of Noise at Work  
>
>Regulations 2005 which deals with operators requirements for their staff and BS:4142
>  
>The Method for rating and assessing industrial and commercial sound - this looks at how and where to measure sound in mixed residential and business communities. I hope this helps  
>
>Tricia  

The first document mentioned is in relation to the noise levels that are acceptable for their staff and people working on the premises rather than those sounds that are heard from outside the premises so this is of less of a concern to us. Although, it can still be found [here](http://www.legislation.gov.uk/uksi/2005/1643/contents/made). 

The other document mentioned is owned by the British Standards Institute and incurs a cost if we wish to use it. A brief description of the document said the standard is used by the council and describes methods for rating and assessing:

* Helps assess sound levels at proposed new residential premises 
* Enables the investigation of complaints by determining sound levels 
* Reduces the likelihood of financial penalties 
* Supports current UK planning guidance and Environment Agency guidance sound of industrial or commercial nature.

We also looked into licensing reviews and found that anyone with evidence suggesting there is a problem can request a licence review from the council as long as it comes under one of the following:

* Crime and/or disorder 
* Public nuisance 
* Public Safety 
* Prevention of harm to children

In this case, the noise generated from the pubs and or clubs would be classed as a nuisance. 

When making a review request evidence needs to be provided to support the case that you are making. This evidence can be in multiple forms such as:

* a diary or record of events or incidents 
* photos or video evidence
* sound recordings
* a record of complaints made to the responsible authorities about the premise

<style>
	.todo{ color:red }
</style>

#Orange Street

###Initial Ideas

At this point we had spoken to enough individuals to have a good place to start working on a potential prototype. We needed to plan how we would efficiently tackle the problem ahead of us. We first had to make a list of requirements based on our aims <span class="todo">link to aims</span>

* We needed multiple sensors 
* We needed the sensors to be self-sustainable for a long period of time.
* We needed the sensors to be out of the way but effective (Out of mind, not reminders to the clients), so no wires running everywhere.
* We needed a way to visualise all the data from these sensors into a form that was easily understandable
* We needed control over the network, and ideally a way to configure it.
* We needed cases that could ensure the endurance of the devices in different conditions.

Translating this to a solution we can work with:

* We were looking at some form of wireless solution, we could not afford to have wires running everywhere when the clients wanted the solution ‘out of mind’. With wireless comes many different solutions, we investigated the best options available to us.
* We know we had to sample sound - we did not know how often to sample however so we went to investigate that also.
* A microphone is needed with any other electronic circuitry that comes with it. 
* A way to display this data, we decided to investigate ways to do such a thing.
* We had to ensure some form of data backup also.
* Some of the requested locations for these sensors were completely unreachable by permanent power supplies, which led us to the investigation of long term battery solutions.
* We needed a case that could survive harsh weather and conditions, one that would be of a suitable Ingress Protection Rating.
* 

#### Minutes

Below are the minutes taken for every meeting that we, personally had between us as a group. They are a rough summary of what decisions we chose to take and how we followed up on them in the weeks after.

Weekly Minutes (September 27th - 25th March 2016)

<b> 27/9/2015 </b>
* Project begins.
* Meeting with supervisor, arranging a meeting with clients.
* Research into general hardware understanding.
* Research into general electronics understanding.

<b>3/10/2015</b>
* Research into sensor amplifier, this is required for our sensor to accurately measure noise.
* Reading Portigal Book, this is required to interview our clients in the best format possible.

<b>10/10/2015</b>
* Working on sensor amplifier, have to calculate accurate values for use.
* Concluding on client meetings, taking notes from the important moments in the meeting.
* Sensors are required as expected, multiple of them will be used to gather data on sound.
* Starting to learn 3D print, will need case designs for components in the project. 
* Start researching potential solutions in system architecture to the problem.

<b>18/10/2015</b>
* A Basic sensor has been created using the amplifier circuit, can now use this act as a sensor temporarily.
* Program needs to be written to sample sound from the current sensor.
* Researching sound waves and understanding of sampling, need a better technical understanding of sampling sound waves and sound in general.
* Researching into potential networking solutions, we need a way of transferring this data from the sensor to the website.
* Researching into hardware boards, Arduinos, MBEDs, any particular board that could be used to handle the sensors requirements.

<b>25/10/2015</b>
* Using the written program for sampling data from the sensor, taking this sampled data and working out how to gather the values we need in order to demonstrate a sound level.
* Using the FRDM K64F as a guide - 3D printing a case for this board.
* Decision to use the XBee as our networking module, offers great customisation and low power cost.

<b>2/11/2015</b>
* Started using Github to handle different elements of the project code base.
* Started getting XBees S2 talking to each other, sending dummy data between two modules.
* Began discussing how often we wish to sample data, how many samples to take and the accuracy of our data. 
* Researching into very low boards to act in place of the sensor.

<b>9/11/2015</b>
* Discussed the potential of using the MBED as a Hub as we are familiar with it.
* Looking into XBees and their configurability, discussing whether encryption or the alike is necessary.
* Researching into converting sound values into decibel levels.

<b>16/11/2015</b>
* Still working with XBees, looking into setting up multiple on a network with a mesh topology as opposed to point to point.
* Discussed the battery concerns, clients ideally want a rechargeable set of batteries. Looking into battery solutions.
* Sketching visualisation ideas.  
* Decided on using the Rocket scream board for the sensor, but going to use Arduino Uno for the time being.

<b>23/11/2015</b>
* Attempting to get an Arduino board communicating to an XBee, wiring the module up ourselves as it’s likely we’ll use an Arduino board.
* After showing 5 sketches produced from each other, we concepted some form of clock that displays noise levels.
* Researching into different solutions for a Hub, potentially FRDM K64F. 

<b>30/11/2015</b>
* Mapping locations for sensors, where are we likely place them - what sort of problems does this raise?
* Concepting case designs for the Arduino Uno.
* Researching components for a clock like device.

<b>7/12/2015</b>
* Going to use AT mode for XBee for Hub and sensor, simpler to set up and then focus on API mode of XBee. 
Research into XBee settings, API mode.
* Clock components decided, visualising components and how to use them. Going to use 24 LEDS on the clock for 24 hours.

<b>14/12/2015</b>
* Clock testing and programming, deciding what colours to use, frequency of them.
* Case design tested, researching into weatherproofing the case.
* Raspberry Pi decided for the Hub.
* Prototype of sensor is going to be placed in client's house over Christmas break.
* Prototype will use local SD card instead of network due to power restrictions with the board being used.
* Decided to sample once a minute and average to use as a representation of that minute.

<b>21/12/2015</b>
* Final meeting before Christmas break, sensor has been placed in Client's house on Orange Street. 
* Rocket scream board arrived, testing with rechargeable batteries is next step
* AT Networking finalised.

<b>20/1/2016</b>
* First meeting since end of Christmas break, sensor has been collected and data returned for evaluation.
* From result it is hard to determine accuracy of noise, sampling needs to be more accurate
* Increasing sampling rate to 3 times a minute.
* Work commencing on creating the Hub, and arranging networked solutions.

<b>27/1/2016</b>
* Clock case design prototyping started.
* Raspberry Pi Model B+ acquired, programming beginning in Python with Jessie Lite as the Operating System.
* Investigating how to visualise data on the website.
* Order requested for components to build more sensors.
* Sampling rate is now much more accurate.

<b>3/2/2016</b>
* Programming the RocketScream, research into power usage with the board (disabling/enabling features).
* Researching sleep mode configuration on XBee modules.
* Case design for Hub started.
* Hub to backup data if network fails.

<b>10/2/2016</b>
* Finished hub, need to test with all components under different circumstances.
* Sensor finished, accuracy lacking - looking into solutions.
* Case design for clock on-going.
* Colour sensitive users for clock.

<b>17/2/2016</b>
* Light intensity as opposed to different colours for users of colour blind nature.
* New sensor prototype almost finished, solution to accuracy is a 16bit ADC.
* New case design for sensor, directional microphone.

<b>24/2/2016</b>
* Testing entire system in the ‘wild’, sensor outside, clock on the side and Hub routing traffic.
* If goes to plan, place in Client's house during this week.
* Case finished for sensor, case for clock next.
* Current networking is AT mode.
* Live visualization being worked on.

<b>31/2/2016</b>
* Designing initial poster for project fair.
* Programming API mode for network.
* Design for clock case finished. Need a way to diffuse light.

<b>7/3/2016</b>
* Visualisation of data on website finished.
* Planning on testing website with users.
* Hub API mode finished.

<b>14/3/2016</b>
* Sensor API mode finished.
* Building of a dummy sensor working with API mode to demonstrate capabilities.
* Visualisation of data finished.
* Clock case finished.
* Plans for poster to test the clock and demonstrate our visualisation.

<b>18/3/2016</b>
* Use clock to demonstrate noise levels and visualisation.
* Laptops and tablets for visualising website.
* Dummy sensor to demonstrate range and error correction.
* Hand out flyers on the project.

<b>25/3/2016</b>
* Formating corpus and technical report for project.







<a name="sensor"></a>
## Sensor
[Back to contents](#contents)

###Description

The sensor samples sound every minute. The microphone in the sensor starts collecting sound data every minute it produces data that represents a sine wave. The data is then put through an ADC (Analogue to Digital Converter) that amplifies the analogue data (sine wave) and removes any voltage noise. It is then analysed by the sensor, taking fifty points along the wave, in this minute time period, to find the amplitude of the wave (how loud the sound is).  

The final sensor is comprised of multiple parts, [Microphone](#mic), [ADC](#adc), [Board](#sensor_board), [Clock](#sensor_clock), [Battery](#battery), [XBee](#sensor_xbee), [Case](#sensor_case):

*<a name="mic"></a>Microphone*

The microphone is an electret microphone with a built in MAX4466 amplifier. This amplifier has adjustable gain which is used to boost the raw signal which is passed from the microphone. In the final version of this sensor we decided that this amp was not enough and that we needed to add another amplifier to the circuit to improve our recordings

*<a name="adc"></a>ADC*

The circuit contains an external ADC in the form of an ADS1115. This was chosen for three main reasons. The 16 bit resolution allowed us to work with a larger range of values which we would not have got using the onboard ADC of the board. It also contained a programmable amplifier which we could use to firther amplify the signal coming from the mic. The other reason was that it allowed comparison between 2 analog inputs. 

We found that we were getting a lot of noise coming from the mic which we discovered was caused by the voltage from the board. To counter this voltage coming out of the board with the data coming back from the microphone on the ADC. This allowed us to get the difference and remove any electrical noise from the mic.

*<a name="sensor_board"></a>Board*

The final board we chose was the Rocket Scream Mini Ultra 8 MHz Plus. The reasons this was chosen are below:

 - Battery connector
 - Built in charging circuit
 - Low power voltage regulator
 - Thermal regulation for the battery
 - Relatively cheap
 - Battery voltage monitor

 We slightly modified this board by removing the power indicators to decrease the current draw. 
 
 The board is in a near constant sleep state and only wakes up on a pin interrupt to take readings and send the data back to the sensor. This ensures a battery life of around one and a half months. The interrupt is triggered from the clock.
 
*<a name="sensor_clock"></a>Clock*

The sensor needs a clock to be able to accurately record the time readings are taken. The clock on the sensor also has a further purpose of waking the sensor up at certain times. For this we used a DS3231 which kept time incredibly accurately and also provided an 'alarm' function which could pull a pin high or low based on a set of programmable rules. We set this rule for every minute which means it pulled the pin low every minute. We then had the board sleep listen for an interrupt on that point. 

*<a name="battery"></a>Battery*

We used a 1500mah lithium polymer battery for the sensor as it provided a good balance betwwen power and size. In previous iterations we used a 2000mah which provided a longer battery life however we couldn't source another one in time for the final deployment.

*<a name="sensor_case"></a>Case*
The Case was designed in a way that was intended to aim our microphone at the noisy street and protect the electronics from the elements. It was 3D printed at a high fidelity (high infill of plastic) with a thickness of 3mm as not to allow water in through the printed plastic. It was then sanded and sprayed with a high fill primer to fill any pores left int the plastic left from the printing process. As the case had to be closed around the electronics of the sensor a seam was built in that was filled with a neoprene strip as to stop any water from getting through said seam.

A final version of the code can be found [here](sensor/micTest)

### Previous Work

####  Iteration 1
Based on our [client interaction](#client_interaction) we decided that we had to make a device that measured the volume of the sound in Orange Street, collecting the data and sending it back to a server so that it is stored and can be accessed by the client to use.

Building on the initial ideas we had and also looking back to the client interaction section we decided on the following requirements for the sensor:

- Long battery life
- Reliability
- Record the volume of sound in the surrounding area
- Transmit that data back to a hub


We looked into how sound works and discovered that we would need to capture a sound wave and subtract the minimum from the maximum to get an overall amplitude of the wave. We could then use this data to calculate other things such as decibels but initialy recording the sound wave was crucial. We planned to use a microphone and microcontroller board to select some points on a sound wave and perform the calculation.

*The Microphone Amplifying Circuit*

After talking to the client the important part of the diagram would remain constant throughout the process, which was the amplifying circuit. For a microphone to be able to produce a voltage signal able to be processed for data it must be amplified, we know for certain we are measuring noise levels in this project and so this is a crucial step.

**image 1**

The basic place to start is a non-inverting amplifying circuit, used with any op-amp it effectively calculates the gain based on two resistor values going into an inverting and non-inverting input. (Gain= 1+ (R2/R1)

The OP-AMP IC we’ve been using is the MCP 6002, the datasheet can be found here. (http://ww1.microchip.com/downloads/en/DeviceDoc/21733j.pdf)

**Image 2**

It’s an IC with two OP-AMPS and isn’t designed for anything too complicated, for the time being it’s perfect to get a basic amplifying circuit built.

Looking at the microphone itself, it’s a very basic condenser microphone that a lot of products (Mostly cheap ones) use in manufacturing. For the time being it’s ideal, however later on we might consider modifying the microphone as this can have great benefits without changing much of the circuit let alone power requirements (Direction, pop filters, windscreens etc).

Most microphones that feed into a amplifying circuit are biased by a resistor value and then thrown down to ground (0v), one could use a potential to guarantee the voltage level applied to a microphone also.

So far, we’re looking at a circuit like this.

**image 3**
Other solutions that can be found on the web include using a different IC (As opposed to the MCP 6002) and modifying the circuit above. 

List of other IC’s and amplifiers we looked into.

<table>
	<tr>
		<td>IC Chip</td>
		<td>Link</td>
	</tr>
	<tr>
		<td>NE5535, TL071, OPA 371</td>
		<td>http://www.zen22142.zen.co.uk/Circuits/Audio/lf071_mic.htm</td>
	</tr>
	<tr>
		<td>LM386</td>
		<td>http://www.learningaboutelectronics.com/Articles/Microphone-amplifier-circuit.php</td>
	</tr>
	<tr>
		<td>MCP 6002</td>
		<td>http://www.aiscube.com/main/downloads/RVHS/RV_lesson_301112.pdf</td>
	</tr>
</table>

Although some may seem more suitable than others, as of right now we’ve focused on having a working circuit. In the long term, once we are happy with this solution we will most likely have a pre-built circuit instead of designing the non-inverting amplifier ourselves and choosing which OP-AMP to use. 


*Processing the Data*

The next step was to process the data, there were many ways to handle this from Microcontrollers to all-in-one IOT boards. We researched the following methods of taking data from a microphone to then process.

<table>
	<tr>
		<td> Potential Idea </td>
		<td> Description </td>
		<td> Pros </td>
		<td> Cons </td>
	</tr>
	<tr>
		<td> IOT Microcontroller Boards </td>
		<td> A whole board designed to handle multiple functions, such as Wifi/3G/Bluetooth with sensors, a built in microcontroller and more.</td>
		<td> 
			<ul>
				<li>A lot of built in features to reduce complexity of building communications between chips.</li>
				<li>Widely available, often designed for IOT solutions.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Often a lot of unneeded accessories (such as temperature sensor)</li>
				<li>Increase the physical size of the device based on unneeded extras</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td> Microcontrollers  </td>
		<td>Singular processors, adjustable clock speeds, do not have the functionality of some of the features present on a microcontroller.</td>
		<td> 
			<ul>
				<li>A lot more freedom in deciding how to run the device.</li>
				<li>Removes any unnecessary features.</li>
				<li>Allows to scale down size of the sensor considerably.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Longer to produce and build together as can take more components.</li>
				<li>More complicated, requires further electronics knowledge.</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td> Barebones  </td>
		<td>Using only modules to handle the work, avoiding any form of major processing.</td>
		<td> 
			<ul>
				<li>Potentially reduce power usage.</li>
				<li>Removes any unnecessary features of a Microcontroller.</li>
				<li>Allows to scale down size of the sensor considerably.</li>
				<li>A lot more freedom in deciding how to run the device.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Longer to produce and build together as can take more components.</li>
				<li>Much more complicated, requires further electronics knowledge.</li>
				<li>Difficult to prototype a sensor without a Microcontroller.</li>
			</ul>
		</td>
	</tr>
</table>

For the purpose of a prototype we decided to work with a IOT Microcontroller, we need to investigate common IOT Microcontroller modules, ones that are ideal for our implementation of this IOT device. 

*Arduino Microcontroller Boards*

Arguably one of the most popular development boards commercially available, has a full function IDE written in C++. Multiple different boards designed for different purposes, all having sharing the basic functionality (such as analog inputs) while offering unique differences. They allow for shields to be placed into them which add even further adaptability, allowing for 3rd party hardware to be interfaced easily into the device. This functionality can be as simple as an SD card reader, a WiFi chip or even an external clock. 

Which one suited our best needs? What did we need in a device?
<ul>
	<li>Low power</li>
	<li>Within reasonable price range</li> 
	<li>Relatively small</li>
	<li>Ability to interface with certain components (Backup mediums if network is down, an external clock to keep track of time, an ADC input and form of digital output to transfer data to a wireless module).</li>
</ul>

This narrowed down our choices to the following Arduino devices.
<ul>
	<li>Arduino Nano</li>
	<li>Arduino Pro Mini</li>
	<li>Arduino Macro</li>
	<li>Arduino Uno</li>
</ul>

**Image 4**

*Arduino Nano*

**Image 5**

(https://www.arduino.cc/en/uploads/Main/ArduinoNanoManual23.pdf)

“The ATmega168 has 16 KB of flash memory for storing code (of which 2 KB is used for the bootloader); the ATmega328has 32 KB, (also with 2 KB used for the bootloader). The ATmega168 has 1 KB of SRAM and 512 bytes of EEPROM (which can be read and written with the EEPROM library); the ATmega328 has 2 KB of SRAM and 1 KB of EEPROM” (Arduino.cc, n.d.)
<ul>
	<li>Serial: 0 (RX) and 1 (TX). Used to receive (RX) and transmit (TX) TTL serial data. These pins are connected to the corresponding pins of the FTDI USB-to-TTL Serial chip.</li>
	<li>External Interrupts: 2 and 3. These pins can be configured to trigger an interrupt on a low value, a rising or falling edge, or a change in value. See the attachInterrupt() function for details.</li>
	<li>PWM: 3, 5, 6, 9, 10, and 11. Provide 8-bit PWM output with the analogWrite() function.</li>
	<li>SPI: 10 (SS), 11 (MOSI), 12 (MISO), 13 (SCK). These pins support SPI communication, which, although provided by the underlying hardware, is not currently included in the Arduino language.</li>
	<li>LED: 13. There is a built-in LED connected to digital pin 13. When the pin is HIGH value, the LED is on, when the pin is LOW, it's off.</li>
</ul>

The nano is a small device that has all the functionality that we ideally would want, it has connections over Serial, I2C and SPI (Although supported by hardware, not supported by Arduino libraries).

It requires a minimum of 5v operating power, anything below and functionality is lost and we run the risk of disabling features.

It can run the ATMega 168 or 328, we would ideally use the 328 as it offers much more space (EEPROM, SRAM and Flash memory) and is a later iteration over the 168. The dimensions of the device are 0.73” x 1.70”.

*Arduino Pro mini*

**Image 6**

(http://www.atmel.com/images/Atmel-8271-8-bit-AVR-Microcontroller-ATmega48A-48PA-88A-88PA-168A-168PA-328-328P_datasheet_Complete.pdf)

Essentially the Pro Mini is identical to the Arduino Nano except for the added ability of lower bootloader space and the ability to run at 3.3v over 5v and other small differences that do not add much to our required project.

“There are two version of the Pro Mini. One runs at 3.3V and 8 MHz, the other at 5V and 16 MHz... The ATmega328 has 32 kB of flash memory for storing code (of which 0.5kB is used for the bootloader). It has 2 kB of SRAM and 1kBs of EEPROM.“ (Arduino.cc, n.d.)

*Arduino Uno*

**IMAGE 8**

The Uno sticks out in this comparison due to its size difference against the previous 3, which begs the question - why then? Simply put, the Arduino Uno is a very friendly board to use, and for prototyping would be ideal as we would not need to worry about many problems that we could face when going straight in with one of the other solutions. It also shares a lot of common ground with the other 3, except for its size.

It runs the ATmega328P, which has slight differences to the ATmega328 (Slight power reduction). Only uses 0.5KB of the Flash memory for the bootloader, runs at 16MHz and needs at least 6v operating voltage which like the macro can cause instability if run at this low a voltage. 

The biggest benefit for us, was that the Uno would offer easy adaptability and help quickly work with a prototype while we decide which microcontrollers to use, their frequency, and work on breadboards instead of soldering straight away. 

*MBED FRDM-K64F*

**IMAGE 9**

Another popular developer of IOT boards, using ARM based architecture instead of AVRs. The argument between these two processor architecture is often put down to ARM is powerful, and AVR is not so much. There are variants on the processors but otherwise they tend to stick to those groups. MBEDs have an online compiler and IDE, which works in a similar fashion to Arduinos but is effectively always online which comes with its own problems such as requiring internet access. 

The most ideal MBED board we found was the FRDM-K64F which is regarded as the flagship board, it’s perfectly ideal for prototyping - but in the long run most likely would be too much of a power killer. It’s compatible with most Arduino shields too. In the long run however, the FRDM-K64F while having many features, especially when combined with the MBED application shield - is too much functionality for what we need bundled down, even in a prototype we do not need such complexity. 

Even with all its functionality switched off the device consumes more amps than one of the arduino boards. However we decided that this board would be ideal if used for our hub, as during that period power will not be a concern. 


*Conclusion*

We did experiment with the FRDM K64F and Arduino Uno in measuring sound. Our experiments with these boards consisted of testing the circuit we had made for measuring sound levels. Using Java we have written a program that talks on serial to the boards which prints out values as fast as it can from the AMP. With these values our program samples 50 times in a second, long enough to gauge a sound wave. Using the minimum and maximum samples we calculate the range and pass all these values along to a file to be saved.

```java 
	// Read values from sensor

        /* Calculate the range of 50 samples */
        int i = 50;
        int max = data[0];
        int min = max;
        int range;
        int j;

        while (i-- > 1) {
            j = data[i];
            if (j > max) {
                max = j;
            }
            if (j < min) {
                min = j;
            }
        }
        
        range = max - min;
        
        // Save to file 
        // ...
```
 
 <p align="center">Code snippet from Java Serial Receiver </p>  
 

Logging this data shows the structure and accuracy behind our sensor. Using this data we can increase the sensitivity of our sensor or increase the sample rate.

A version of this code can be found [here](sensor/InitialNoiseLevel/)

####Christmas Deployment
Over the christmas period we deployed a version of our sensor that wrote data to an SD card. This was designed to go into one of the resident's houses and record data for a short period of time. We used an arduino uno with a shield that contained an SD card reader. 

We needed a way to power the whole board for the time that we would be away over the christmas break. A standard Uno with no low power code drew a current ~42.5mA. A standard AA battery would provide around 1500mAh.

 $$ 1500mAh/42.5mA=35.29 hours $$

The christmas break lasts 4 weeks so 35.29 hours was going to be nowhere near enough and we would only get data for the first day and a half. 

We discussed several other options that included rechargeable batteries, multiple AA batteries and plugging it into the wall. Multiple AA batteries was discounted because it would be very expensive and we’d need a lot of them. It would also increase the size drastically.

Rechargeable batteries looked like a viable option as they came in much higher capacities and would allow the client to recharge them if they did happen to run out when we were away. We did some initial calculations with the 10000mAh battery that we had to hand:

$$ 10000mAh/42.5mA=232.94 hours $$

$$ 232.94/24= 9.7 days $$

While this was getting better it was still slightly too short for what we needed it for. At this point bigger batteries became more expensive and the University wouldn’t be able to order them in time. This meant we had to make the arduino use less power when it was running. To do this we used low power libraries and turned off everything that we weren’t using. After doing this we managed to get the power usage down to ~22mA. 

$$ 10000mAh22mA= 454.54 hours  $$

$$ 454.54/24= 18.9 days $$

This was a more reasonable amount of time and would give us a good amount of data that we could use in the future. The battery pack we were using could also be easily charged using  a micro usb cable (the same kind that is used to charge phones) which meant we could ask the client to charge it if it did run out of power.

A version of this code can be found [here](sensor/SDCardPrototype/)


####Iteration 2 
#####Issues with previous iteration
There were several issues that arose with the code and hardware we created during the christmas testing We discovered that the mic signal was not being amplified enough which led to a lot of readings being the same even though the noise levels were vastly different. The previous iteration also recorded data directly to an SD card for us to look at later. This is an issue as we needed some way of transmitting data back to the board.

#####Result of iteration
We struggled with amplifying the sound as there we were also amplifiying a lot of electrical noise. We pushed this back to a future iteration as we were getting held up by it.

We added an Xbee to the board so that we could transmit data back to the hub which worked without any issues.

####Iteration 3
#####Issues with previous iteration
We noticed some issues with the previous iteration cutting off data after sending large amounts. This is an issue that needs fixing. We are also currently getting the time for timestamping the data from the internal clock. This is proving to be an issue as the time is not accurate. Over longer periods the time on the board will drift further and further away from the actual time. Also, if the sensor runs out of battery the time will be lost.

#####Result of iteration
The loss of data when transmitting was due to the Xbee buffers being overloaded as we sent the data too quickly. To solve this we added small delays in between sending the data. This fixed the issue and the data appears to be being sent without any issues. We also added a clock to the circuit. This has a backup battery so it can still keep time in the event of the sensor losing power. This clock is also accurate and can keep to +/-1 second over a year. 

####Iteration 4
The aim of this iteration was to fix the issue in iteration 2 where we discovered that mic readings were not being amplified enough to pick up changes in the noise level.

#####Issues with previous iteration
No issues

#####Result of iteration
We added a 16-bit adc which gives us a higher resolution and also allows us to remove electical noise using a comparison of two pins. To do this we used a potential divider to half the 3.3v signal that the board was running off and put in pin 1 of the ADC, we then put the mic output into pin 2. Comparing these 2 pins gave us a wave that was much less noisy, as the power voltages were effectively cancelling each other out. This also means that we could produce a wave which had an maximum amplitude of that was the same as our resolution whereas previously there was a noise baseline which, when amplified, also increased leading to us not being able to amplify it too much. These changes allow us to see the noise level change in much more detail and also pick up smaller changes.

#####Iteration 5
For this iteration we wanted to add a rechargable battery to the circuit so the client could charge it in their house without having to buy standard alkaline batteries. We also wanted to think about low power.

#####Issues with previous iteration
None

#####Result of iteration
We changed our board from an arduino to a more low power version. This board is called the 'Rocket Scream Mini Ultra 8 MHz Plus' and draws a much lower current than the arduino due to it's more power efficient on board regulator. This board also comes with a battery connector which allows us to plug a lithium polymer battery into it and provides pins which a source of up to 20V can be plugged in. We began testing charging it using a standard usb charger and it seems to work, albeit slowly as the charging circuit can charge the batter using a max current of 500mA compared to the 2A you'd be able to charge a similar sized phone battery at. We also tried a different version of the board which used even less power, the 'Rocket Scream Mini Ultra', however we decided against using this due to lack of features such as as voltage regulator, which we would need to use our battery efficiently, and recharging circuits.

####Iteration 6
In this iteration we wanted to make sensor run at a lower power so it could last on batteries for much longer.

#####Issues with previous iteration
Test code was running on the board constantly which led to the battery not being able to fully chage as the code was making the board use a lot of power. This led us to think there was an issue with the charging circuit and look into that. The issue in the end was fixed by making sure the code didn't run and leaving it to charge for a longer period of time.

##### Result of iteration
We used the [Rocket Scream Low-Power](https://github.com/rocketscream/Low-Power) library which allowed us to turn off all of the functions of the processor we were not using and put it into a deep sleep mode. This deep sleep dramatically reduced power usage. We are using the watchdog timer on the board to allow us to set the amount of time we sleep however the watchdog timer can only count up to 8 seconds so to get it to sleep for 1 minute, we needed to run the it 8 times. Some example code for this can be seen below:

```c++
#include <lowpower.h>
#include <avr/wdt.h>

bool count = 8;

void setup()
{
	//Clear the prescaler
	WDTCSR |= (1<<WDCE) | (1<<WDE);

	//1001 for the watchdog prescaler is 1024k cycles 
	//which is ~8seconds
	WDTCSR = 1<<WDP0 | 1<<WDP3;
	
	//Enable interrupt
	WDTCSR |= _BV(WDIE);

}


//Watchdog timer interrupt
ISR(WDT_vect)
{
  if(count > 0)
  {
  	//decrement the count 
  	count--;
  }
  else
  {
  	//Do nothing which returns to the main loop
  }
}

//Put the processort to sleep until it's woken up bt WDT
void sleep()
{
	LowPower.powerDown(SLEEP_FOREVER,ADC_OFF, BOD_OFF);  
}
void loop() 
{
    // read the data...
}  
```
####Iteration 7
##### Issues with the previous iteration
There were several issues we noticed after the iteration. One of these was that the watchdog timer wasn't accurate enough and readings times were drifting a lot. We also found that the code sometimes failed and just stopped working completely. The Xbee was also still drawing a large amount of power as it was running in transmit mode all of the time, even when it was not being used by the program.

#####Results of iteration
We changed the clock to a DS3231 which allowed us to fire interrupts at predetermined intervals, such as every minute. We could then use that wake the processor from it's sleep and it could then take the readings. We made some modifications to the DS3231 by removing the power and transmit LEDs to reduce power consumption. The clock ensured that readings were taken at the same point every minute. We also reprogrammed the Xbee to use pin hibernate mode. This meant that when we pulled a pin low on the board, the Xbee would also enter sleep mode. This sleep mode reduced it's power usage down to around 500μA which was acceptable. The Xbee was then only powered on when we wanted to send data, which was a tiny fraction of the time. Changing to interrupt based processor sleep seems to have solved the problem of the board not waking from sleep.

All code mentioned in this section can be found [here](sensor/)


### Bibliography

Arduino.cc, (n.d.). Arduino - ArduinoBoardProMini. [online] Available at: https://www.arduino.cc/en/Main/ArduinoBoardProMini [Accessed 16 Jan. 2016].
<style>
	.todo{ color:red }
</style>

[toc]

<a name="networking"></a>
##Networking [cont.](#contents)
###Description

Our network is a robust low powered mesh that has a coordinator handling as many routers and end points as we need. The coordinator is capable of addressing each node on the network as well as the nodes being able to address the coordinator. The hardware used to handle interaction on the network is the XBee S2 module using the ZigBee protocol communicating to our devices using serial. XBee S2 have sleep functionality and only draw 40mA upon transmitting making them ideal for a low powered solution. 

Due to the configuration behind each XBee module we were able to have full control over our own network as well as control features such as sleep modes and firmware. We are using API mode when handling XBee modules on our network, as this firmware allows us to have much more control over the network.

The sensors were programmed in C++ and the Hub was programmed in Python, so we have written two Libraries to be able to communicate in the format the XBee modules expected. Using these libraries we can have greater control over the API mode letting us know when nodes disappear on the network, or that a packet failed to transmit to name a few.

<p class="todo">Might need to change to fit format ^

IMAGE 1

IMAGE 2

###Previous Work

####Iteration 1, Researching Wireless Solutions

#####The Solution we need

Based on how we aim to solve the problem, with multiple sensors sending data back to a hub. <span class="todo">reference initial ideas page</span> Our networking solution needs to allow us to have a hub that can have multiple sensors connected wirelessly. The network needs to allow us to communicate data reliably. The data we are expecting to be sending between the sensors and the hub is only going to be ≈ 2000 bits an hour based on the fact that we are going to send a timestamp and an averaged hourly value as a 'long' and an 'int'. 

#####Researching Technologies

Because we decided that we were working with a wireless network based on our aims<span class="todo"> link to why we chose to use wireless</span> Investigating potential solutions considerations of strength, distance, maximum payload size and power usage have to be made. The most obvious solution is WiFi.

Here is a table that we formulated over common wireless solutions: 
 
<table>
	<tr>
		<td></td>
		<td>Range (line of sight)</td>
		<td>Range (Urban)</td>
		<td>Frequency</td>
		<td>Current Consumption (max)</td>
		<td>Power Consumption (sleep)</td>
		<td>Voltage</td>
		<td>Data Rate (s)</td>
	</tr>
	<tr>
		<td>WiFi</td>
		<td>100m</td>
		<td>20m</td>
		<td>2.4GHz/5GHz</td>
		<td>300mA</td>
		<td>Varies</td>
		<td>>= 5v</td>
		<td>Varies</td>
	</tr>
	<tr>
		<td>Bluetooth</td>
		<td>100m</td>
		<td>20 - 30m</td>
		<td>2.4GHz</td>
		<td>30mA</td>
		<td>Varies</td>
		<td>N/A</td>
		<td>1 - 3Mbits</td>
	</tr>
	<tr>
		<td>Bluetooth Low Energy</td>
		<td>100m</td>
		<td>< 100m</td>
		<td>2.4GHz</td>
		<td>15mA</td>
		<td>Varies</td>
		<td>N/A</td>
		<td>1Mbit</td>
	</tr>
	<tr>
		<td>XBee XSC</td>
		<td>9500m</td>
		<td>610m</td>
		<td>902 - 928MHz</td>
		<td>60mA(R) 265mA(T)</td>
		<td>45uA</td>
		<td>3.3v</td>
		<td>10Kbits</td>
	</tr>
	<tr>
		<td>XBee Series 2</td>
		<td>120m</td>
		<td>40m</td>
		<td>2.4GHz</td>
		<td>40mA (R & T)</td>
		<td>< 1uA</td>
		<td>3.3v</td>
		<td>250Kbits</td>
	</tr>
</table>

<br>
*WiFi*

WiFi is widely used and accepted as a way to wirelessly transmit data. This means our clients should be familiar with it in some sense. However WiFi is not really intended to be used in devices that need to be situated in one place for an extended amount of time. This is because WiFi can use a lot of power when sending and receiving data. Hence why smartphones can lose power quickly while connected to a WiFi network.

Because we shouldn't be sending anything more than ≈7 kilobytes a day, therefore the ability to send upwards of 10 megabytes might be overkill. 

However, the main reasons why we would want to use WiFi comes in two forms. Not only can we transmit reasonable distances but we can directly connect devices to the clients home WiFi.<span class="todo"> do we want to link to where the client said we could use wifi?</span> This could, in theory, lead to the elimination of the hubs which would result in problems regarding data processing. The sensor would have to do all of its data processing onboard meaning it could effect the timing of the capture of our data.

One of our mains goals for the sensor is to make the battery as long as possible . WiFi is one of the more power consuming options, so using WiFi with or without a hub our sensor would have to use much more power when receiving and transmitting data making the battery life less than desirable. 

Another one of the more problematic issues of WiFi would be the encryption, the data we are sending is not of national security nor anything that could be any real use to anyone aside our clients and in the event that our clients change their WiFi credentials (Encryption key, SSID etc) then we risk jeopardising the sensors.

<br>
*Bluetooth and Bluetooth Low Energy*

Bluetooth is also a viable alternative for transferring over a low bandwidth where speed is not too key an issue. Depending on how often we schedule the device to transmit data. Since the range on this is considerably lower (5-30 meters) so we would have to consider integrating this with a hub of some kind to forward our data. Fortunately some of the properties across Orange Street feature flat rooftops; upon which we could attach peripherals such as antennas if we need to.  

Bluetooth smart devices have a typically very low sleep current which equates to low power consumption when it isn’t being used. This is ideal as the device will have periods of inactivity once we decide upon which kind of timeframe it should be operating over. 

Bluetooth works on a dynamic network topology called PAN, which supports up to 8 other devices and a minimum of two, although we don’t plan on having an abundance of sensors in one house (Minimum most likely 3) 

<br>
*XBee S2 and XSC*

We found that the S2 in particular was more than adequate for our desires, having one of the lower current draws for transmitting/receiving data, especially that of in sleep with a good data rate (250kbps) and working on a mesh network topology.  Not only this, but the XBee offered full configurable settings on its usage and setup, allowing us greater control of the network than other alternatives.

The XBee can also be programmed manually to work on its own meaning in theory we could eliminate the Microcontroller entirely, however this solution leads to problems involving working out the current time and large packet payloads. We may come back to it at a later point, but for now we decided to use it purely for as means for A-B for our data. 

#####Conclusion, Configuring the XBee

We've decided to choose the XBee S2 as our solution. Due to its customisability and low powered nature its perfect for having our own control on a network. If we utilised WiFi for example then we would have to concern ourselves with high power usage and lacking full control of the network. The XBee offers a multitude of different possibilites and fits closest to our goals of a low powered networking solution. 

####Iteration 2, XBee AT Mode

XBees have microcontrollers onboard that store and control the instructions that let them know where data is being sent, sleep functionality, node hopping, retry attempts and much more. For our network we needed to configure each XBee to work within our desired parameters.

In order to configure these settings we required software and hardware to interface into the XBee, software created by Digit International called XCTU. We had to make our own programmer however as we hadn't received our own programmer as of yet. With this we have started altering the settings on the firmware to adapt the XBees to our desired network structure.

IMAGE 5

When programming the XBees over serial, there are many different options for installing new firmware settings. We've been working with ZNet 2.5 AT for both coordinators and end routers on the network as this is the recommended starting firmware as provides all functionality we currently need. Although we could end changing at a later date depending on what functionality we require.

XBees share one trait across all networks, that is the requirement for them to be able to communicate; using a PANID. The PANID is a 64 bit integer that is unique on a network and separates other networks in close proximity from each other, unless you unluckily both choose the same PANID - however with the options available that is a very slim chance.

IMAGE 6

Using AT Command mode we've had to specifically set values on the XBee. These have ranged from 64bit destination address to encryption being enabled. This information is used in creating packets, we can't change this information without reprogramming the XBees which could cause a problem. However we know which nodes need to address each other in the long run, so none of these details need changing for the time being. 

After we set the two XBee devices to be on the same personal network (sharing PANID), aligning their firmware (ZNet 2.5 AT), and finally setting them as coordinator and router - they were able to communicate. In AT mode we could send bytes down serial to the XBee and the firmware of that XBee would create a packet based on what we’ve set as predefined instructions. The XBee constructed these packets based on their programmed firmware, which we had configured. 

We ideally need one hub per house which could communicate and route data between nodes. The hubs are going to be powered by mains as opposed to sensors which are powered by batteries and in varying locations. The sensors communicate using XBees to the Hub on a mesh topology, in theory allowing us to have as many sensors as we may need.

#####Setting up AT Mode

We’ve been using AT mode so far with XBees. AT Mode is designed to be very straightforward to use, the device connects to the XBee module on serial and sends any data in a form of bytes to be used in a packet and transmitted on the network. We’ve been using XCTU to talk between XBee modules, making sure we understand the concepts of how they are designed to communicate and parameters for addressing each other. 
	

IMAGE 7.1

Setting the XBees up involves us requiring two major pieces of information, the PANID and Address. The coordinators destination points to 0x000000000000FFFF while any end points or routers need to point their destinations to the coordinator's address. That can be achieved in two ways, one way is using 0x0000000000000000 or actually specifying its address.

IMAGE 7.2
#####AT Mode and Hardware

We’ve started using FRDM-K64Fs to talk to one another as they provide an application shield and libraries alongside which are full compatibility with a hardware ‘installation’ of the XBee (installation being the XBee has dedicated pins, rather than soldering it to the board). The K64Fs had simple programs designed purely to send data to one another.

INSERT PICTURE OF MBEDS

The MBEDs is the current choice for the Hub but not for the sensor, so at some point we will need to test the capability of using an MBED to talk to an Arduino style board. This has furthered our understand of using XBees with AT mode, specifically how to progress further and utilise these modules in our future components.

* Code for MBED receiver
* Code for MBED transmitter

#####Testing Range

We know roughly the distance of an XBee from its datasheet, however our clients home and in particular Canterbury has very old structures. These structures have very thick walls, we need to know whether our XBees can transmit through these obstacles or whether we need to boost the signal. We modified the previous code used to test between FRDM K64Fs to calculate latency between packets and then walked around parts of campus determining if we had enough packet loss for concern.

We used ‘The Shed’ as the coordinators base station while moving through different parts of the School of Computing while the coordinator was making note of whether it was receiving any data or not. We’ve mapped our findings and calculated distances to determine whether we are going to struggle with walled structures or not.

IMAGE 4

As shown above the XBees are capable of travelling around 30m and only suffer complete packet loss when passing multiple walls, which is most likely unavoidable in our project. We will definitely need some form low powered communications network so boosting the power will be a trade off we most likely can’t afford. 

####Iteration 3, AT Mode with Hub, Sensor and Clock

Our next role is to implement the Hub, Clock and the sensor(s) on the network. For this to work all nodes need to be able to communicate with one another.

IMAGE 7.3

The sensor is planning to send around 700 bytes of data an hour to the hub, the hub then processes that data. If the clock sends a request to the hub then the hub processed that and responds with data back to the clock. Using AT mode it is simply a matter of writing down to serial the bytes you wish to send across the network, all the nodes are configured to talk to one another. The clock and sensor both have their destination addresses set 0x0 pointing to the coordinator while the coordinator has its address set to 0x000000000000FFFF. This allows it to broadcast, the sensor won’t respond as it will not be needed and will be utilising sleep mode on the XBee whereas the clock will respond as the broadcast will directed at the clock.

Code used for Hub with AT Mode can be found here.

#####Problems

In theory the solution was fine, however a problem we did not account for was payload size. For unknown reasons the coordinator would lose segments of incoming data and then just carry on until it received the next transmission. This meant that data was becoming malformed and mixed up which meant it was completely useless to us. Upon further investigation, we found that the internal buffers of the XBees are that of 202 bytes. The XBee datasheet offers flow-control through the use of pins CTS and RTS but in fact it's very likely the XBee doesn’t support fragmentation of packets as we haven’t found anything to prove it does. Using the CTS and RTS pins could prove interesting, but it would only solve the problem of knowing when the XBees internal buffers are almost full or empty.

So we’re likely to be able to send around 150 bytes in a single packet (RF data and packet header), we circumvented this for the time being by purposely delaying and breaking up the data the sensor had. This took advantage of the internal hardware on the XBee which has timers dedicated to calculating when to stop listening on serial, form a packet and send it. By breaking the message down we effectively caused the XBee to send multiple packets across the network in one go.

The other solution to this problem could be to transmit more frequently, every minute over an hour but battery usage would be the main concern. 

A concern was raised regarding the issue of multiple sensors, as of right now we have no way of knowing who is sending data to the hub as well as data becoming malformed and merged due to AT mode. With one sensor this won’t be an issue:

IMAGE 7.73

However with multiple sensors, data becomes inoperable:

IMAGE 7.75

Making this an issue to tackle in the next iteration.

For more information on these particular systems and how they process data see their respective sections.

For information regarding the datasheet for the XBee S2, see this document.
https://www.sparkfun.com/datasheets/Wireless/Zigbee/XBee-Datasheet.pdf
* Page 12 refers to data input buffers of size 202 bytes
* Page 11 refers to ‘Packetization Timeout’ from serial to RF


####Iteration 4, API Mode 

On our previous iteration we discovered a few problems with using AT mode and the XBee modules themselves. We can’t fragment packets without having some form of intervention ourselves and we can’t determine who is sending data which will cause issues for multiple sensors. A simple fix to this is to prefix all incoming data with an identifying name and delimiter, for example clock:”message”. However this is most likely overhead as further research has shown that by using API mode we won’t need to do this as source addresses are passed with packets. We did manage to confirm that fragmentation is not possible on XBee S2 networks, see www.digi.com/wiki/developer/index.php/Determine_MTU for details. 

#####API Mode

API mode is the more advanced for AT in a lot of ways. The XBee will function the same and you can transmit data to the XBee in the same manner, that’s serial down to the XBee RX pin. However, just sending a stream of bytes won’t make the XBee transmit data. With API mode you have to make the packets as opposed to having them made for you. This has required a lot of research into formats and to do so accurately with good use of examples, we used “Building Wireless Sensor Networks” by Robert Faludi. Faludi provides excellent examples and technical details on the use of API mode.

IMAGE 7.4

API mode has many different packets you can create, from investigating the formats of these packets we can see specifically how to form and send data. We would only need 3 different packets format for our system to be fully utilised, those of:

* 0x10 TRANSMIT REQUEST
* 0x90 RECEIVE PACKET
* 0x8B TRANSMIT REQUEST

The typical format of one these packets, for example the transmit request appears as follows:

Transmit (“Hello world”): “7E 00 19 10 01 00 00 00 00 00 00 00 00 FF FE 00 00 48 65 6C 6C 6F 20 57 6F 72 6C 64 D5”
Receive (“Hello world”): “7E 00 19 10 01 00 00 00 00 00 00 00 00 FF FE 00 00 48 65 6C 6C 6F 20 57 6F 72 6C 64 D5”
Status (“Hello world”): 7E 00 07 8B 01 00 00 00 00 00 73

These hexadecimal values while alien looking are relatively straightforward to identify as again they are following a format. The packets we will form will be a transmit packet while the packets we receive will be a status and receive packet. 

The transmit packet must follow this format when being created:

IMAGE 7.5

The receive packet will follow this format, so we know the offset of each byte:

IMAGE 7.6

The status packet will follow this format, again we know the offset of each byte:

IMAGE 7.7

These formats are important because when we wish to send or receive data to the XBee it will need to be in this format. Instead of:

~~~python
self.serial.write(“Hello world!”) # AT method
~~~

We would use:

~~~python
self.serial.write(bytearray.fromhex('7E 00 17 10 01 00 13 A2 00 40 C1 FD 49 FF FE 00 00 48 65 79 20 57 6F 72 6C 64 A7')) # API method
~~~

However for true implementation we would want this to return some indicator of whether the message was transmitted successfully or not. For example:

~~~python
response = transmit(bytearray.fromhex('7E 00 17 10 01 00 13 A2 00 40 C1 FD 49 FF FE 00 00 48 65 79 20 57 6F 72 6C 64 A7')) # API method
if response == x:
       # do something ...
~~~

If we had this, then we could use this within our existing components to implement a form of error awareness and resolution.

#####API Mode System Benefits

API mode offers a lot more in utility at the cost of more effort on implementation. The benefit of using it, is that you can access all data in a packet header. This would allow us to see all sorts of ranging information from source address to checksums and would solve our problem of needing to identify nodes on the network. It also comes with a lot of added benefits, using API mode we could determine whether a node is out of range, what nodes are on the network and whether packets have been successfully delivered or not. 

For API mode to be implemented we need to build two libraries capable of handling the underlying functions of the XBee. One library would need to utilise Python and the other C++, the Python library would be used by the Hub while any other nodes would use the C++ library. The Hub had its own requirements and so the library would need to reflect that.


######Hub API requirements
* Node discovery (Locate any new nodes)
* Heartbeat requests (Determine whether a node is still active)
* Individual node addressing (Address any node on the network as opposed to broadcasting each time)
* Fragmentation (Break large payloads down)
* Assembly (Reassemble large payloads)
* Message storing (If multiple sensors are sending their payloads at the same time, the hub needs to be able identify and reassemble separate messages at the same time)
* Status awareness (Was a packet received?)

######Sensor and clock API requirements
* Fragmentation (Break large payloads down)
* Assembly (Reassemble large payloads)
* Respond to heartbeat requests (Respond to hubs request to see if they are ‘alive’)
* Single message storing (The hub will only ever send one message, to the clock it will be requests or a heartbeat but never at the same time. To the sensor it will be a heartbeat.)
* Status awareness (Was a packet received?) 

######Multiple Sensors Solution

Initially we used AT mode for working with one sensor, however problems soon arose when we planned to add multiple sensors to our network. The problem was that it would become impossible to identify who was sending data causing different sensor readings to become mixed up across transmissions. Using one sensor was fine because only one source of traffic with sensor readings was expected, the clock wouldn’t interfere as this was a different format of data. Using API mode has let us identify each node on the network and where each stream of traffic is coming from, fixing this problem for us.

Image 7.76

######Fragmenting Packets

As show in our previous iteration the XBee did support packet fragmentation, so in order for this to work we need to manually number each frame in a packet from each source. We also need to be able to determine which is the final frame of a packet, we’ve decided to use an ‘!’ character, which would never naturally appear in any of our normal packets.

IMAGE 7.8

######Overall Benefits

These requirements will allow us to build a robust network capable of recovery upon failure, if a packet isn’t received for example then retransmit it. We will be able to also provide more feedback to the client such as if a node is no longer within range, if they moved the sensor too far away from the Hub for example.

* For implementations of our node code (C++), see here.
* For implementations of our Hub code (Python), see here.
* For implementations of our Hub code utilising the API, see here. 

#####XBee Sleep Settings

Amongst many of the settings available on the XBee, sleep is a must have for our sensors. There are many options available to us when configuring sleep mode. Most importantly how often does the module stay asleep for and then how often to stay awake for. In terms of reserving power this feature is invaluable for the sensor. 

The sensor currently uses a set of pins on the XBee to command it to enter sleep mode, or awake from sleep mode - thus limiting its power consumption.

####Iteration 5, Sensor out of range

Building off the last iteration, we can now offer a huge more information to the client and to the network. This includes node discovery, a very powerful feature for our network which determines whether nodes are now out of range or have disappeared. Using this information we could alert the client that the sensor has run out of battery and thus died or been moved too far away from the Hub.  

We decided to construct a dummy sensor in order to demonstrate range testing and how to show the client this information in a meaningful manner. The dummy was created using an Arduino Uno, a set of LEDs (Green and Red) as well as a XBee breakout board. It was transmitting random floating values from one of its analog pins in the same format expected of the actual sensor. The sensor was initially given a set of LEDs; green and red. These LEDs would turn on or off depending on the circumstance, if the sensor was within range of the coordinator (The hub) the green LED would light up, else if the sensor was out of range the red LED would light up. 

Although simple in principle, this was not possible with the use of AT mode (Without doing some serious and inefficient modifications). Using status packets we can determine whether a sensor was within range or not and then use this information to alert the client. We’ve decided that this information could be made easier to understand if the Hub was to alert the web server when a sensor was out of range, as this information can be displayed on the website for easier access rather than flashing LEDs.
IMAGE 10

## <a name="hub"></a>Hub [cont.](#contents)

Image Here
(The finished Hub, requiring only ethernet and power it is capable of coordinating the entire network.)

The Hub uses a Raspberry Pi Model B+ running Raspbian Jessie Lite, the Pi offers GPIO pins to connect external boards to it. Using these pins, an XBee module is connected on serial and provides the Pi with its position on the network as coordinator. The Pi only requires three connections for it to function, an ethernet connection, the serial connection to the XBee and finally power. The programs controlling the network are written in Python 3.

The hub is comprised of multiple parts: [Board](#hub_board), [Communication / XBee](#hub_xbee), [Case](#hub_case)

#####<a name="hub_board"></a>Board

The Hub uses a Raspberry Pi Model B+ running Raspbian Jessie Lite, the Pi offers GPIO pins to connect external boards to it. Using these pins, an XBee module is connected on serial and provides the Pi with its position on the network as coordinator. The Pi only requires three connections for it to function, an ethernet connection, the serial connection to the XBee and finally power. The programs controlling the network are written in Python 3.

#####<a name="hub_xbee"></a>Communication / XBee

The XBee module is configured as coordinator on the network, giving the Hub its status and control on the network. The XBee can address any other XBee module on the network or broadcast to all of them. All other XBees address the coordinator as it is the centre point of the network. Sensors forward their data through the XBees to the Hub the Clock makes requests using its XBee to the Hub also.

#####<a name="hub_processing"></a>Processing Role

It handles data coming in from the sensor and requests from the clock. The clock can request decibel averages of the past 24 hours using the Hub as a middleman, the Hub then forwards this request to the web server and returns the result to the clock. The sensors submit their sampled data to the hub in order for this to then be sent forward to the web server. 
The Hub takes into account that it may not be able to reach the web server for various reasons, and will try multiple times to connect. If it fails with sensor data it will save this in the SD card on the Pi, if it cannot request data for the clock it will return an error instead and the clock can react accordingly. 

Upon a series of failed attempts, once a successful attempt is made the Hub will transmit all previous stored data and delete it afterwards to clear space in memory. 

#####<a name="hub_case"></a>Case

The case was a 3D printed design that was required due to the extra components that the Hub required. The Pi has many off the shelf cases that can be used, however due to our requirement of fitting an XBee module these cases would not suffice. The 3D printed case was capable of fitting the XBee module as well as the Pi.


### Initial Premise

Unlike the sensor, power consumption was not an issue as the client told us that we could connect to a power outlet. It didn't need to be outside the clients premisses either. This meant we could use any feasible board for this role. We needed a board that could offer the most useful functionality towards our project.

The hub was required to be a middleman between sensors and the web server, forwarding traffic onto the website over ethernet and handling any heavy processing. Initially we planned on using an FRDM-K64F board due to familiarity and easy access to them within the University. 

### Hub Hardware
####Iteration ONE
#####FRDM K64F

Image Here
(FRDM K64F Board)

The FRDM-K64F board has a lot of unneeded functionality. It has an unnecessary amount of sensors on the board itself (temperature sensor and accelerometer for example) which wouldn't add to our project benefits. Although as previously stated we are testing this board because of its availability and our familiarity with it. We are familiar with this board and we know that it has a shield that has the ability to interface with an XBee which is what we decided to use for our networking. <span class="todo">(insert link to networking decisions)</span> Using the board would not be an issue, as we have had extensive skill in handling and programming it. Including the MBED Application shield would benefit us in providing pins designed for an XBee module to interface with. It also offers an LCD display for reporting information back to the client, which could be useful for showing basic messages. However the shield does offer a lot of useless additions as well. Introducing more sensors and obstructing every pin on the FRDM makes it unlikely to be a realistic option for our Hub.

<p class="todo">Here I was going to include my case design implementation for the hub, but it went on for a while, would you like me to do that in its own page?</p>

###Research Into other Boards

####Arduino Uno

Considering the Arduino Uno for the hub as a likely candidate for the fact that the board itself does not have any sensors that would be considered unnecessary like on the FRDM K64F. It is programmable in C much like the K64F so will essentially use the same code. The main reason for choosing this board would be to trim the unessential things from our current solution. The Uno is also a well known board that is vastly documented. 

Unlike the K64F the Uno lacks an ethernet port built in. To remedy this we would have to add an Arduino shield capable of offering ethernet such as the Arduino Ethernet shield. The shield while similar to the MBED Application shield provides the ability to transmit more than just data along ethernet, it could provide power too, although this means adding the PoE (Power over Ethernet) component. This added functionality means the possibility for less wires, this means easier instillation for the client as only one connection would be required. There are libraries that exist to help use the shield and it’s functionality and the board offers a lot of useful debug information regarding current status with sending data, making it easier to work with.

With the problem of ethernet solved this only leaves connection to XBee out. In order to fix this we would have to either, include another [shield](http://uk.rs-online.com/web/p/products/6961670/?grossPrice=Y&cm_mmc=UK-PLA-_-google-_-PLA_UK_EN_Semiconductors-_-Semiconductor_Development_Kits&mkwid=s8484M9Xf_dc|pcrid|88057061283|pkw||pmt||prd|6961670&gclid=Cj0KEQjwid63BRCswIGqyOubtrUBEiQAvTol0WdagHobLZ9zO5iXOsR0-jdPUrM43OJ-dTZv86HIMcgaAkHy8P8HAQ) that had a breakout for the XBee or physically wiring up an XBee. Wiring up an XBee would require soldering the required pins on the XBee to wires that we could plug into the headers of the ethernet shield. If we choose to have the ethernet shield with the PoE module the XBee shield would probably not fit and therefore we would have to solder the XBee to the board. In circumstance of soldering the XBee it would also lead to being unable to then modify the firmware settingson the module without desoldering first leading to more spendature of time. Otherwise we could use the shield on its own, meaning we could reconfigure the XBee at any time.

####Arduino Yun

INSERT IMAGE OF YUN AND SYSTEM DIAGRAM (IMAGE 0)

The Arduino Yun is a very unique Arduino board, as it offers two processors. The AR9331 handles a Linux distribution while the ATMega32U4 handles the board. This means we can run an Operating System with all the benefits that brings on this board. The board comes with an ethernet port and WiFi as well, making it immediately more ideal than the previous two boards mentioned. The board also comes with an SD card port for supplying the Operating System, so in theory a large SD card would allow data logging and more storage in general. The board itself can run Arduino sketches which can interface with shell scripts running on the Linux distro, although the two processors are kept separate; bridging is possible due to a library provided.

However the Yun lacks a great deal of hardware support in terms of volatile memory only offering  64MB of DDR2 ram with 16MB of flash, 9 of which is taken by the Linux distribution. With this considered a better alternative would be something like a Raspberry Pi which could offer more memory and more Operating Systems varieties. The price of a Yun is higher than previous entries, averaging around £50 which is more than double the price of an Uno. 

####Micro Server

It is plausible to use a Micro Server in place of the Hub. The server could have a serial programmer connected to a XBee and use programs to read and access the data coming in. Using a Micro server would give huge benefits in terms of processing power, data storage and security. We could have our own choice of operating system and hardware. Data could come in and be backed up internally, then processed to be sent off. However price and size could cause issues, as these servers do not often come cheap and are a lot larger than other potential solutions. They can also become quite loud and considering noise is what we are trying to help our client with it is probably not an ideal solution furthermore it would draw a lot more power than a development board meaning it could have a visible cost impact on the client.

####Raspberry Pi

The Raspberry Pi is a well known mini computer in its own right and full of IoT uses too. Following on from the Microserver idea, the premise of having an operating system was very appealing. Especially the idea of being able to remotely access the Hub, in which both the Microserver, Yun and Pi could provide this. The Pi while being smaller and considerably cheaper than its Microserver counterpart did lack internal hardware to boot, but for the purpose we had planned it was more than adequate. It would’t be noisy either. 

The Pi was a good middleground between the Yun and the Microserver. It didn’t have as many Operating Systems to chose from compared to the Microserver (due to its Arm architecture) but it did offer a good selection of Operating Systems in terms of networking and much more compared to the Arudino Yun. Its price was not as expensive as the Yun or the Microserver, averaging around £25. 

Internal storage could be managed using a SD card of any size meaning data logging was possible as well. With this being built in as well as an ethernet port it has many advantages over previous entries. The only piece of hardware that is lacking for what we need is an XBee connection. Although solutions are the same as the Arduino Uno, either we use a shield with XBee breakouts or we physically wire an XBee up.

However with all this, the Pi did lack the speed of other boards that didn’t require a OS to maintain. It also didn't offer built in WiFi unlike the Yun, but we were unlikely to use this anyway due to potentially changing security of a WiFi network. 

####Research Conclusion

We decided to use a Raspberry Pi (Model B+ 512MB) over other solutions. While the Arduino and FRDM K64F boards offered speed, they lacked remote accessing and long term storage and would require more adaptions to work around this. The Microserver was too large, expensive and potentially noisy. The Yun while very promising lacked internal hardware to match the Pi as well being double the price. The Pi offered a full operating system while maintaining a small size, better secure networking and remote access for updating on the network. This meant that if a bug was found in our code we could remotely update in on the hub, we would also be able to access any logged debug information from the program. 

#####Raspberry Pi (Model B+)
We decided to use a Raspberry Pi (Model B+ 512MB). The Pi offered a full operating system, better secure networking and remote access for updating on the network. This means that if a bug is found in our code while the hub is deployed in our clients house we could remotely update in on said hub. In the same way we would also be able to access any logged debug information from the program.

#####How to move forward with the pi

The Model B+ will be supplied by the university. The operating system of choice was Raspbian Jessie Lite because it is the officially supported OS of the Pi therefore, recommended by the developers of the Pi. The Pi will have to be connected to the XBee over serial, however in order to use these ports they have to be masked by systemd to force them to be free on startup. 

Then we need to write a program capable of handling incoming AT packets from serial, interpret them and respond accordingly. <span class="todo"><- link to code for this</span> 

The program will be written in Python 3 as its easily available on the Pi and offers all the functionality required to create a robust networking program. We will have to modify /etc/rc.local to contain “sudo python hub.py” so that the script will start every time the Operating System starts. If the network was down, or errors occurred on transmit then the Pi will save data locally, and retry on its next attempt.



###Language of Choice: Python <span class="todo">is this description of code or why python was chosen?</span>

*Why Python*

We have chosen Python because it was easily available on the Pi, had plenty of documentation supporting it and is a very easy language to read from another developer's standing. In terms of interfacing it with serial and the network there are plenty of libraries that exist to make this as simple and efficient as possible, we have decided to use PySerial and Requests to handle these requirements. 

*Python Libraries*

PySerial and Requests simplified any complications we may have had from writing our own initial libraries as well as having organised documentation to support them. They abstracted a lot of complicated hardware tasks (such as interrupt handling on GPIO pins) and communicating over the network. Other libraries we plan on using are those standard to Python, time for handling timing operations, random for random calculations, threading to handle multiple tasks to name a few.

###Coordinator on Network

The Hubs most important role will be that of the coordinator on the network, it is the centre point. Due to how XBees address each other, it is very easy to send data straight to coordinator using its predefined 64bit address (0x0000000000000000).  The Hub could address any node on the network and with this could determine which nodes were which and if they were still within range.

####Iteration 2, AT Mode

#####Setting up the Pi

Now that we’ve settled on an operating system, hardware and programming language we can progress to implementing a working network with the Pi. By default the Pi uses the serial ports for terminal access, for us this is of no use and we need those ports for the XBee to communicate on. In order to open the ports we had to go through Systemd which is the main configuration tool for handling debian related Linux distros. Systemd is quite new to Raspbian and because of this most tutorials offering assistance are outdated as they refer to older versions of Raspbian where the use inittab was involved. 





In order to change anything we need access to the Pi. We’ve been remotely accessing the Pi using SSH and a program called Putty, this gives us full access to the Pi without having to actually plug anything into it. Researching Systemd has shown us that you can mask services which effectively disables them entirely from starting. First we needed to find the service we were looking for.

~~~python
systemctl list-units
~~~

This returned us a long list, so from this we needed to find which service was the serial port. As it transpires the Pi will always use the same serial port as it only has one - ttyAMA0. We knew what the serial port is, so we now needed to mask it.

First we decided to play safe and stop the service.

~~~python
systemctl stop sys-devices-platform-soc-20201000.uart-tty-ttyAMA0.device
~~~

Then, we masked it - to stop it from starting again on a reboot.

~~~python
systemctl mask sys-devices-platform-soc-20201000.uart-tty-ttyAMA0.device
~~~

IMAGE 7

Now that serial is free we’ve got to connect the XBee to the Pi, looking at the pinout sheet for the Pi we can see which pins to interface with when compared back to our XBee. 

IMAGE 7v2

The final step is to make sure we have the libraries we need for python, using pip a tool that installs these libraries we can run a command to install them. Pip had to be installed however, which could be done using.

~~~python
python -m pip install -U pip
~~~

With Pip installed, we needed to then install the libraries required for our Pi.

~~~python
pip install pyserial
pip install requests
~~~

Now our Pi is ready to act as a coordinator. The next stage is programming it and making sure it knows how to act accordingly to data. We need to consider the possibility of no access to the internet too, what means do we have to ensure data backups. 

#####What does the Hub need to do?

The Hub is the middleman between the webserver and the nodes on the network, it has a responsibility to ensure data from those nodes reaches their destination. We need to be able guarantee data will be logged if it cannot reach its location, or if a request can’t be completed such in the case of the clock. The Hub should wait and listen for any incoming data and once a full set of data has been received act upon it, if it’s a request from the clock - request values from the server and respond back. If it’s data from one of the sensors then that needs to be sent to the webserver. It needs to be able to distinguish between a sensor and a clock otherwise it’ll send data to the wrong nodes or request values from the webserver for the wrong reasons. 

IMAGE 7.1

######Basic Structure

The Pi will run a thread that continuously waits on serial input, once received it will take as much as it can in before analysing what it’s received. Upon analysing it will decide whether the data is a request from the clock or sensor data, if sensor data it will attempt to transmit it to the webserver, if a request it will request the last 24 hours of average sound values from the web server. If a clock request is made and the web server does respond then the hub expects a format of 24 integer values in an array, when these values are obtained it forwards them to the clock. 

######Data backup

In case the connection between the hub and webserver fails, we need to ensure data backups. In the case that the network fails the Pi will write all of its currently available sensor data to a local file, it’ll re attempt to transmit data the next time it receives another set of sensor data. If that fails, then the cycle continues - save data and try again next time. The hub does try a total of 5 times before giving up and saving to a file, just in case there was a particular error that occurred.

######Distinguishing traffic

The hub needs to be able to tell which node is transmitting which data to it, how does it know whether the data it's received is that of a clock making a request or a sensor sending data? The clock sends data in a format of “R:!”. This is unique, it never appears in any of the sensor data and so when the hub receives any data it will scan for this particular set of characters. If received, it will know that this is a request and not sensor data. Otherwise it will assume all incoming data is from the sensor and forward it to the webserver. 

####Iteration 3, API Mode 

Now that we’ve changed from AT mode to API mode, not much needs to change but at the same time the properties of the Hub have greatly expanded. The API has been designed so that more functionality could be provided without requiring an excess amount of modification to existing code. 

The basic idea being, we only need to change one line:

~~~python
serial.write(“Hello world!”);
# becomes …
response = xbee.sendMessage("sensor1", "Hello world!")
~~~

Now although we’ve added an extra parameter, that is purely beneficial. The extra parameter allows us to address individual nodes on the network, if we want to address every node we specify ‘broadcast’ as the node on the network.

~~~python
# Will message every node on the network with “Hello world!”
response = xbee.sendMessage(“broadcast”, “Hello world!”)
~~~

The nicknames for nodes helps in multiple ways, not only does it allow us to forward this data to be used in identifying different sensors, clocks etc but we can use it to show the client a name that is more legible than a series of hexadecimal values. 

#####Hub Python Library

For information regarding the process behind designing and researching the API required for the Hub, please see Networking, Iteration 4.

The Hub is utilising a library written to handle the API mode of the XBee, the library has many purposes that help make the network as robust as possible. Using these features we’ve been able to make our coordinator incredibly robust as handling large payloads, transmission errors, node discovery and error recovery.

Below is a flowchart diagram demonstrating the new processing behind the Hub.

IMAGE 10

######Node Discovery and Heartbeats

Being able to determine what sensors already exist on a network offers us much more functionality. We’re are able to ping nodes on the network and determine their network status.

On startup the program running on the hub will  load from memory any nodes it has previously found, after this it’ll try to find any new nodes on the network and save them. This way, it can determine if a node was missing (Maybe a sensor was moved) and could report this back to the client. The hub will periodically send heartbeats across the network to see any changes on the nodes. If a change is detected (such as a node disappearing) it will report this back to the server, this way we can display this information on the website that a sensor was out of range or had run out for battery. 

The Hub utilises the ability to periodically send heartbeats to nodes on the network, this ensures that nodes are up to date - it also falls under node discovery as it will use heartbeats to add new nodes to the network. Once the Hub detects a node its unfamiliar with, it will request its ‘nickname’ for assigning it in its map. The format being:

~~~python
# Send node a HB request asking for it's nickname
response = self.sendMessage(node, "HB#:")
#  Wait for node to respond
time.sleep(.25) 
 # Failed to contact the node
if not response == 0:
	return
#  Add the node to the map along with its 64bit address
# …
self.destinationNodes[name] = newNode
~~~

If the Hub fails to contact a new node, it will reattempt the next time the node retransmits to it. 

With node discovery it simplifies sending messages from the coordinator to the sensors, instead of requiring individuals addresses, you can pass names of nodes into the “sendMessage” function and it will conclude the address based on this from a map structure storing a key to a value. The key being the nickname pointing to the 64bit address, this could be furthered if we implemented the 16bit addresses, which would avoid an address lookup.

~~~python
# Send message with API, sensor1 lets the API know which 64bit
# address we’re looking for, returns successful or not
response = xbee.sendMessage("sensor1", "Hello World")
~~~

######Packet Transmission Status

The Hub stores a single transmit status packet at a time, due to the structure of the library it will only ever need one as it will always check against its transmissions before attempting to transmit again. 

Previously we’ve been unable to determine whether a packet was received or not without physically checking the receiving node. With the new library we’re able to get a response back from our ‘sendMessage’ function, here is a list of the possible response codes:

    0 = successfully transmitted all frames
    1 = payload too big, more than 255 frames required
    2 = Invalid node, does not exist on network
    3 = Failed to transmit data to device, could not reach node

So the Hub can now act accordingly, 

~~~python
sensor = “sensor1”
response = xbee.sendMessage(sensor, "Hello World")
if not response == 0:
	print “Failed to reach”,sensor,”!”
~~~

The output of this code if under the circumstances the XBee failed to transmit would be “Failed to reach sensor1!”. 

With this new feature we can report back to the webserver if a sensor or clock is out of range, or if for any other reason we can’t contact them. Similar features are offered for the sensor as well, meaning that they can also determine whether they are out of range or if the Hubs XBee has failed. 

######Packet Fragmentation 

Previously we’ve been unable to transmit large payloads without potentially malforming data, with the new library we can successfully reconstruct packets based on their frame IDs and source addresses. 

When the Hub needs to transmit a message above the MTU for RF data it will begin fragmentation of that message. It calculates how many frames are required for this packet and breaks it down into separate frames for transmission. It prefixes each frame with its ID and upon the final frame suffixes it with the unique termination character ‘!’, which will not appear in normal transmission.  

The Hub will transmit a frame and wait for an acknowledgement from a status packet before transmitting the next packet, this guarantees that frames cannot arrive out of sync. If it fails to transmit multiple times on the same frame it will return an error code.

IMAGE 11

######Packet Assembly

The Hub stores a list of messages it has received and arranges them based on current frame ID as well as source, it can determine whether a message has terminated upon final frame and return the source of the transmission. When a frame is received the Hub will check all stored messages, if it finds a packet with the same source address that hasn’t terminated and shares the same current frame ID it will append the RF data to the packet contents. 

Due to the structure of the library it is impossible to send frames out of sync, as each frame is checked to ensure it was received before transmitting the next frame. If a packet fails to be terminated after a certain time window of the last frame received it will be dropped. 







## Server
[Back to contents.](#contents)

[toc]

###Description

As there are multiple users wishing to see data coming from multiple sources we needed some sort of central service that collects the information and displays it in an easy way for the users to see. 

The server acts as an API where all data is sent to and requested from. This allows us to add different visualisations very easily without the data being coupled with the interface. 

Readings that are sent to the api are processed to remove anomolous values and are scaled between 0 and 100. We then store the data in the database and it can be requested by other visualisations by making calls to the API endpoints.

There is a key which must be sent with each request to ensure that it is a device that is allowed to access that data. The request should be made over HTTPS to avoid exposing the key. The key is hardcoded into the server but can be changed by modifying the code if needed.


###API Spec
The API responds to HTTP requests which conform to [RFC2616](https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html). 

Key middleware is present throughout the API and it's responses are the following:

| Status | Response|
|--------|---------|
|403		|`{"error":{"text": The key you provided was incorrect}}`|
|401| `{"error":{"text": You did not provide a key}}`|

The endpoints are as follows:
####Readings
*Request*

|  Method | URL  |  
|---		|---|
|  POST | /api/readings  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|
|POST| 	data	| [data object](#data_object)|


*Response*

| Status | Response|
|--------|---------|
|200		|`{status:success}`|
|400| `{"error":{"text": PDO Error}}`|

<a name'data+object'></a>
####Data object
The data object is a csv string which contains both a timestamp and a microphone reading. It also contains the battey reading of the sensor. The csv should be formatted as shown below:

```
'id',id
timestamp,reading
'batt', battery_percentage
```
example with values:

```
id, 2
14073748529, 3547
14073748530, 3047
14073748531, 3538
batt, battery_percentage
```

Please ensure all lines are separated with \n\r

####Get
Returns 24 hours worth of data averaged over one hour periods
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|


*Response*

| Status | Response|
|--------|---------|
|200		|`{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,12,22,23,24}`|
|400| `{"error":{"text": Database Error}}`

####Get Hourly

Returns all data averages over hourly periods
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get/hourly  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|


*Response*

| Status | Response|
|--------|---------|
|200		|
`{0:{start:183975627; end:183975687; avg: 12.4;}1:...}`|
|400| `{"error":{"text": Database Error}}`


####Get Hourly In range
Returns all data recorded between 2 given timestamps averaged over an hourly period.
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get/hourly/{start}/{end}  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|
| URI  | start	| timestamp (string)|
| URI  |end		|timestamp (string)|


*Response*

| Status | Response|
|--------|---------|
|200		|`{0:{start:183975627; end:183975687; avg: 12.4;}1:... }`|
|400| `{"error":{"text": Database Error}}`

###Previous Work

####Iteration One
***At this point we had thought visualisation and back end server were the same thing. This was later changed but for documentation purposes we have considered the inital iteratartions of this as part of the server***

As there are multiple users wishing to see data coming from multiple sources there needs to be some kind of central service that collects the information and displays it in an easy way for the users to see. 

One option for this is to use the hubs themselves as servers. This means that there would be no extra hardware required and everything to run the system would be in the user’s home. This poses several problems, one of which is that the hardware is in the user’s home so if something were to go wrong with the software and it were to crash the device would require a restart on the user’s end which would mean either asking them or going into their house. During this time there would be no results being received by the server and  you would not be able to view any previous results. It also means asking the hub device to do multiple things which means there are more things that could go wrong.

Another option is to have this service run on the university’s servers, this approach also has several pros and cons. One of the benefits is that all the infrastructure and software to run a server and databases are in place and we would simply have to ask for one to be set up. Another good thing about using the university’s infrastructure is that we have greater control and there are safeguards already in place for if things go wrong. One downside to this method is that currently, to access the servers, you need to be connected to the University’s network by being on campus or over VPN. This could be a big problem as the the devices will not be located on campus and ideally would not be connected to the VPN as it can become complex and is yet another thing that could go wrong. One way around this that has been suggested is to use the server that The Shed has. We have been told by Dan Knox that it would be possible to open up some of the ports on that server to allow connections from outside the University’s network.

Overall the option of having a web server in the university would be the best option as it is already provided as a service and is maintained so there would be less maintence for this project. This decision is relies on being able to open up the sheds servers for outside connections. If it turns out this is not possible then we will have to revisit the hub/server idea and possibly think of some other options.

#####What we need
The basic idea of the web end of this project is to provide a place to store large amounts of data over a large period of time and have some sort of mechanism where the user can see those results in a meaningful way. The devices/hubs also need to be able to connect to this service so they can send results directly to it. The user also needs to be made aware of device status such as whether the battery is running low or the device has crashed and needs restarting. This means that the main requirements of the web service are as follows:

- Provide an interface the hubs can easily talk to
- Have the ability to store large amounts of data, around 2.5 million records per year (365 days * 24 hours * 60 minutes * 5 devices which is a reading every minute)
- Show the information that has been collected in a meaningful way that makes sense to the user.
- Provide users with notifications, in the form of emails, regarding the status of devices
- Be easily maintainable as it may need to be picked up by other developers in the future
- Process data. The data sent from the hub will be the raw data from the sensors. The web service needs to turn these into meaningful values and store those

#####Technologies
######Database Comparison
One thing that the web end will definitely need is a database to store all of the data that it is being sent from the sensors. There are many different types of database that are available but we narrowed it down to just three based on what we had experience with and were comfortable using in a short space of time. These three are mongodb, PostgreSQL and MySQL.

*MongoDB*

MongoDB is a NoSQL database that has not defined structure. You can add and remove fields in each record as you see fit. It also favours a high insert rate over a high read rate which is what our application would be doing as a majority of the work would be coming from the sensors rather than people wanting to view the data. The variable structure of this database would make it easier to add sensors going forwards however even though there is no explicit structure in the database itself it would just move the structure over to the web app instead. This means that the web app know what data is stored where and where relations between it should be. This means more time has to be spent on the web app to make sure the structure makes sense. There would still need to be many changes made on the app side if a new sensor type was introduced. Also, as it is a relatively new technology the documentation is not ideal and it is harder to pick up than a standard relational database if you have never worked with NoSQL before. 

*PostgreSQL*

Postgres is a fully features RDBMS that is widely used and growing in popularity. There is a large community around Postgres meaning there are a lot of blog and knowledgebase style articles that provide a lot of support and make development easier. One of the disadvantages is that it provides a lot of functionality that will be unused for simple reads and writes which is what this application will be doing. A benefit of postgres is that it is provided by the university and can be set up by someone outside the project.

*MySQL*

MySQL is another RDBMS and is the most popular one. One advantage of MySQL is that it is very easy to pick up and get started with as it only provides a limited set of features. This could be a downside but it provides everything that this application would need. It is slightly faster than Postgres and there is a lot of support on the internet for it. It is also something that can be set up and maintained by the university.


All of these databases can handle large amounts of data >20 million records which means they are all suitable for the volume of data that will be necessary for this project.

######Language
Because the application needs to run on a server, it needs to be written in a language that a server can be easily set up to understand. PHP was chosen for this as it was a language that everyone in the group is familiar with and has had previous experience using. PHP also fits all of the requirements and is very well documented. 

######MVC Frameworks
Frameworks are tools that are designed to make the development of applications easier by providing a set structure and providing some commonly used features such as authentication. This means that there is less time spent re inventing the wheel and more time can be spent on application specific code. The decision to use a framework was made as one of the key requirements is maintainability. Frameworks provide a lot of documentation to make understanding them very easy. To create something that was tested and documented to the level of an existing framework would take a long time and we felt we could better spend this time in other areas such as UI development. 

Several frameworks were looked at: 

*Laravel*

Laravel is an open source MVC PHP framework. Laravel provides a lot of features out of the box such as an ORM (used for creating and maintaining relationships in databases), a templating engine, database migrations (used to control the structure of your database) and range of other packages handling things such as payment and social logins that can be easily implemented. A benefit of this framework is that it could be very easily extended to add complex features with very little effort and development time. Another good thing about Laravel is that the documentation is well maintained and is regularly updated.

One downside is that it does a lot of things that are simply not necessary for this project. These unnecessary features increase the learning curve of this framework even though it can make things easier in the long run.


*Slim*

Slim is a simple PHP framework that is often used for simple web apps and apis.  It doesn’t provide some of the more advanced features that laravel does but it does give you things such as routing, middleware (for things such as authentication), and easy http manipulation methods.

One downside to Slim is that it is not hugely popular so there are less tutorials and help threads for it but it does have it’s own set of well maintained documentation which means this isn’t a huge issue. 

A benefit is that it doesn’t try to do everything for you, just a core set of things which means it’s easy to pick up and requires very little time to understand. This is key for the maintainability part of the requirements. It also gives you the ability to create simple views to display data without having to learn another templating language, it does it all in PHP.  

*CodeIgniter*

CodeIgniter is another widely used MVC framework that provides a lot of features straight out of the box. As with Laravel, the downside to this is that there is a lot to learn and it’s not instantly obvious what is going on. One of it’s main advantages is its speed compared to other large frameworks however this is less of an advantage when comparing it to lighter frameworks such as slim. It also has a very active community which means documentation is readily available and kept updated.

*Conclusion*

After looking at the different frameworks that were available to us we decided that the best one to use was Slim due to its simple nature. It meant that we could all pick it up fast and get working quickly while still having good documentation that would be easy for anyone else to pick up.

######Version Control
Version control was necessary for this projects as it provided a log of what had been done which we could revert back to if anything went wrong. It also allowed us all to view the code so it could be looked over to check what was being written and committed was sane.We decided to use git for version control as it is an industry standard and we all had some experience of using it. We are hosting the remote repository on github as it provides an easy to use interface and also allows transfer of repository ownership should someone else wish to take the project on in future. 

##### Outcome of Iteration
We produced a system that would take data it recieved from requests and store it in a database. This system ran in a local development environment so was no accessible outside of the computer it was running on. It also showed pages that displayed basic data such as a table of timestamps and readings.


#### Iteration 2

##### Issues with previous iteration

During the previous iteration we discussed putting the application on the university servers however this hasn't been set up so we have used a temporary sever that we are hosting ourselves using digital ocean. The server is using the same technologies as previously mentioned and is running on ubuntu 14.04. 

Another issue we became aware of after the implementation of the first iteration was that the data and the views were very tightly coupled together. We then decided that it would benefit the project to split the front end and back end up into two separate parts. The server would act as an API and the frontend would be used to display the data. This would allow us to add the 'clock', which we weren't aware of at the beginning, to the system without any major issues.


#####Outcome of iteration
We worked to split the front end code from the API and the front end so that they could work independantaly without dupilcation of code. We realised some kind of security was also needed so we added key based authentication to provide a basic level of security. 


#### Iteration 3
#####Issues with previous iteration
While working on the visualisation we discovered that filtering on the client side was not an option as it took too long to load. This meant that we had to do averageing and filerting on the server side. This was due to loading large amounts of raw data. For example to visualise 1 month worth of dummy data it was having to load ~600,000 (60\*24\*7*4) readings which took a considerable amount of time. It then had to group this data and calculate averages based on this which, again, increased page load time. The total load time of a page loading this amount of data was ~6 seconds

The sensor was also struggling to create json arrays due to memory limitations. This meant that the format the server was expecting was often not the format it recieved. 

#####Outcome of iteration
We changed the format of data being sent to and from the sensor from JSON to CSV. This meant there was less overhead in generating the data on the sensors and also less overhead when recieving data.

We moved a majority of the data processing over to the server rather than the client. This was mainly done by using SQL queries to group and average the data. As this is what the database engine is designed for it was able to considerably speed up this process.


<a name="visualisation"></a>
### Visualisation 

[Back to contents](#contents)

#### Description

The web visualisation aspect of the system allows users to both get a quick overview of that data that has been recorded but also dive into the data for a much more detailed view of it. This was an important part of the system as it had to make noise levels clear while also providing the raw data that would be used to back that up.

The finised web visualisation used D3.js to create a number of different ways of displaying the data. The main three it uses are the clock, compare, and graph.

#####The clock interface
The clock is intened to bridge the gap between the phyical parts of the system and the digital parts. It provides a consistent representation of data between the two in an effort to make the user more comfortable. A comparison between the physical clock and the digital clock can be seen below <style>
	.todo{ color:red }
</style>

#Orange Street

## <a name="casing"></a>Casing [cont.](#contents)

###Hub Case

The Hub case is 3D printed. It was designed to hold the Raspberry Pi in place through the use of screws and nuts. It is also designed to have room for the XBee component needed. 