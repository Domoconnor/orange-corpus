<style>
ul{
margin:0;
}


</style>
<div style="position:fixed; top:0; left:0; margin:10px;">
<a href="#contents">Back to Contents</a>
</div>
#Orange Street
<a name="contents"></a>
##Contents

[toc]


<a name="client-interaction"></a>
##Client Interaction 
[Back to contents.](#contents)

###Aims
Our client interaction brought to light these main issues to consider in our project. 

**They do not want to think about the noise:**   
The user talked a lot about having to worry about remembering specific times they were caused inconvenience by the noise outside and then provide evidence of those inconveniences. Therefore the project needs to store data and visualise it in a way that could be presented as evidence of their inconvenience. Also from this we can gather that the user does not really want any real interaction with the device as it would mean them thinking about the noise. The point of the device should be that it runs autonomously (to create peace of mind for the user) collecting data for the user to visualise and use as evidence at their discretion.

**Solution needs little to no interaction, running in the background:**  
The user expects the device to have a maintenance level of a device akin to a router. They expect some general maintenance but they do not want to be too involved with it, ie worrying about battery life all the time.

**A long term solution:**  
Along the lines of the other two themes before, the user wanted the system to be robust and sustainable. During the meeting the user said that this year so far wasn't as bad as last and didn't want to complain this year if it was to change next and get worse. Therefore the end result of the project should be something that the user can maintain on their own.

**People should be aware of their own noise levels:**  
The client talked a lot about wanting the people in the street to know how noisy they are being. Points being brought up suggesting signs that had the decibel reading on them so that people can visualise the noise like a road sign that turns on when you are going too fast. Although, as we wouldn't be able to enforce the sound level it could possibly encouraging even challenging people in the street to be loud to try and make the sign go off.

<p class="todo">DO WE WANT TO INCLUDE A LIST OF GOALS TO ACHIEVE?</p>

####Meeting ONE

We had to speak with the clients before we started to formulate a solution. We had to know what they wanted, so that we could make a solution that best filled their needs. To prepare for this we researched proper interviewing techniques by reading: *“Interviewing users: How to Uncover Compelling Insights (Steve Portigal, 2013)”*.  

The main lesson we took from the Portigal book was that we needed to let the client talk. We did not want to steer their answers in any direction. We organised roles amongst ourselves, with a leader asking questions and the rest taking notes. If the note takers had any questions we made sure they were asked at the end of the question so that the client did not lose track.

Our intended outcome for this meeting was to have an incite into our clients perception of the problem they are having, whereby we can devise a method in which to solve said problem. We had an idea of the client's problem before we went into the meeting, based on what we were told in the project brief. Therefore, in preparation we made a list of questions that we felt we needed answered to gain a better understanding.<span class="todo"> REFERENCE ORIGINAL QUESTION SHEET</span>. We then trimmed down our question list intending to allow our client to talk as freely as possible. <span class="todo">REFERENCE SECOND QUESTION SHEET</span> 

<p class="todo">INCLUDE RECORDING</p>

####Meeting TWO

We spoke to another client that was meant to be present at the original meeting but was unable to make it. They are a landlord of Orange Street tenants living next to a popular club called ‘The Ballroom’. In this meeting we followed the same layout as set in the first meeting, making one person take the lead and the others taking notes, we also followed the same structure of questions.

<p class="todo">INCLUDE SEB RECORDING AND QUOTES</p>

<p class="todo">DO WE INCLUDE PHOTO OF THE RESIDENTS HOUSES ON GOOGLE MAPS?</p>

<img src="images/OrangeStreet_dist.jpg">

####Other Communication

We also tried to speak to other people, pubs and bars in the area to try and gain a greater understanding of the issues that were present in the street and what people were doing to try and solve them.  

A message was sent out to three of the main purported culprits of noise on the street: The Maori Bar, The Seven Stars and Ballroom. The message said: 
>Hello, three other Kent students and I have undertaken a project whereby we are looking into sound around Orange Street. We were wondering how you deal with sound i.e. keeping it contained or if there is a way you try and stop it from spilling into the street. 
>
>Thank you  

The Maori Bar responded with: 
>Hello Matthew thanks for your message, our building is soundproofed in the walls and we make sure the door is kept shut so to trap and muffle as much of the sound as possible. We also monitor our sound levels regularly with a decibel reader.  
>
>Orange Street is a very busy street especially on a Friday and Saturday night and attracts a lot of foot traffic. Of course telling people to keep quiet is near enough impossible as they pass between venues. We don't have live music or DJ's but The Seven Stars and The Ballroom do. We are a small venue with only about 40 people in at one time on average. We would be interested in your findings in your project. Keep us posted.
>
>The Maori Bar team.

This shows that there is an awareness that the street is loud but it can be hard to police outside of the venue. It was also interesting that they mentioned keeping the door closed as the door being opened and closed with the occasional noise leaking out was cited as a large source of annoyance by the clients.  

The Seven Stars allowed us to come and talk to a manager. They said they maintain the noise by trying to keep the doors and windows shut as much as possible and they have a set of double doors so that the sound is muffled when people are coming and going. They also said that they had decibel readers that they checked to make sure that the inside noise was in accordance with the set sound levels. They know that people are noisy when they leave the establishment but he said there was nothing that could be done about that as it is a problem that comes with the clientele.  

Unfortunately The Ballroom did not get back to us.  

####Noise Law

We looked into noise laws. We did this so that we could understand, firstly, if the way we were collecting data was legal and to see if the data we provide to the client would be of any use to them.  

The main thing we found were that there are noise laws in place but they only apply to residential premises according to the ***Noise Act 1996 - Non commercial only. This law only relates to noise that is coming from a residential premises such as neighbours, it does not affect licensed premises.***  

We also found that police can close a premises based on the ***161 Closure orders for identified premises - (1) A senior police officer may make a closure order in relation to any relevant premises if he reasonably believes that: (a) there is, or is likely imminently to be, disorder on, or in the vicinity of and related to, the premises and their closure is necessary in the interests of public safety, or  (b) a public nuisance is being caused by noise coming from the premises and the closure of the premises is necessary to prevent that nuisance.***

The following email is from the Environmental Health department of Canterbury County Council. This is the department that handles any noise complaints regarding both residential and commercial premises. We enquired to them about noise laws.

>Dom  
>
>In response to your enquiry each premises is based on its own merits, hours of operation and location so we don’t have any set levels for Canterbury District. Two documents which may be of use to you are the Control of Noise at Work  
>
>Regulations 2005 which deals with operators requirements for their staff and BS:4142
>  
>The Method for rating and assessing industrial and commercial sound - this looks at how and where to measure sound in mixed residential and business communities. I hope this helps  
>
>Tricia  

The first document mentioned is in relation to the noise levels that are acceptable for their staff and people working on the premises rather than those sounds that are heard from outside the premises so this is of less of a concern to us. Although, it can still be found [here](http://www.legislation.gov.uk/uksi/2005/1643/contents/made). 

The other document mentioned is owned by the British Standards Institute and incurs a cost if we wish to use it. A brief description of the document said the standard is used by the council and describes methods for rating and assessing:

* Helps assess sound levels at proposed new residential premises 
* Enables the investigation of complaints by determining sound levels 
* Reduces the likelihood of financial penalties 
* Supports current UK planning guidance and Environment Agency guidance sound of industrial or commercial nature.

We also looked into licensing reviews and found that anyone with evidence suggesting there is a problem can request a licence review from the council as long as it comes under one of the following:

* Crime and/or disorder 
* Public nuisance 
* Public Safety 
* Prevention of harm to children

In this case, the noise generated from the pubs and or clubs would be classed as a nuisance. 

When making a review request evidence needs to be provided to support the case that you are making. This evidence can be in multiple forms such as:

* a diary or record of events or incidents 
* photos or video evidence
* sound recordings
* a record of complaints made to the responsible authorities about the premise

##Initial Ideas

At this point we had spoken to enough individuals to have a good place to start working on a potential prototype. We needed to plan how we would efficiently tackle the problem ahead of us. We first had to make a list of requirements based on our aims <span class="todo">link to aims</span>

* We needed multiple sensors 
* We needed the sensors to be self-sustainable for a long period of time.
* We needed the sensors to be out of the way but effective (Out of mind, not reminders to the clients), so no wires running everywhere.
* We needed a way to visualise all the data from these sensors into a form that was easily understandable
* We needed control over the network, and ideally a way to configure it.
* We needed cases that could ensure the endurance of the devices in different conditions.

Translating this to a solution we can work with:

* We were looking at some form of wireless solution, we could not afford to have wires running everywhere when the clients wanted the solution ‘out of mind’. With wireless comes many different solutions, we investigated the best options available to us.
* We know we had to sample sound - we did not know how often to sample however so we went to investigate that also.
* A microphone is needed with any other electronic circuitry that comes with it. 
* A way to display this data, we decided to investigate ways to do such a thing.
* We had to ensure some form of data backup also.
* Some of the requested locations for these sensors were completely unreachable by permanent power supplies, which led us to the investigation of long term battery solutions.
* We needed a case that could survive harsh weather and conditions, one that would be of a suitable Ingress Protection Rating.
* 

### Minutes

Below are the minutes taken for every meeting that we, personally had between us as a group. They are a rough summary of what decisions we chose to take and how we followed up on them in the weeks after.

Weekly Minutes (September 27th - 25th March 2016)

<b> 27/9/2015 </b>
* Project begins.
* Meeting with supervisor, arranging a meeting with clients.
* Research into general hardware understanding.
* Research into general electronics understanding.

<b>3/10/2015</b>
* Research into sensor amplifier, this is required for our sensor to accurately measure noise.
* Reading Portigal Book, this is required to interview our clients in the best format possible.

<b>10/10/2015</b>
* Working on sensor amplifier, have to calculate accurate values for use.
* Concluding on client meetings, taking notes from the important moments in the meeting.
* Sensors are required as expected, multiple of them will be used to gather data on sound.
* Starting to learn 3D print, will need case designs for components in the project. 
* Start researching potential solutions in system architecture to the problem.

<b>18/10/2015</b>
* A Basic sensor has been created using the amplifier circuit, can now use this act as a sensor temporarily.
* Program needs to be written to sample sound from the current sensor.
* Researching sound waves and understanding of sampling, need a better technical understanding of sampling sound waves and sound in general.
* Researching into potential networking solutions, we need a way of transferring this data from the sensor to the website.
* Researching into hardware boards, Arduinos, MBEDs, any particular board that could be used to handle the sensors requirements.

<b>25/10/2015</b>
* Using the written program for sampling data from the sensor, taking this sampled data and working out how to gather the values we need in order to demonstrate a sound level.
* Using the FRDM K64F as a guide - 3D printing a case for this board.
* Decision to use the XBee as our networking module, offers great customisation and low power cost.

<b>2/11/2015</b>
* Started using Github to handle different elements of the project code base.
* Started getting XBees S2 talking to each other, sending dummy data between two modules.
* Began discussing how often we wish to sample data, how many samples to take and the accuracy of our data. 
* Researching into very low boards to act in place of the sensor.

<b>9/11/2015</b>
* Discussed the potential of using the MBED as a Hub as we are familiar with it.
* Looking into XBees and their configurability, discussing whether encryption or the alike is necessary.
* Researching into converting sound values into decibel levels.

<b>16/11/2015</b>
* Still working with XBees, looking into setting up multiple on a network with a mesh topology as opposed to point to point.
* Discussed the battery concerns, clients ideally want a rechargeable set of batteries. Looking into battery solutions.
* Sketching visualisation ideas.  
* Decided on using the Rocket scream board for the sensor, but going to use Arduino Uno for the time being.

<b>23/11/2015</b>
* Attempting to get an Arduino board communicating to an XBee, wiring the module up ourselves as it’s likely we’ll use an Arduino board.
* After showing 5 sketches produced from each other, we concepted some form of clock that displays noise levels.
* Researching into different solutions for a Hub, potentially FRDM K64F. 

<b>30/11/2015</b>
* Mapping locations for sensors, where are we likely place them - what sort of problems does this raise?
* Concepting case designs for the Arduino Uno.
* Researching components for a clock like device.

<b>7/12/2015</b>
* Going to use AT mode for XBee for Hub and sensor, simpler to set up and then focus on API mode of XBee. 
Research into XBee settings, API mode.
* Clock components decided, visualising components and how to use them. Going to use 24 LEDS on the clock for 24 hours.

<b>14/12/2015</b>
* Clock testing and programming, deciding what colours to use, frequency of them.
* Case design tested, researching into weatherproofing the case.
* Raspberry Pi decided for the Hub.
* Prototype of sensor is going to be placed in client's house over Christmas break.
* Prototype will use local SD card instead of network due to power restrictions with the board being used.
* Decided to sample once a minute and average to use as a representation of that minute.

<b>21/12/2015</b>
* Final meeting before Christmas break, sensor has been placed in Client's house on Orange Street. 
* Rocket scream board arrived, testing with rechargeable batteries is next step
* AT Networking finalised.

<b>20/1/2016</b>
* First meeting since end of Christmas break, sensor has been collected and data returned for evaluation.
* From result it is hard to determine accuracy of noise, sampling needs to be more accurate
* Increasing sampling rate to 3 times a minute.
* Work commencing on creating the Hub, and arranging networked solutions.

<b>27/1/2016</b>
* Clock case design prototyping started.
* Raspberry Pi Model B+ acquired, programming beginning in Python with Jessie Lite as the Operating System.
* Investigating how to visualise data on the website.
* Order requested for components to build more sensors.
* Sampling rate is now much more accurate.

<b>3/2/2016</b>
* Programming the RocketScream, research into power usage with the board (disabling/enabling features).
* Researching sleep mode configuration on XBee modules.
* Case design for Hub started.
* Hub to backup data if network fails.

<b>10/2/2016</b>
* Finished hub, need to test with all components under different circumstances.
* Sensor finished, accuracy lacking - looking into solutions.
* Case design for clock on-going.
* Colour sensitive users for clock.

<b>17/2/2016</b>
* Light intensity as opposed to different colours for users of colour blind nature.
* New sensor prototype almost finished, solution to accuracy is a 16bit ADC.
* New case design for sensor, directional microphone.

<b>24/2/2016</b>
* Testing entire system in the ‘wild’, sensor outside, clock on the side and Hub routing traffic.
* If goes to plan, place in Client's house during this week.
* Case finished for sensor, case for clock next.
* Current networking is AT mode.
* Live visualization being worked on.

<b>31/2/2016</b>
* Designing initial poster for project fair.
* Programming API mode for network.
* Design for clock case finished. Need a way to diffuse light.

<b>7/3/2016</b>
* Visualisation of data on website finished.
* Planning on testing website with users.
* Hub API mode finished.

<b>14/3/2016</b>
* Sensor API mode finished.
* Building of a dummy sensor working with API mode to demonstrate capabilities.
* Visualisation of data finished.
* Clock case finished.
* Plans for poster to test the clock and demonstrate our visualisation.

<b>18/3/2016</b>
* Use clock to demonstrate noise levels and visualisation.
* Laptops and tablets for visualising website.
* Dummy sensor to demonstrate range and error correction.
* Hand out flyers on the project.

<b>25/3/2016</b>
* Formating corpus and technical report for project.







<a name="sensor"></a>
## Sensor
[Back to contents](#contents)

###Description

The sensor samples sound every minute. The microphone in the sensor starts collecting sound data every minute it produces data that represents a sine wave. The data is then put through an ADC (Analogue to Digital Converter) that amplifies the analogue data (sine wave) and removes any voltage noise. It is then analysed by the sensor, taking fifty points along the wave, in this minute time period, to find the amplitude of the wave (how loud the sound is).  

The final sensor is comprised of multiple parts, [Microphone](#mic), [ADC](#adc), [Board](#sensor_board), [Clock](#sensor_clock), [Battery](#battery), [XBee](#sensor_xbee), [Case](#sensor_case):

*<a name="mic"></a>Microphone*

The microphone is an electret microphone with a built in MAX4466 amplifier. This amplifier has adjustable gain which is used to boost the raw signal which is passed from the microphone. In the final version of this sensor we decided that this amp was not enough and that we needed to add another amplifier to the circuit to improve our recordings

*<a name="adc"></a>ADC*

The circuit contains an external ADC in the form of an ADS1115. This was chosen for three main reasons. The 16 bit resolution allowed us to work with a larger range of values which we would not have got using the onboard ADC of the board. It also contained a programmable amplifier which we could use to firther amplify the signal coming from the mic. The other reason was that it allowed comparison between 2 analog inputs. 

We found that we were getting a lot of noise coming from the mic which we discovered was caused by the voltage from the board. To counter this voltage coming out of the board with the data coming back from the microphone on the ADC. This allowed us to get the difference and remove any electrical noise from the mic.

*<a name="sensor_board"></a>Board*

The final board we chose was the Rocket Scream Mini Ultra 8 MHz Plus. The reasons this was chosen are below:

 - Battery connector
 - Built in charging circuit
 - Low power voltage regulator
 - Thermal regulation for the battery
 - Relatively cheap
 - Battery voltage monitor

 We slightly modified this board by removing the power indicators to decrease the current draw. 
 
 The board is in a near constant sleep state and only wakes up on a pin interrupt to take readings and send the data back to the sensor. This ensures a battery life of around one and a half months. The interrupt is triggered from the clock.
 
*<a name="sensor_clock"></a>Clock*

The sensor needs a clock to be able to accurately record the time readings are taken. The clock on the sensor also has a further purpose of waking the sensor up at certain times. For this we used a DS3231 which kept time incredibly accurately and also provided an 'alarm' function which could pull a pin high or low based on a set of programmable rules. We set this rule for every minute which means it pulled the pin low every minute. We then had the board sleep listen for an interrupt on that point. 

*<a name="battery"></a>Battery*

We used a 1500mah lithium polymer battery for the sensor as it provided a good balance betwwen power and size. In previous iterations we used a 2000mah which provided a longer battery life however we couldn't source another one in time for the final deployment.

*<a name="sensor_case"></a>Case*
The Case was designed in a way that was intended to aim our microphone at the noisy street and protect the electronics from the elements. It was 3D printed at a high fidelity (high infill of plastic) with a thickness of 3mm as not to allow water in through the printed plastic. It was then sanded and sprayed with a high fill primer to fill any pores left int the plastic left from the printing process. As the case had to be closed around the electronics of the sensor a seam was built in that was filled with a neoprene strip as to stop any water from getting through said seam.

A final version of the code can be found [here](sensor/micTest)

### Previous Work

####Iteration 1 - Researching Hardware
Based on our [client interaction](#client_interaction) we decided that we had to make a device that measured the volume of the sound in Orange Street, collecting the data and sending it back to a server so that it is stored and can be accessed by the client to use.

Building on the initial ideas we had and also looking back to the client interaction section we decided on the following requirements for the sensor:

- Long battery life
- Reliability
- Record the volume of sound in the surrounding area
- Transmit that data back to a hub


We looked into how sound works and discovered that we would need to capture a sound wave and subtract the minimum from the maximum to get an overall amplitude of the wave. We could then use this data to calculate other things such as decibels but initialy recording the sound wave was crucial. We planned to use a microphone and microcontroller board to select some points on a sound wave and perform the calculation.

*The Microphone Amplifying Circuit*

After talking to the client the important part of the diagram would remain constant throughout the process, which was the amplifying circuit. For a microphone to be able to produce a voltage signal able to be processed for data it must be amplified, we know for certain we are measuring noise levels in this project and so this is a crucial step.

![1](Images/sensordan/IMAGE1.PNG)

The basic place to start is a non-inverting amplifying circuit, used with any op-amp it effectively calculates the gain based on two resistor values going into an inverting and non-inverting input. (Gain= 1+ (R2/R1)

The OP-AMP IC we’ve been using is the MCP 6002, the datasheet can be found here. (http://ww1.microchip.com/downloads/en/DeviceDoc/21733j.pdf)

![2](images/sensordan/IMAGE2.png)

It’s an IC with two OP-AMPS and isn’t designed for anything too complicated, for the time being it’s perfect to get a basic amplifying circuit built.

Looking at the microphone itself, it’s a very basic condenser microphone that a lot of products (Mostly cheap ones) use in manufacturing. For the time being it’s ideal, however later on we might consider modifying the microphone as this can have great benefits without changing much of the circuit let alone power requirements (Direction, pop filters, windscreens etc).

Most microphones that feed into a amplifying circuit are biased by a resistor value and then thrown down to ground (0v), one could use a potential to guarantee the voltage level applied to a microphone also.

So far, we’re looking at a circuit like this.

![3](images/sensordan/IMAGE3.png)
Other solutions that can be found on the web include using a different IC (As opposed to the MCP 6002) and modifying the circuit above. 

List of other IC’s and amplifiers we looked into.

<table>
	<tr>
		<td>IC Chip</td>
		<td>Link</td>
	</tr>
	<tr>
		<td>NE5535, TL071, OPA 371</td>
		<td>http://www.zen22142.zen.co.uk/Circuits/Audio/lf071_mic.htm</td>
	</tr>
	<tr>
		<td>LM386</td>
		<td>http://www.learningaboutelectronics.com/Articles/Microphone-amplifier-circuit.php</td>
	</tr>
	<tr>
		<td>MCP 6002</td>
		<td>http://www.aiscube.com/main/downloads/RVHS/RV_lesson_301112.pdf</td>
	</tr>
</table>

Although some may seem more suitable than others, as of right now we’ve focused on having a working circuit. In the long term, once we are happy with this solution we will most likely have a pre-built circuit instead of designing the non-inverting amplifier ourselves and choosing which OP-AMP to use. 


*Processing the Data*

The next step was to process the data, there were many ways to handle this from Microcontrollers to all-in-one IOT boards. We researched the following methods of taking data from a microphone to then process.

<table>
	<tr>
		<td> Potential Idea </td>
		<td> Description </td>
		<td> Pros </td>
		<td> Cons </td>
	</tr>
	<tr>
		<td> IOT Microcontroller Boards </td>
		<td> A whole board designed to handle multiple functions, such as Wifi/3G/Bluetooth with sensors, a built in microcontroller and more.</td>
		<td> 
			<ul>
				<li>A lot of built in features to reduce complexity of building communications between chips.</li>
				<li>Widely available, often designed for IOT solutions.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Often a lot of unneeded accessories (such as temperature sensor)</li>
				<li>Increase the physical size of the device based on unneeded extras</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td> Microcontrollers  </td>
		<td>Singular processors, adjustable clock speeds, do not have the functionality of some of the features present on a microcontroller.</td>
		<td> 
			<ul>
				<li>A lot more freedom in deciding how to run the device.</li>
				<li>Removes any unnecessary features.</li>
				<li>Allows to scale down size of the sensor considerably.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Longer to produce and build together as can take more components.</li>
				<li>More complicated, requires further electronics knowledge.</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td> Barebones  </td>
		<td>Using only modules to handle the work, avoiding any form of major processing.</td>
		<td> 
			<ul>
				<li>Potentially reduce power usage.</li>
				<li>Removes any unnecessary features of a Microcontroller.</li>
				<li>Allows to scale down size of the sensor considerably.</li>
				<li>A lot more freedom in deciding how to run the device.</li>
			</ul>
		</td>
		<td> 
			<ul>
				<li>Longer to produce and build together as can take more components.</li>
				<li>Much more complicated, requires further electronics knowledge.</li>
				<li>Difficult to prototype a sensor without a Microcontroller.</li>
			</ul>
		</td>
	</tr>
</table>

For the purpose of a prototype we decided to work with a IOT Microcontroller, we need to investigate common IOT Microcontroller modules, ones that are ideal for our implementation of this IOT device. 

*Arduino Microcontroller Boards*

Arguably one of the most popular development boards commercially available, has a full function IDE written in C++. Multiple different boards designed for different purposes, all having sharing the basic functionality (such as analog inputs) while offering unique differences. They allow for shields to be placed into them which add even further adaptability, allowing for 3rd party hardware to be interfaced easily into the device. This functionality can be as simple as an SD card reader, a WiFi chip or even an external clock. 

Which one suited our best needs? What did we need in a device?
<ul>
	<li>Low power</li>
	<li>Within reasonable price range</li> 
	<li>Relatively small</li>
	<li>Ability to interface with certain components (Backup mediums if network is down, an external clock to keep track of time, an ADC input and form of digital output to transfer data to a wireless module).</li>
</ul>

This narrowed down our choices to the following Arduino devices.
<ul>
	<li>Arduino Nano</li>
	<li>Arduino Pro Mini</li>
	<li>Arduino Macro</li>
	<li>Arduino Uno</li>
</ul>

![4](images/sensordan/IMAGE4.png)

*Arduino Nano*

![5](images/sensordan/IMAGE5.png)

(https://www.arduino.cc/en/uploads/Main/ArduinoNanoManual23.pdf)

“The ATmega168 has 16 KB of flash memory for storing code (of which 2 KB is used for the bootloader); the ATmega328has 32 KB, (also with 2 KB used for the bootloader). The ATmega168 has 1 KB of SRAM and 512 bytes of EEPROM (which can be read and written with the EEPROM library); the ATmega328 has 2 KB of SRAM and 1 KB of EEPROM” (Arduino.cc, n.d.)
<ul>
	<li>Serial: 0 (RX) and 1 (TX). Used to receive (RX) and transmit (TX) TTL serial data. These pins are connected to the corresponding pins of the FTDI USB-to-TTL Serial chip.</li>
	<li>External Interrupts: 2 and 3. These pins can be configured to trigger an interrupt on a low value, a rising or falling edge, or a change in value. See the attachInterrupt() function for details.</li>
	<li>PWM: 3, 5, 6, 9, 10, and 11. Provide 8-bit PWM output with the analogWrite() function.</li>
	<li>SPI: 10 (SS), 11 (MOSI), 12 (MISO), 13 (SCK). These pins support SPI communication, which, although provided by the underlying hardware, is not currently included in the Arduino language.</li>
	<li>LED: 13. There is a built-in LED connected to digital pin 13. When the pin is HIGH value, the LED is on, when the pin is LOW, it's off.</li>
</ul>

The nano is a small device that has all the functionality that we ideally would want, it has connections over Serial, I2C and SPI (Although supported by hardware, not supported by Arduino libraries).

It requires a minimum of 5v operating power, anything below and functionality is lost and we run the risk of disabling features.

It can run the ATMega 168 or 328, we would ideally use the 328 as it offers much more space (EEPROM, SRAM and Flash memory) and is a later iteration over the 168. The dimensions of the device are 0.73” x 1.70”.

*Arduino Pro mini*

![6](images/sensordan/IMAGE6.png)

(http://www.atmel.com/images/Atmel-8271-8-bit-AVR-Microcontroller-ATmega48A-48PA-88A-88PA-168A-168PA-328-328P_datasheet_Complete.pdf)

Essentially the Pro Mini is identical to the Arduino Nano except for the added ability of lower bootloader space and the ability to run at 3.3v over 5v and other small differences that do not add much to our required project.

“There are two version of the Pro Mini. One runs at 3.3V and 8 MHz, the other at 5V and 16 MHz... The ATmega328 has 32 kB of flash memory for storing code (of which 0.5kB is used for the bootloader). It has 2 kB of SRAM and 1kBs of EEPROM.“ (Arduino.cc, n.d.)

*Arduino Uno*

![8](images/sensordan/IMAGE8.png)

The Uno sticks out in this comparison due to its size difference against the previous 3, which begs the question - why then? Simply put, the Arduino Uno is a very friendly board to use, and for prototyping would be ideal as we would not need to worry about many problems that we could face when going straight in with one of the other solutions. It also shares a lot of common ground with the other 3, except for its size.

It runs the ATmega328P, which has slight differences to the ATmega328 (Slight power reduction). Only uses 0.5KB of the Flash memory for the bootloader, runs at 16MHz and needs at least 6v operating voltage which like the macro can cause instability if run at this low a voltage. 

The biggest benefit for us, was that the Uno would offer easy adaptability and help quickly work with a prototype while we decide which microcontrollers to use, their frequency, and work on breadboards instead of soldering straight away. 

*MBED FRDM-K64F*

![9](images/sensordan/IMAGE9.png)

Another popular developer of IOT boards, using ARM based architecture instead of AVRs. The argument between these two processor architecture is often put down to ARM is powerful, and AVR is not so much. There are variants on the processors but otherwise they tend to stick to those groups. MBEDs have an online compiler and IDE, which works in a similar fashion to Arduinos but is effectively always online which comes with its own problems such as requiring internet access. 

The most ideal MBED board we found was the FRDM-K64F which is regarded as the flagship board, it’s perfectly ideal for prototyping - but in the long run most likely would be too much of a power killer. It’s compatible with most Arduino shields too. In the long run however, the FRDM-K64F while having many features, especially when combined with the MBED application shield - is too much functionality for what we need bundled down, even in a prototype we do not need such complexity. 

Even with all its functionality switched off the device consumes more amps than one of the arduino boards. However we decided that this board would be ideal if used for our hub, as during that period power will not be a concern. 

####Iteration 2 - Making our own amplifier
#####Issues with previous iteration
No issues to report, this is the first design iteration.

#####Result of iteration
Using our amplifier we’ve been able to start sampling sound. We’ve been experimenting with the FRDM K64F and Arduino Uno in measuring sound. Our experiments with these boards consisted of testing the circuit we had made for measuring sound levels. Using the FRDM-K64F:

~~~c++
Serial serial(USBTX, USBRX); // Serial connection
 
// Initialize a pins to perform analog input
AnalogIn   ain(A0);
 
int main(void)
{
    while (1) {
        // print to serial analog input
        printf("normalized: %d \r\n", ain.read_u16()); 
        
    } 

}
~~~

The FRDM-K64F has given us superb accuracy when sampling the microphone, values ranging from 0-65555. This is due to the 16bit analog to digital converter on the board. 

![11](images/sensordan/IMAGE11.png)

We also sampled using an Arduino Uno:

~~~c++
int analogPin = 3;     // Microphone amp connected pin 3
int val = 0;           // variable to store the value read

void setup()
{
  Serial.begin(9600);          //  setup serial
}

void loop()
{
  val = analogRead(analogPin);    // read the input pin
  Serial.println(val);             // print to serial the value
}
~~~ 

We need a way to take these values and use them to sample the sound wave. The values are being sent over serial, so having a program listening on serial and processing data will let us be able to visualise sound over time. 

 Using Java we have written a program that talks on serial to the boards. Our program samples 50 times in a second, long enough to gauge a sound wave. Using the minimum and maximum samples we calculate the range and pass all these values along to a file to be saved.
 
This is the section of our code which samples at 50 times a second:

```java 
	// Read values from sensor

        /* Calculate the range of 50 samples */
        int i = 50;
        int max = data[0];
        int min = max;
        int range;
        int j;

        while (i-- > 1) {
            j = data[i];
            if (j > max) {
                max = j;
            }
            if (j < min) {
                min = j;
            }
        }
        
        range = max - min;
        
        // Save to file 
        // ...
```

Logging this data shows the structure and accuracy behind our sensor. Using this data we can increase the sensitivity of our sensor or increase the sample rate to gain a better understanding. 

As of right now the values (0-500) on the Y axis are not too useful for us, we can determine whether noise has risen but we ideally want to work with decibel levels. 

To view our testing results in more detail, please see here. 

####Iteration 3 - Using a pre-built amplifier
#####Issues with previous iteration
The size of the amplifier we built was ideally too large for a small sensor, we could condense it by soldering and moving components closer together but it would be easier and more efficient to buy pre-built amplifiers. 

#####Result of iteration
We’ve purchased a pre-built amplifier to simplify our circuit, ideally we don’t want wires going everywhere and using a prebuilt amplifier makes our task easier due to less complexity and time required to build one. 

![12](images/sensordan/IMAGE12.png)

The next step is to wire the pre-built microphone amplifier to one of the boards, we’ve decided to use the FRDM K64F for the time being as its sample range from 0-65555 makes it appealing to work with.
 
![13](images/sensor/IMAGE13.png)

This was a very simple change and nothing too complicated occurred, but it does benefit us in the long run. The size of the new amplifier works in our favour as its size makes it very easy to adopt into a system where as previously we had a cluster of wires and components. It doesn’t risk being disconnected when compared to our previous amplifier which was held together through loose wires. 

* For a version of this code see <a href="/sensor/initialNoiseLevel/sketch_dec02a/sketch_dec02a.ino">here</a>.
* For the Java sampling program see <a href="/SensorJavaSamplingCode/">here</a>. 

####Christmas Deployment
Over the christmas period we deployed a version of our sensor that wrote data to an SD card. This was designed to go into one of the resident's houses and record data for a short period of time. We used an arduino uno with a shield that contained an SD card reader. 

We needed a way to power the whole board for the time that we would be away over the christmas break. A standard Uno with no low power code drew a current ~42.5mA. A standard AA battery would provide around 1500mAh.

 $$ 1500mAh/42.5mA=35.29 hours $$

The christmas break lasts 4 weeks so 35.29 hours was going to be nowhere near enough and we would only get data for the first day and a half. 

We discussed several other options that included rechargeable batteries, multiple AA batteries and plugging it into the wall. Multiple AA batteries was discounted because it would be very expensive and we’d need a lot of them. It would also increase the size drastically.

Rechargeable batteries looked like a viable option as they came in much higher capacities and would allow the client to recharge them if they did happen to run out when we were away. We did some initial calculations with the 10000mAh battery that we had to hand:

$$ 10000mAh/42.5mA=232.94 hours $$

$$ 232.94/24= 9.7 days $$

While this was getting better it was still slightly too short for what we needed it for. At this point bigger batteries became more expensive and the University wouldn’t be able to order them in time. This meant we had to make the arduino use less power when it was running. To do this we used low power libraries and turned off everything that we weren’t using. After doing this we managed to get the power usage down to ~22mA. 

$$ 10000mAh22mA= 454.54 hours  $$

$$ 454.54/24= 18.9 days $$

This was a more reasonable amount of time and would give us a good amount of data that we could use in the future. The battery pack we were using could also be easily charged using  a micro usb cable (the same kind that is used to charge phones) which meant we could ask the client to charge it if it did run out of power.

A version of this code can be found [here](sensor/SDCardPrototype/)


####Iteration 4 
#####Issues with previous iteration
There were several issues that arose with the code and hardware we created during the christmas testing We discovered that the mic signal was not being amplified enough which led to a lot of readings being the same even though the noise levels were vastly different. The previous iteration also recorded data directly to an SD card for us to look at later. This is an issue as we needed some way of transmitting data back to the board.

#####Result of iteration
We struggled with amplifying the sound as there we were also amplifiying a lot of electrical noise. We pushed this back to a future iteration as we were getting held up by it.

We added an Xbee to the board so that we could transmit data back to the hub which worked without any issues.

####Iteration 5
#####Issues with previous iteration
We noticed some issues with the previous iteration cutting off data after sending large amounts. This is an issue that needs fixing. We are also currently getting the time for timestamping the data from the internal clock. This is proving to be an issue as the time is not accurate. Over longer periods the time on the board will drift further and further away from the actual time. Also, if the sensor runs out of battery the time will be lost.

#####Result of iteration
The loss of data when transmitting was due to the Xbee buffers being overloaded as we sent the data too quickly. To solve this we added small delays in between sending the data. This fixed the issue and the data appears to be being sent without any issues. We also added a clock to the circuit. This has a backup battery so it can still keep time in the event of the sensor losing power. This clock is also accurate and can keep to +/-1 second over a year. 

####Iteration 6
The aim of this iteration was to fix the issue in iteration 2 where we discovered that mic readings were not being amplified enough to pick up changes in the noise level.

#####Issues with previous iteration
No issues

#####Result of iteration
We added a 16-bit adc which gives us a higher resolution and also allows us to remove electical noise using a comparison of two pins. To do this we used a potential divider to half the 3.3v signal that the board was running off and put in pin 1 of the ADC, we then put the mic output into pin 2. Comparing these 2 pins gave us a wave that was much less noisy, as the power voltages were effectively cancelling each other out. This also means that we could produce a wave which had an maximum amplitude of that was the same as our resolution whereas previously there was a noise baseline which, when amplified, also increased leading to us not being able to amplify it too much. These changes allow us to see the noise level change in much more detail and also pick up smaller changes.

#####Iteration 7
For this iteration we wanted to add a rechargable battery to the circuit so the client could charge it in their house without having to buy standard alkaline batteries. We also wanted to think about low power.

#####Issues with previous iteration
None

#####Result of iteration
We changed our board from an arduino to a more low power version. This board is called the 'Rocket Scream Mini Ultra 8 MHz Plus' and draws a much lower current than the arduino due to it's more power efficient on board regulator. This board also comes with a battery connector which allows us to plug a lithium polymer battery into it and provides pins which a source of up to 20V can be plugged in. We began testing charging it using a standard usb charger and it seems to work, albeit slowly as the charging circuit can charge the batter using a max current of 500mA compared to the 2A you'd be able to charge a similar sized phone battery at. We also tried a different version of the board which used even less power, the 'Rocket Scream Mini Ultra', however we decided against using this due to lack of features such as as voltage regulator, which we would need to use our battery efficiently, and recharging circuits.

####Iteration 8
In this iteration we wanted to make sensor run at a lower power so it could last on batteries for much longer.

#####Issues with previous iteration
Test code was running on the board constantly which led to the battery not being able to fully chage as the code was making the board use a lot of power. This led us to think there was an issue with the charging circuit and look into that. The issue in the end was fixed by making sure the code didn't run and leaving it to charge for a longer period of time.

##### Result of iteration
We used the [Rocket Scream Low-Power](https://github.com/rocketscream/Low-Power) library which allowed us to turn off all of the functions of the processor we were not using and put it into a deep sleep mode. This deep sleep dramatically reduced power usage. We are using the watchdog timer on the board to allow us to set the amount of time we sleep however the watchdog timer can only count up to 8 seconds so to get it to sleep for 1 minute, we needed to run the it 8 times. Some example code for this can be seen below:

```c++
#include <lowpower.h>
#include <avr/wdt.h>

bool count = 8;

void setup()
{
	//Clear the prescaler
	WDTCSR |= (1<<WDCE) | (1<<WDE);

	//1001 for the watchdog prescaler is 1024k cycles 
	//which is ~8seconds
	WDTCSR = 1<<WDP0 | 1<<WDP3;
	
	//Enable interrupt
	WDTCSR |= _BV(WDIE);

}


//Watchdog timer interrupt
ISR(WDT_vect)
{
  if(count > 0)
  {
  	//decrement the count 
  	count--;
  }
  else
  {
  	//Do nothing which returns to the main loop
  }
}

//Put the processort to sleep until it's woken up bt WDT
void sleep()
{
	LowPower.powerDown(SLEEP_FOREVER,ADC_OFF, BOD_OFF);  
}
void loop() 
{
    // read the data...
}  
```
####Iteration 9
##### Issues with the previous iteration
There were several issues we noticed after the iteration. One of these was that the watchdog timer wasn't accurate enough and readings times were drifting a lot. We also found that the code sometimes failed and just stopped working completely. The Xbee was also still drawing a large amount of power as it was running in transmit mode all of the time, even when it was not being used by the program.

#####Results of iteration
We changed the clock to a DS3231 which allowed us to fire interrupts at predetermined intervals, such as every minute. We could then use that wake the processor from it's sleep and it could then take the readings. We made some modifications to the DS3231 by removing the power and transmit LEDs to reduce power consumption. The clock ensured that readings were taken at the same point every minute. We also reprogrammed the Xbee to use pin hibernate mode. This meant that when we pulled a pin low on the board, the Xbee would also enter sleep mode. This sleep mode reduced it's power usage down to around 500μA which was acceptable. The Xbee was then only powered on when we wanted to send data, which was a tiny fraction of the time. Changing to interrupt based processor sleep seems to have solved the problem of the board not waking from sleep.

All code mentioned in this section can be found [here](sensor/)


### Bibliography

Arduino.cc, (n.d.). Arduino - ArduinoBoardProMini. [online] Available at: https://www.arduino.cc/en/Main/ArduinoBoardProMini [Accessed 16 Jan. 2016].


<a name="networking"></a>
##Networking 
[Back to contents](#contents)
###Description

Our network is a robust low powered mesh that has a coordinator handling as many routers and end points as we need. The coordinator is capable of addressing each node on the network as well as the nodes being able to address the coordinator. The hardware used to handle interaction on the network is the XBee S2 module using the ZigBee protocol communicating to our devices using serial. XBee S2 have sleep functionality and only draw 40mA upon transmitting making them ideal for a low powered solution. 

Due to the configuration behind each XBee module we were able to have full control over our own network as well as control features such as sleep modes and firmware. We are using API mode when handling XBee modules on our network, as this firmware allows us to have much more control over the network.

The sensors were programmed in C++ and the Hub was programmed in Python, so we have written two Libraries to be able to communicate in the format the XBee modules expected. Using these libraries we can have greater control over the API mode letting us know when nodes disappear on the network, or that a packet failed to transmit to name a few.

<p class="todo">Might need to change to fit format ^

IMAGE 1

IMAGE 2

###Previous Work

####Iteration 1

#####What We Need

Based on how we aim to solve the problem, with multiple sensors sending data back to a hub. <span class="todo">reference initial ideas page</span> Our networking solution needs to allow us to have a hub that can have multiple sensors connected wirelessly. The network needs to allow us to communicate data reliably. The data we are expecting to be sending between the sensors and the hub is only going to be ≈ 2000 bits an hour based on the fact that we are going to send a timestamp and an averaged hourly value as a 'long' and an 'int'. 

#####Researching Technologies

Because we decided that we were working with a wireless network based on our aims<span class="todo"> link to why we chose to use wireless</span> Investigating potential solutions considerations of strength, distance, maximum payload size and power usage have to be made. The most obvious solution is WiFi.

Here is a table that we formulated over common wireless solutions: 
 
<table>
	<tr>
		<td></td>
		<td>Range (line of sight)</td>
		<td>Range (Urban)</td>
		<td>Frequency</td>
		<td>Current Consumption (max)</td>
		<td>Power Consumption (sleep)</td>
		<td>Voltage</td>
		<td>Data Rate (sec)</td>
	</tr>
	<tr>
		<td>WiFi</td>
		<td>100m</td>
		<td>20m</td>
		<td>2.4GHz/5GHz</td>
		<td>300mA</td>
		<td>Varies</td>
		<td>>= 5v</td>
		<td>Varies</td>
	</tr>
	<tr>
		<td>Bluetooth</td>
		<td>100m</td>
		<td>20 - 30m</td>
		<td>2.4GHz</td>
		<td>30mA</td>
		<td>Varies</td>
		<td>N/A</td>
		<td>1 - 3Mbits</td>
	</tr>
	<tr>
		<td>Bluetooth Low Energy</td>
		<td>100m</td>
		<td>50m</td>
		<td>2.4GHz</td>
		<td>15mA</td>
		<td>Varies</td>
		<td>N/A</td>
		<td>1Mbit</td>
	</tr>
	<tr>
		<td>XBee XSC</td>
		<td>9500m</td>
		<td>600m</td>
		<td>902 - 928MHz</td>
		<td>60mA(R) 265mA(T)</td>
		<td>45uA</td>
		<td>3.3v</td>
		<td>10Kbits</td>
	</tr>
	<tr>
		<td>XBee Series 2</td>
		<td>120m</td>
		<td>40m</td>
		<td>2.4GHz</td>
		<td>40mA (R & T)</td>
		<td>< 1uA</td>
		<td>3.3v</td>
		<td>250Kbits</td>
	</tr>
</table>

[xbee comparison](https://www.sparkfun.com/pages/xbee_guide)

<br>
*WiFi*

WiFi is widely used and accepted as a way to wirelessly transmit data. This means our clients should be familiar with it in some sense. However WiFi is not really intended to be used in devices that need to be situated in one place for an extended amount of time. This is because WiFi can use a lot of power when sending and receiving data. Hence why smartphones can lose power quickly while connected to a WiFi network.

Because we shouldn't be sending anything more than ≈7 kilobytes a day, therefore the ability to send upwards of 10 megabytes might be overkill. 

However, the main reasons why we would want to use WiFi comes in two forms. Not only can we transmit reasonable distances but we can directly connect devices to the clients home WiFi.<span class="todo"> do we want to link to where the client said we could use wifi?</span> This could, in theory, lead to the elimination of the hubs which would result in problems regarding data processing. The sensor would have to do all of its data processing onboard meaning it could effect the timing of the capture of our data.

One of our mains goals for the sensor is to make the battery as long as possible . WiFi is one of the more power consuming options, so using WiFi with or without a hub our sensor would have to use much more power when receiving and transmitting data making the battery life less than desirable. 

<br>
*Bluetooth and Bluetooth Low Energy*

Bluetooth is also a viable solution. Bluetooth and Bluetooth LE can be ideal for data transmission over low bandwidth, and in our case both bluetooth and BLE both have high enough bandwidth for what we are looking to do. The range on bluetooth is of the lowest (with a max of 30 meters) of the possible solutions we would have to make sure that the range was suitable in the customers house if we are going to use it. Whereas bluetooth LE is a better solution as it will run with a much lower energy consumption and has a much better range in urban areas where we will be deploying the devices.

Both possible solutions offer a star network (piconet) topology which would be a good solution to our problem. With there bing a master device (hub) and slaves (sensors) being connected. Although there is a maximum of seven slaves able to connect to a master at one time. Nevertheless, seven slaves might not be an unreasonable amount for what we are trying to do. We do not aim to have seven sensors in a customers house. Ultimately it would not be a scalable solution if you wanted more than seven sensors in one house as we would then have to have multiple hubs.

Also, with bluetooth we would have to carefully schedule how we send and received data as bluetooth (general) has to form a connection between master and slave to transmit data.

<br>
*XBee S2 and XSC*

The XBee S2 is also a good solution to our problem, having a low current draw for transmitting/receiving data, especially when in sleep, a data rate (250kbps) suitable for what we want to send, range suitable for what we need and the possibility for a mesh network topology. Not only this, but the XBee offered full configurable settings on its usage and setup, allowing us greater control of the network.

The XBee can also be programmed manually to work on its own meaning in theory we could eliminate the Microcontroller entirely, however this solution leads to problems involving working out the current time and large packet payloads. 

XBee XSC seems to be unideal for what we are trying to do. The range is unnecessarily high because we are looking at sending distances of 40m max. The power draw is also an issue because of the range it can send also, because of the range the data rate is much lower. All of these things considered it is not a good solution compared to the S2.

#####Conclusion

Comparing all of these technologies there are two standouts being Bluetooth LE and XBee S2 because of their low power consumption and ideal transmission range. On one hand BLE is better than XBee because of its higher data rate and slightly larger range. Although, we decided to go with the XBee because of the possibility of creating a mesh network based on the scalability of the product. Although we are going to use the AT mode one the XBee which will give us a basic star network to begin with.

#####Initial Network

XBees have microcontrollers onboard that store and control the instructions that let them know where data is being sent, sleep functionality, node hopping, retry attempts and much more. For our network we needed to configure each XBee to work within our desired parameters.

In order to configure these settings we required software and hardware to interface into the XBee. XCTU,software created by Digit International and a makeshift serial programmer. With this we could then start altering the settings on the firmware and adapt the XBee's to our desired network structure.

IMAGE 5

When programming the XBees over serial, there are many different options for installing new firmware settings. Initially we worked with ZNet 2.5 AT for both coordinators and end routers on the network.

XBees share one trait across all networks that is a requirement for them to be all to communicate, this is their PANID. The PANID is a 64 bit integer that is ideally unique on a network and separates other networks in close proximity from each other.

IMAGE 6

Using AT Command mode we had to specifically set values on the XBee. These ranged from 64bit destination address to encryption being enabled. This information was used in creating packets.

After we set the two XBee devices to be on the same personal network (sharing PANID), aligning their firmware (ZNet 2.5 AT), and finally setting them as coordinator and router - they were able to communicate. In AT mode we could send bytes down serial to the XBee and the firmware of that XBee would create a packet based on what we’ve set as predefined instructions.

<p class ="todo">DAN code for sending on arduino/ frdm. just initial sending in at stuff

Testing the range of the XBee revealed some problems that were unseen before such as the range being weaker than expected when facing an urban environment. The shed being the receiver's location is simply a building in an open courtyard surrounded by other buildings. The moment we entered another building the XBee's communication would experience huge packet loss and eventually fail entirely. This lead to a new problem, how could we guarantee data's arrival. If the nodes on the network were out of range how could we display this to our client in a meaningful manner?

Testing the XBee's we found that the range was about what we expected. We tested the range by tanking a sensor, that was a node on the network, from the shed, that housed the coordinator, 

IMAGE 4

Although we didn’t need XBee’s to be able to communicate huge distances (beyond 25m) it did raise concerns - causing us to later research API mode and ways of ensuring packet robustness.

####API vs AT

We used API mode over AT mode in the end as this offered more configurability for our network, however it was more overhead in terms of setting up. We would need to account for packet formats, error checking and versatility. With AT mode a lot of this is covered for you, however nearly all of it is hidden away and meant that we couldn’t use it.

For API mode to work in our favour, we had to create two APIs one for the sensors and the Hub. These APIs had to be able to interpret the packet format expected from the XBees (see for formatting: Hub)

IMAGE 8

The written APIs for API mode

The premise of the APIs was to create libraries that would not force the other components to be completely recoded, instead replacing one line would effectively have the same result. With AT mode, sending data was a simple matter of writing that data out to serial and we needed to keep that format. In actuality, with API mode it was not that straightforward. We needed to recreate the packet structure every time a packet was to be sent.

We needed a way to change one line into a whole new function but without changing more than just that line.

IMAGE 9

Both APIs were different and not just in language. The end point/router API was written in C++ and was only ever designed to talk to the coordinator, so when sending a message using this API - it will address the coordinator. Whereas the Python API for the Hub had to allow for the addressing of any node on the network, and had to be able to store multiple incoming packets from different sources. The end point/routers only needed to store one message at a time, and those messages were always from the coordinator who would never send more than one at a time. Due to this requirement, our written APIs did not have to accommodate for every possibility, only the ones that expect and want. 

XBees couldn’t support large packet fragmentation, which meant large payloads would simply drop. Since we were transmitting a lot of data in one go, this lead to problems arising as we had to implement our own fragmentation of packets.

For more information regarding the Hub API and packet fragmentation, see Hub.

Sleep Settings

Amongst many of the settings available on the XBee, sleep was a must have. The XBee actually had the ability to act independently as a sensor with settings being provided for polling data from pins, but due to lack of functionality we sided against using this feature. 

There were many options available to us when configuring sleep mode. Most importantly how often does the module stay asleep for and then how often to stay awake for. In terms of reserving power this feature is invaluable for the sensor. 

The sensor used a set of pins on the XBee to command it to enter sleep mode, or awake from sleep mode - thus limiting its power consumption.

Sensor out of range

We constructed a dummy sensor in order to demonstrate range testing and how to show the client this information in a meaningful manner. The dummy was created using an Arduino Uno, a set of LEDs (Green and Red) as well as a XBee breakout board. It was transmitting random floating values from one of its analog pins in the same format expected of the actual sensor. The sensor was initially given a set of LEDs; green and red. These LEDs would turn on or off depending on the circumstance, if the sensor was within range of the coordinator (The hub) the green LED would light up, else if the sensor was out of range the red LED would light up. 

Although simple in principle, this was not possible with the use of AT mode (Without doing some serious and inefficient modifications). Using status packets we could determine whether a sensor was within range or not and then use this information to alert the client. We later decided that this information could be made easier to understand if the Hub was to alert the web server when a sensor was out of range, as this information could be displayed on the website. 

IMAGE 10

###Conclusion

After testing the XBees on multiple platforms, their range and customizability make them perfect for a small mesh network of sensors to hubs. For our IOT based project they seem more than suitable to fit the role for low-powered sensors reporting back. 
<a name="hub"></a>Hub
##Hub 

[Back to contents.](#contents)

Image Here
(The finished Hub, requiring only ethernet and power it is capable of coordinating the entire network.)

The Hub uses a Raspberry Pi Model B+ running Raspbian Jessie Lite, the Pi offers GPIO pins to connect external boards to it. Using these pins, an XBee module is connected on serial and provides the Pi with its position on the network as coordinator. The Pi only requires three connections for it to function, an ethernet connection, the serial connection to the XBee and finally power. The programs controlling the network are written in Python 3.

The hub is comprised of multiple parts: [Board](#hub_board), [Communication / XBee](#hub_xbee), [Case](#hub_case)

*<a name="hub_board"></a>Board*

The Hub uses a Raspberry Pi Model B+ running Raspbian Jessie Lite, the Pi offers GPIO pins to connect external boards to it. Using these pins, an XBee module is connected on serial and provides the Pi with its position on the network as coordinator. The Pi only requires three connections for it to function, an ethernet connection, the serial connection to the XBee and finally power. The programs controlling the network are written in Python 3.

*<a name="hub_xbee"></a>Communication / XBee*

The XBee module is configured as coordinator on the network, giving the Hub its status and control on the network. The XBee can address any other XBee module on the network or broadcast to all of them. All other XBees address the coordinator as it is the centre point of the network. Sensors forward their data through the XBees to the Hub the Clock makes requests using its XBee to the Hub also.

*<a name="hub_processing"></a>Processing Role*

It handles data coming in from the sensor and requests from the clock. The clock can request decibel averages of the past 24 hours using the Hub as a middleman, the Hub then forwards this request to the web server and returns the result to the clock. The sensors submit their sampled data to the hub in order for this to then be sent forward to the web server. 
The Hub takes into account that it may not be able to reach the web server for various reasons, and will try multiple times to connect. If it fails with sensor data it will save this in the SD card on the Pi, if it cannot request data for the clock it will return an error instead and the clock can react accordingly. 

Upon a series of failed attempts, once a successful attempt is made the Hub will transmit all previous stored data and delete it afterwards to clear space in memory. 

*<a name="hub_case"></a>Case*

The case was a 3D printed design that was required due to the extra components that the Hub required. The Pi has many off the shelf cases that can be used, however due to our requirement of fitting an XBee module these cases would not suffice. The 3D printed case was capable of fitting the XBee module as well as the Pi.


### Initial Premise

Unlike the sensor, power consumption was not an issue as the client told us that we could connect to a power outlet. It didn't need to be outside the clients premisses either. This meant we could use any feasible board for this role. We needed a board that could offer the most useful functionality towards our project.

The hub was required to be a middleman between sensors and the web server, forwarding traffic onto the website over ethernet and handling any heavy processing. Initially we planned on using an FRDM-K64F board due to familiarity and easy access to them within the University. 

### Hub Hardware
####Iteration ONE
#####FRDM K64F

Image Here
(FRDM K64F Board)

The FRDM-K64F board has a lot of unneeded functionality. It has an unnecessary amount of sensors on the board itself (temperature sensor and accelerometer for example) which wouldn't add to our project benefits. Although as previously stated we are testing this board because of its availability and our familiarity with it. We are familiar with this board and we know that it has a shield that has the ability to interface with an XBee which is what we decided to use for our networking. <span class="todo">(insert link to networking decisions)</span> Using the board would not be an issue, as we have had extensive skill in handling and programming it. Including the MBED Application shield would benefit us in providing pins designed for an XBee module to interface with. It also offers an LCD display for reporting information back to the client, which could be useful for showing basic messages. However the shield does offer a lot of useless additions as well. Introducing more sensors and obstructing every pin on the FRDM makes it unlikely to be a realistic option for our Hub.

<p class="todo">Here I was going to include my case design implementation for the hub, but it went on for a while, would you like me to do that in its own page?</p>

###Research Into other Boards

####Arduino Uno

Considering the Arduino Uno for the hub as a likely candidate for the fact that the board itself does not have any sensors that would be considered unnecessary like on the FRDM K64F. It is programmable in C much like the K64F so will essentially use the same code. The main reason for choosing this board would be to trim the unessential things from our current solution. The Uno is also a well known board that is vastly documented. 

Unlike the K64F the Uno lacks an ethernet port built in. To remedy this we would have to add an Arduino shield capable of offering ethernet such as the Arduino Ethernet shield. The shield while similar to the MBED Application shield provides the ability to transmit more than just data along ethernet, it could provide power too, although this means adding the PoE (Power over Ethernet) component. This added functionality means the possibility for less wires, this means easier instillation for the client as only one connection would be required. There are libraries that exist to help use the shield and it’s functionality and the board offers a lot of useful debug information regarding current status with sending data, making it easier to work with.

With the problem of ethernet solved this only leaves connection to XBee out. In order to fix this we would have to either, include another [shield](http://uk.rs-online.com/web/p/products/6961670/?grossPrice=Y&cm_mmc=UK-PLA-_-google-_-PLA_UK_EN_Semiconductors-_-Semiconductor_Development_Kits&mkwid=s8484M9Xf_dc|pcrid|88057061283|pkw||pmt||prd|6961670&gclid=Cj0KEQjwid63BRCswIGqyOubtrUBEiQAvTol0WdagHobLZ9zO5iXOsR0-jdPUrM43OJ-dTZv86HIMcgaAkHy8P8HAQ) that had a breakout for the XBee or physically wiring up an XBee. Wiring up an XBee would require soldering the required pins on the XBee to wires that we could plug into the headers of the ethernet shield. If we choose to have the ethernet shield with the PoE module the XBee shield would probably not fit and therefore we would have to solder the XBee to the board. In circumstance of soldering the XBee it would also lead to being unable to then modify the firmware settingson the module without desoldering first leading to more spendature of time. Otherwise we could use the shield on its own, meaning we could reconfigure the XBee at any time.

####Arduino Yun

INSERT IMAGE OF YUN AND SYSTEM DIAGRAM (IMAGE 0)

The Arduino Yun is a very unique Arduino board, as it offers two processors. The AR9331 handles a Linux distribution while the ATMega32U4 handles the board. This means we can run an Operating System with all the benefits that brings on this board. The board comes with an ethernet port and WiFi as well, making it immediately more ideal than the previous two boards mentioned. The board also comes with an SD card port for supplying the Operating System, so in theory a large SD card would allow data logging and more storage in general. The board itself can run Arduino sketches which can interface with shell scripts running on the Linux distro, although the two processors are kept separate; bridging is possible due to a library provided.

However the Yun lacks a great deal of hardware support in terms of volatile memory only offering  64MB of DDR2 ram with 16MB of flash, 9 of which is taken by the Linux distribution. With this considered a better alternative would be something like a Raspberry Pi which could offer more memory and more Operating Systems varieties. The price of a Yun is higher than previous entries, averaging around £50 which is more than double the price of an Uno. 

####Micro Server

It is plausible to use a Micro Server in place of the Hub. The server could have a serial programmer connected to a XBee and use programs to read and access the data coming in. Using a Micro server would give huge benefits in terms of processing power, data storage and security. We could have our own choice of operating system and hardware. Data could come in and be backed up internally, then processed to be sent off. However price and size could cause issues, as these servers do not often come cheap and are a lot larger than other potential solutions. They can also become quite loud and considering noise is what we are trying to help our client with it is probably not an ideal solution furthermore it would draw a lot more power than a development board meaning it could have a visible cost impact on the client.

####Raspberry Pi

The Raspberry Pi is a well known mini computer in its own right and full of IoT uses too. Following on from the Microserver idea, the premise of having an operating system was very appealing. Especially the idea of being able to remotely access the Hub, in which both the Microserver, Yun and Pi could provide this. The Pi while being smaller and considerably cheaper than its Microserver counterpart did lack internal hardware to boot, but for the purpose we had planned it was more than adequate. It would’t be noisy either. 

The Pi was a good middleground between the Yun and the Microserver. It didn’t have as many Operating Systems to chose from compared to the Microserver (due to its Arm architecture) but it did offer a good selection of Operating Systems in terms of networking and much more compared to the Arudino Yun. Its price was not as expensive as the Yun or the Microserver, averaging around £25. 

Internal storage could be managed using a SD card of any size meaning data logging was possible as well. With this being built in as well as an ethernet port it has many advantages over previous entries. The only piece of hardware that is lacking for what we need is an XBee connection. Although solutions are the same as the Arduino Uno, either we use a shield with XBee breakouts or we physically wire an XBee up.

However with all this, the Pi did lack the speed of other boards that didn’t require a OS to maintain. It also didn't offer built in WiFi unlike the Yun, but we were unlikely to use this anyway due to potentially changing security of a WiFi network. 

####Research Conclusion

We decided to use a Raspberry Pi (Model B+ 512MB) over other solutions. While the Arduino and FRDM K64F boards offered speed, they lacked remote accessing and long term storage and would require more adaptions to work around this. The Microserver was too large, expensive and potentially noisy. The Yun while very promising lacked internal hardware to match the Pi as well being double the price. The Pi offered a full operating system while maintaining a small size, better secure networking and remote access for updating on the network. This meant that if a bug was found in our code we could remotely update in on the hub, we would also be able to access any logged debug information from the program. 

#####Raspberry Pi (Model B+)
We decided to use a Raspberry Pi (Model B+ 512MB). The Pi offered a full operating system, better secure networking and remote access for updating on the network. This means that if a bug is found in our code while the hub is deployed in our clients house we could remotely update in on said hub. In the same way we would also be able to access any logged debug information from the program.

#####How to move forward with the pi

The Model B+ will be supplied by the university. The operating system of choice was Raspbian Jessie Lite because it is the officially supported OS of the Pi therefore, recommended by the developers of the Pi. The Pi will have to be connected to the XBee over serial, however in order to use these ports they have to be masked by systemd to force them to be free on startup. 

Then we need to write a program capable of handling incoming AT packets from serial, interpret them and respond accordingly. <span class="todo"><- link to code for this</span> 

The program will be written in Python 3 as its easily available on the Pi and offers all the functionality required to create a robust networking program. We will have to modify /etc/rc.local to contain “sudo python hub.py” so that the script will start every time the Operating System starts. If the network was down, or errors occurred on transmit then the Pi will save data locally, and retry on its next attempt.



###Language of Choice: Python <span class="todo">is this description of code or why python was chosen?</span>

*Why Python*

We have chosen Python because it was easily available on the Pi, had plenty of documentation supporting it and is a very easy language to read from another developer's standing. In terms of interfacing it with serial and the network there are plenty of libraries that exist to make this as simple and efficient as possible, we have decided to use PySerial and Requests to handle these requirements. 

*Python Libraries*

PySerial and Requests simplified any complications we may have had from writing our own initial libraries as well as having organised documentation to support them. They abstracted a lot of complicated hardware tasks (such as interrupt handling on GPIO pins) and communicating over the network. Other libraries we plan on using are those standard to Python, time for handling timing operations, random for random calculations, threading to handle multiple tasks to name a few.

###Coordinator on Network

The Hubs most important role will be that of the coordinator on the network, it is the centre point. Due to how XBees address each other, it is very easy to send data straight to coordinator using its predefined 64bit address (0x0000000000000000).  The Hub could address any node on the network and with this could determine which nodes were which and if they were still within range.

####Iteration 2, AT Mode

#####Setting up the Pi

Now that we’ve settled on an operating system, hardware and programming language we can progress to implementing a working network with the Pi. By default the Pi uses the serial ports for terminal access, for us this is of no use and we need those ports for the XBee to communicate on. In order to open the ports we had to go through Systemd which is the main configuration tool for handling debian related Linux distros. Systemd is quite new to Raspbian and because of this most tutorials offering assistance are outdated as they refer to older versions of Raspbian where the use inittab was involved. 





In order to change anything we need access to the Pi. We’ve been remotely accessing the Pi using SSH and a program called Putty, this gives us full access to the Pi without having to actually plug anything into it. Researching Systemd has shown us that you can mask services which effectively disables them entirely from starting. First we needed to find the service we were looking for.

~~~python
systemctl list-units
~~~

This returned us a long list, so from this we needed to find which service was the serial port. As it transpires the Pi will always use the same serial port as it only has one - ttyAMA0. We knew what the serial port is, so we now needed to mask it.

First we decided to play safe and stop the service.

~~~python
systemctl stop sys-devices-platform-soc-20201000.uart-tty-ttyAMA0.device
~~~

Then, we masked it - to stop it from starting again on a reboot.

~~~python
systemctl mask sys-devices-platform-soc-20201000.uart-tty-ttyAMA0.device
~~~

IMAGE 7

Now that serial is free we’ve got to connect the XBee to the Pi, looking at the pinout sheet for the Pi we can see which pins to interface with when compared back to our XBee. 

IMAGE 7v2

The final step is to make sure we have the libraries we need for python, using pip a tool that installs these libraries we can run a command to install them. Pip had to be installed however, which could be done using.

~~~python
python -m pip install -U pip
~~~

With Pip installed, we needed to then install the libraries required for our Pi.

~~~python
pip install pyserial
pip install requests
~~~

Now our Pi is ready to act as a coordinator. The next stage is programming it and making sure it knows how to act accordingly to data. We need to consider the possibility of no access to the internet too, what means do we have to ensure data backups. 

#####What does the Hub need to do?

The Hub is the middleman between the webserver and the nodes on the network, it has a responsibility to ensure data from those nodes reaches their destination. We need to be able guarantee data will be logged if it cannot reach its location, or if a request can’t be completed such in the case of the clock. The Hub should wait and listen for any incoming data and once a full set of data has been received act upon it, if it’s a request from the clock - request values from the server and respond back. If it’s data from one of the sensors then that needs to be sent to the webserver. It needs to be able to distinguish between a sensor and a clock otherwise it’ll send data to the wrong nodes or request values from the webserver for the wrong reasons. 

IMAGE 7.1

######Basic Structure

The Pi will run a thread that continuously waits on serial input, once received it will take as much as it can in before analysing what it’s received. Upon analysing it will decide whether the data is a request from the clock or sensor data, if sensor data it will attempt to transmit it to the webserver, if a request it will request the last 24 hours of average sound values from the web server. If a clock request is made and the web server does respond then the hub expects a format of 24 integer values in an array, when these values are obtained it forwards them to the clock. 

######Data backup

In case the connection between the hub and webserver fails, we need to ensure data backups. In the case that the network fails the Pi will write all of its currently available sensor data to a local file, it’ll re attempt to transmit data the next time it receives another set of sensor data. If that fails, then the cycle continues - save data and try again next time. The hub does try a total of 5 times before giving up and saving to a file, just in case there was a particular error that occurred.

######Distinguishing traffic

The hub needs to be able to tell which node is transmitting which data to it, how does it know whether the data it's received is that of a clock making a request or a sensor sending data? The clock sends data in a format of “R:!”. This is unique, it never appears in any of the sensor data and so when the hub receives any data it will scan for this particular set of characters. If received, it will know that this is a request and not sensor data. Otherwise it will assume all incoming data is from the sensor and forward it to the webserver. 

####Iteration 3, API Mode 

Now that we’ve changed from AT mode to API mode, not much needs to change but at the same time the properties of the Hub have greatly expanded. The API has been designed so that more functionality could be provided without requiring an excess amount of modification to existing code. 

The basic idea being, we only need to change one line:

~~~python
serial.write(“Hello world!”);
# becomes …
response = xbee.sendMessage("sensor1", "Hello world!")
~~~

Now although we’ve added an extra parameter, that is purely beneficial. The extra parameter allows us to address individual nodes on the network, if we want to address every node we specify ‘broadcast’ as the node on the network.

~~~python
# Will message every node on the network with “Hello world!”
response = xbee.sendMessage(“broadcast”, “Hello world!”)
~~~

The nicknames for nodes helps in multiple ways, not only does it allow us to forward this data to be used in identifying different sensors, clocks etc but we can use it to show the client a name that is more legible than a series of hexadecimal values. 

#####Hub Python Library

For information regarding the process behind designing and researching the API required for the Hub, please see Networking, Iteration 4.

The Hub is utilising a library written to handle the API mode of the XBee, the library has many purposes that help make the network as robust as possible. Using these features we’ve been able to make our coordinator incredibly robust as handling large payloads, transmission errors, node discovery and error recovery.

Below is a flowchart diagram demonstrating the new processing behind the Hub.

IMAGE 10

######Node Discovery and Heartbeats

Being able to determine what sensors already exist on a network offers us much more functionality. We’re are able to ping nodes on the network and determine their network status.

On startup the program running on the hub will  load from memory any nodes it has previously found, after this it’ll try to find any new nodes on the network and save them. This way, it can determine if a node was missing (Maybe a sensor was moved) and could report this back to the client. The hub will periodically send heartbeats across the network to see any changes on the nodes. If a change is detected (such as a node disappearing) it will report this back to the server, this way we can display this information on the website that a sensor was out of range or had run out for battery. 

The Hub utilises the ability to periodically send heartbeats to nodes on the network, this ensures that nodes are up to date - it also falls under node discovery as it will use heartbeats to add new nodes to the network. Once the Hub detects a node its unfamiliar with, it will request its ‘nickname’ for assigning it in its map. The format being:

~~~python
# Send node a HB request asking for it's nickname
response = self.sendMessage(node, "HB#:")
#  Wait for node to respond
time.sleep(.25) 
 # Failed to contact the node
if not response == 0:
	return
#  Add the node to the map along with its 64bit address
# …
self.destinationNodes[name] = newNode
~~~

If the Hub fails to contact a new node, it will reattempt the next time the node retransmits to it. 

With node discovery it simplifies sending messages from the coordinator to the sensors, instead of requiring individuals addresses, you can pass names of nodes into the “sendMessage” function and it will conclude the address based on this from a map structure storing a key to a value. The key being the nickname pointing to the 64bit address, this could be furthered if we implemented the 16bit addresses, which would avoid an address lookup.

~~~python
# Send message with API, sensor1 lets the API know which 64bit
# address we’re looking for, returns successful or not
response = xbee.sendMessage("sensor1", "Hello World")
~~~

######Packet Transmission Status

The Hub stores a single transmit status packet at a time, due to the structure of the library it will only ever need one as it will always check against its transmissions before attempting to transmit again. 

Previously we’ve been unable to determine whether a packet was received or not without physically checking the receiving node. With the new library we’re able to get a response back from our ‘sendMessage’ function, here is a list of the possible response codes:

    0 = successfully transmitted all frames
    1 = payload too big, more than 255 frames required
    2 = Invalid node, does not exist on network
    3 = Failed to transmit data to device, could not reach node

So the Hub can now act accordingly, 

~~~python
sensor = “sensor1”
response = xbee.sendMessage(sensor, "Hello World")
if not response == 0:
	print “Failed to reach”,sensor,”!”
~~~

The output of this code if under the circumstances the XBee failed to transmit would be “Failed to reach sensor1!”. 

With this new feature we can report back to the webserver if a sensor or clock is out of range, or if for any other reason we can’t contact them. Similar features are offered for the sensor as well, meaning that they can also determine whether they are out of range or if the Hubs XBee has failed. 

######Packet Fragmentation 

Previously we’ve been unable to transmit large payloads without potentially malforming data, with the new library we can successfully reconstruct packets based on their frame IDs and source addresses. 

When the Hub needs to transmit a message above the MTU for RF data it will begin fragmentation of that message. It calculates how many frames are required for this packet and breaks it down into separate frames for transmission. It prefixes each frame with its ID and upon the final frame suffixes it with the unique termination character ‘!’, which will not appear in normal transmission.  

The Hub will transmit a frame and wait for an acknowledgement from a status packet before transmitting the next packet, this guarantees that frames cannot arrive out of sync. If it fails to transmit multiple times on the same frame it will return an error code.

IMAGE 11

######Packet Assembly

The Hub stores a list of messages it has received and arranges them based on current frame ID as well as source, it can determine whether a message has terminated upon final frame and return the source of the transmission. When a frame is received the Hub will check all stored messages, if it finds a packet with the same source address that hasn’t terminated and shares the same current frame ID it will append the RF data to the packet contents. 

Due to the structure of the library it is impossible to send frames out of sync, as each frame is checked to ensure it was received before transmitting the next frame. If a packet fails to be terminated after a certain time window of the last frame received it will be dropped. 







## Server
[Back to contents.](#contents)


###Description

As there are multiple users wishing to see data coming from multiple sources we needed some sort of central service that collects the information and displays it in an easy way for the users to see. 

The server acts as an API where all data is sent to and requested from. This allows us to add different visualisations very easily without the data being coupled with the interface. 

Readings that are sent to the api are processed to remove anomolous values and are scaled between 0 and 100. We then store the data in the database and it can be requested by other visualisations by making calls to the API endpoints.

There is a key which must be sent with each request to ensure that it is a device that is allowed to access that data. The request should be made over HTTPS to avoid exposing the key. The key is hardcoded into the server but can be changed by modifying the code if needed.


###API Spec
The API responds to HTTP requests which conform to [RFC2616](https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html). 

Key middleware is present throughout the API and it's responses are the following:

| Status | Response|
|--------|---------|
|403		|`{"error":{"text": The key you provided was incorrect}}`|
|401| `{"error":{"text": You did not provide a key}}`|

The endpoints are as follows:
####Readings
*Request*

|  Method | URL  |  
|---		|---|
|  POST | /api/readings  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|
|POST| 	data	| [data object](#data_object)|


*Response*

| Status | Response|
|--------|---------|
|200		|`{status:success}`|
|400| `{"error":{"text": PDO Error}}`|

<a name'data+object'></a>
####Data object
The data object is a csv string which contains both a timestamp and a microphone reading. It also contains the battey reading of the sensor. The csv should be formatted as shown below:

```
'id',id
timestamp,reading
'batt', battery_percentage
```
example with values:

```
id, 2
14073748529, 3547
14073748530, 3047
14073748531, 3538
batt, battery_percentage
```

Please ensure all lines are separated with \n\r

####Get
Returns 24 hours worth of data averaged over one hour periods
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|


*Response*

| Status | Response|
|--------|---------|
|200		|`{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,12,22,23,24}`|
|400| `{"error":{"text": Database Error}}`

####Get Hourly

Returns all data averages over hourly periods
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get/hourly  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|


*Response*

| Status | Response|
|--------|---------|
|200		|
`{0:{start:183975627; end:183975687; avg: 12.4;}1:...}`|
|400| `{"error":{"text": Database Error}}`


####Get Hourly In range
Returns all data recorded between 2 given timestamps averaged over an hourly period.
*Request*

|  Method | URL  |  
|---		|---|
|  get | /api/get/hourly/{start}/{end}  |

| Type | Params | Value |
|------|--------|-------|
| GET	|	key		| string|
| URI  | start	| timestamp (string)|
| URI  |end		|timestamp (string)|


*Response*

| Status | Response|
|--------|---------|
|200		|`{0:{start:183975627; end:183975687; avg: 12.4;}1:... }`|
|400| `{"error":{"text": Database Error}}`

###Previous Work

####Iteration One
***At this point we had thought visualisation and back end server were the same thing. This was later changed but for documentation purposes we have considered the inital iteratartions of this as part of the server***

As there are multiple users wishing to see data coming from multiple sources there needs to be some kind of central service that collects the information and displays it in an easy way for the users to see. 

One option for this is to use the hubs themselves as servers. This means that there would be no extra hardware required and everything to run the system would be in the user’s home. This poses several problems, one of which is that the hardware is in the user’s home so if something were to go wrong with the software and it were to crash the device would require a restart on the user’s end which would mean either asking them or going into their house. During this time there would be no results being received by the server and  you would not be able to view any previous results. It also means asking the hub device to do multiple things which means there are more things that could go wrong.

Another option is to have this service run on the university’s servers, this approach also has several pros and cons. One of the benefits is that all the infrastructure and software to run a server and databases are in place and we would simply have to ask for one to be set up. Another good thing about using the university’s infrastructure is that we have greater control and there are safeguards already in place for if things go wrong. One downside to this method is that currently, to access the servers, you need to be connected to the University’s network by being on campus or over VPN. This could be a big problem as the the devices will not be located on campus and ideally would not be connected to the VPN as it can become complex and is yet another thing that could go wrong. One way around this that has been suggested is to use the server that The Shed has. We have been told by Dan Knox that it would be possible to open up some of the ports on that server to allow connections from outside the University’s network.

Overall the option of having a web server in the university would be the best option as it is already provided as a service and is maintained so there would be less maintence for this project. This decision is relies on being able to open up the sheds servers for outside connections. If it turns out this is not possible then we will have to revisit the hub/server idea and possibly think of some other options.

#####What we need
The basic idea of the web end of this project is to provide a place to store large amounts of data over a large period of time and have some sort of mechanism where the user can see those results in a meaningful way. The devices/hubs also need to be able to connect to this service so they can send results directly to it. The user also needs to be made aware of device status such as whether the battery is running low or the device has crashed and needs restarting. This means that the main requirements of the web service are as follows:

- Provide an interface the hubs can easily talk to
- Have the ability to store large amounts of data, around 2.5 million records per year (365 days * 24 hours * 60 minutes * 5 devices which is a reading every minute)
- Show the information that has been collected in a meaningful way that makes sense to the user.
- Provide users with notifications, in the form of emails, regarding the status of devices
- Be easily maintainable as it may need to be picked up by other developers in the future
- Process data. The data sent from the hub will be the raw data from the sensors. The web service needs to turn these into meaningful values and store those

#####Technologies
######Database Comparison
One thing that the web end will definitely need is a database to store all of the data that it is being sent from the sensors. There are many different types of database that are available but we narrowed it down to just three based on what we had experience with and were comfortable using in a short space of time. These three are mongodb, PostgreSQL and MySQL.

*MongoDB*

MongoDB is a NoSQL database that has not defined structure. You can add and remove fields in each record as you see fit. It also favours a high insert rate over a high read rate which is what our application would be doing as a majority of the work would be coming from the sensors rather than people wanting to view the data. The variable structure of this database would make it easier to add sensors going forwards however even though there is no explicit structure in the database itself it would just move the structure over to the web app instead. This means that the web app know what data is stored where and where relations between it should be. This means more time has to be spent on the web app to make sure the structure makes sense. There would still need to be many changes made on the app side if a new sensor type was introduced. Also, as it is a relatively new technology the documentation is not ideal and it is harder to pick up than a standard relational database if you have never worked with NoSQL before. 

*PostgreSQL*

Postgres is a fully features RDBMS that is widely used and growing in popularity. There is a large community around Postgres meaning there are a lot of blog and knowledgebase style articles that provide a lot of support and make development easier. One of the disadvantages is that it provides a lot of functionality that will be unused for simple reads and writes which is what this application will be doing. A benefit of postgres is that it is provided by the university and can be set up by someone outside the project.

*MySQL*

MySQL is another RDBMS and is the most popular one. One advantage of MySQL is that it is very easy to pick up and get started with as it only provides a limited set of features. This could be a downside but it provides everything that this application would need. It is slightly faster than Postgres and there is a lot of support on the internet for it. It is also something that can be set up and maintained by the university.


All of these databases can handle large amounts of data >20 million records which means they are all suitable for the volume of data that will be necessary for this project.

######Language
Because the application needs to run on a server, it needs to be written in a language that a server can be easily set up to understand. PHP was chosen for this as it was a language that everyone in the group is familiar with and has had previous experience using. PHP also fits all of the requirements and is very well documented. 

######MVC Frameworks
Frameworks are tools that are designed to make the development of applications easier by providing a set structure and providing some commonly used features such as authentication. This means that there is less time spent re inventing the wheel and more time can be spent on application specific code. The decision to use a framework was made as one of the key requirements is maintainability. Frameworks provide a lot of documentation to make understanding them very easy. To create something that was tested and documented to the level of an existing framework would take a long time and we felt we could better spend this time in other areas such as UI development. 

Several frameworks were looked at: 

*Laravel*

Laravel is an open source MVC PHP framework. Laravel provides a lot of features out of the box such as an ORM (used for creating and maintaining relationships in databases), a templating engine, database migrations (used to control the structure of your database) and range of other packages handling things such as payment and social logins that can be easily implemented. A benefit of this framework is that it could be very easily extended to add complex features with very little effort and development time. Another good thing about Laravel is that the documentation is well maintained and is regularly updated.

One downside is that it does a lot of things that are simply not necessary for this project. These unnecessary features increase the learning curve of this framework even though it can make things easier in the long run.


*Slim*

Slim is a simple PHP framework that is often used for simple web apps and apis.  It doesn’t provide some of the more advanced features that laravel does but it does give you things such as routing, middleware (for things such as authentication), and easy http manipulation methods.

One downside to Slim is that it is not hugely popular so there are less tutorials and help threads for it but it does have it’s own set of well maintained documentation which means this isn’t a huge issue. 

A benefit is that it doesn’t try to do everything for you, just a core set of things which means it’s easy to pick up and requires very little time to understand. This is key for the maintainability part of the requirements. It also gives you the ability to create simple views to display data without having to learn another templating language, it does it all in PHP.  

*CodeIgniter*

CodeIgniter is another widely used MVC framework that provides a lot of features straight out of the box. As with Laravel, the downside to this is that there is a lot to learn and it’s not instantly obvious what is going on. One of it’s main advantages is its speed compared to other large frameworks however this is less of an advantage when comparing it to lighter frameworks such as slim. It also has a very active community which means documentation is readily available and kept updated.

*Conclusion*

After looking at the different frameworks that were available to us we decided that the best one to use was Slim due to its simple nature. It meant that we could all pick it up fast and get working quickly while still having good documentation that would be easy for anyone else to pick up.

######Version Control
Version control was necessary for this projects as it provided a log of what had been done which we could revert back to if anything went wrong. It also allowed us all to view the code so it could be looked over to check what was being written and committed was sane.We decided to use git for version control as it is an industry standard and we all had some experience of using it. We are hosting the remote repository on github as it provides an easy to use interface and also allows transfer of repository ownership should someone else wish to take the project on in future. 

##### Outcome of Iteration
We produced a system that would take data it recieved from requests and store it in a database. This system ran in a local development environment so was no accessible outside of the computer it was running on. It also showed pages that displayed basic data such as a table of timestamps and readings.


#### Iteration 2

##### Issues with previous iteration

During the previous iteration we discussed putting the application on the university servers however this hasn't been set up so we have used a temporary sever that we are hosting ourselves using digital ocean. The server is using the same technologies as previously mentioned and is running on ubuntu 14.04. 

Another issue we became aware of after the implementation of the first iteration was that the data and the views were very tightly coupled together. We then decided that it would benefit the project to split the front end and back end up into two separate parts. The server would act as an API and the frontend would be used to display the data. This would allow us to add the 'clock', which we weren't aware of at the beginning, to the system without any major issues.


#####Outcome of iteration
We worked to split the front end code from the API and the front end so that they could work independantaly without dupilcation of code. We realised some kind of security was also needed so we added key based authentication to provide a basic level of security. 


#### Iteration 3
#####Issues with previous iteration
While working on the visualisation we discovered that filtering on the client side was not an option as it took too long to load. This meant that we had to do averageing and filerting on the server side. This was due to loading large amounts of raw data. For example to visualise 1 month worth of dummy data it was having to load ~600,000 (60\*24\*7*4) readings which took a considerable amount of time. It then had to group this data and calculate averages based on this which, again, increased page load time. The total load time of a page loading this amount of data was ~6 seconds

The sensor was also struggling to create json arrays due to memory limitations. This meant that the format the server was expecting was often not the format it recieved. 

#####Outcome of iteration
We changed the format of data being sent to and from the sensor from JSON to CSV. This meant there was less overhead in generating the data on the sensors and also less overhead when recieving data.

We moved a majority of the data processing over to the server rather than the client. This was mainly done by using SQL queries to group and average the data. As this is what the database engine is designed for it was able to considerably speed up this process.


<a name="visualisation"></a>
## Visualisation 

[Back to contents](#contents)

### Description

The web visualisation aspect of the system allows users to both get a quick overview of that data that has been recorded but also dive into the data for a much more detailed view of it. This was an important part of the system as it had to make noise levels clear while also providing the raw data that would be used to back that up.

We created a user account system with the aim of allowing users to recieve next notifications for each of the devices. This system lets users register, sign ing, update their information and view the data. Another reason we did this wasm initially, the residents were concerned that the bars may look at this data in some way and use it to try and benefit them. The account system allows only certain people to view the data while also allowing the residents to let people sign up such as council members. The accounts system used Laravel, which was what was also being used for the API.

Another part of the web visualisation was a sensor status section. From here the residents could check on things such as battery status and last reading so they could be happy it was working.

![](images/visualisation/status.png)
The finised web visualisation used D3.js to create a number of different ways of displaying the data. The main three it uses are the clock, graph, and compare.

####Clock interface
The clock is intened to bridge the gap between the phyical parts of the system and the digital parts. It provides a consistent representation of data between the two in an effort to make the user more comfortable. An image of the phyical and digital clocks can be seen below:


![](images/visualisation/clock.jpeg)
![](images/visualisation/clocks.png)

The clock view is meant as an overview for the entire system, at a glance you can see what has been chosen. The clock allows you to then click through to a more detialed graph.

####Graph
The graph shows a more detailed view of the day allowing you to see what numerical levels the noise reached. It also includes a list of the raw data which consists of timestamps, the raw reading, and decibels. 

![](images/visualisation/graph.png)
![](images/visualisation/data.png)

The graph combined with the raw data output shows the noise level in an easy to understand way while displying important information. 

####Compare
The compare section of the website was created as a way of viewing multiple days worth of data on one page. We previously tried this with graphs but found that it was messy and didn't get the point across. To solve this we created a view that which, like the clock, displayed the data using colours based on the sound level. It displayed hours across the x axis and days on the y axis.

![](images/visualisation/compare.png)

As you can see in the image above, on saturday and wednesday evening it was louder than other evenings as they have a yellow colour rather than green.

###Previous Work
#### Iteration 1 - Initial Work
We wnanted something that we could use to show the data we had gathered from the sensors in an easy way. We began by sing the 5-sketches-or-else method. This started with us each sketching 5 ways we could display this data individually. After we had done that we came together to present our ideas to eachother and discussed what we liked about each one. We then worked together to merge the best elements from all of our designs into new designs. After this we continued to improve these designs until we got to a point we were happy with. You can view all of our initial sketches and improvements [here](sketches/)

The main things that came out of this process were the clock, line graphs and a calendar style view. 

After this we decided to start to consider implementing them. We found that some members of the group had experience graphing data and made the most of that experience.We decided that we would generate the graphs and charts using JavaScript rather than generating them on the server as it would move load from the server to the client and also make it much easier to create as we were familiar with JavaScript. We also decided to use a library as it would allow us to quickly get something out there as we wouldn't have to create it form scratch. Based on the sketches and ideas we made and came up with we came up with the simple library comparison chart seen below.

<table>
	<tr>
		<th>Name</th>
		<th>Difficulty</th>
		<th>Line Graphs?</th>
		<th>Calendar Style?</th>
		<th>Clock/circular Style?</th>
		<th>Well documented?</th>
	</tr>
	<tr>
		<td>Chart.js</td>
		<td>Easy</td>
		<td>Yes</td>
		<td>No</td>
		<td>Yes</td>
		<td>No</td>
	</tr>
	<tr>
		<td>Highcharts</td>
		<td>Medium</td>
		<td>Yes</td>
		<td>No</td>
		<td>Yes</td>
		<td>Yes</td>
	</tr>
	<tr>
		<td>D3.js</td>
		<td>Medium</td>
		<td>Yes</td>
		<td>Yes</td>
		<td>Yes</td>
		<td>Yes</td>
	</tr>
	<tr>
		<td>Flot</td>
		<td>Easy</td>
		<td>Yes</td>
		<td>No</td>
		<td>No</td>
		<td>Yes</td>
	</tr>
	<tr>
		<td>jscharts</td>
		<td>Easy</td>
		<td>Yes</td>
		<td>No</td>
		<td>No</td>
		<td>No</td>
	</tr>
</table>

After looking at this we decided to go with D3. It would give us the flexibility to add more complex charts such as one in the style of a calendar as well as being relatively easy to use, well known and well documented.


##### Result of iteration
We created a simple page that would display a graph of a single day along with all of it's points. This is very simplistic and is just to ensure that we can get our data in the correct format.

####Iteration 2 - Displaying Data over multiple days
During this iteration we wanted to display multiple days worth of data on the same graph.

#####Issues with previous iteration
Processing the data is taking large amounts of time on every page refresh

#####Result of iteration
We now have a graph which can display multiple days worth of data. To select these days there is a calendar which you can click on, clicking on the same date again will then deselct it. The graph updates without needing to refresh the page. It is also much quicker than before as we moved the processing of the data from the frontend to the API.  More on this can be found in the [Server section](#server)


####Iteration 3 - Clock visualisation
We wanted to make a bridge between the clock and the website so we decided to create a digital version of the clock that could be displayed on the website. 

#####Issues with previous iteration
The previous iteration worked fine techinically, however there were some issues with the way the data was displayed. Any more than 3 lines was complicated and meant it's difficult to see what data you are looking. We will improve on this in a future iteration.

#####Result of iteration
We created a visualisation that looks similar to the clock as you can see below:

![](images/visualisation/clock1.png)

This was created from the test data we recieved over christmas.

The clock is built on top of D3 using an extension called Circos.js. Below is the code that is used to create these circles

```javascript
//Get the data from the API
d3.json('http://orange.app/api/get/hourly')
		.get(function(error, json){

			//Loop over each set of data recieved and convert it into a clock
			charts[0].forEach(function(x){
				data = json;
				parent = d3.select("#"+x.id)[0][0].parentNode;
				width = parent.offsetWidth - 50;
				height = parent.offsetHeight ;
				var circos = new circosJS({
					container: "#"+ x.id,
					width: width,
					height: height,
				});


				layout_data = []
				
				//Create the layout data used by Circos.js by creating array of 
				//divs with ids 0 - 23 which represent hours
				for (i = 0; i < 23; i++)
				{
					if(i < 10)
					{
						layout_data.push({"len":1, "id":'0'+i+'hour'});
					}
					else
					{
						layout_data.push({"len":1, "id":i+'hour'});
					}

				}

				var clock_data =[]

				//Turn the data recieved from the api into the correct format and 
				//add it to an array containing all the data from our clock
				json.forEach( function(d){
					if(ymd(new Date(d.start)) == ymd(new Date(x.id.substring(1)))) {
						var date = new Date(d.start)
						var hour = date;
						hour.setHours(hour.getHours() + 1);
						clock_data.push([h(date) + "hour", 0, 1, (d.avg+15)])
						console.log(+d.avg+10);
					}
				})

				//Construct the circos object
				circos
					.layout(
						{
							cornerRadius: 3,
							innerRadius: width/4+25,
							outerRadius: width/4+30,
							ticks: {display: false},
							labels: {
								position: 'center',
								display: true,
								size: 14,
								color: '#000',
								radialOffset: 15,
							}
						},
						layout_data
					)
					//Show what colours you want the sections to be
					//based on colorBrewer
					.heatmap('temperatures', {

						innerRadius: width/4,
						outerRadius: width/4+25,
						min: '23',
						max: '0',
						colorPalette: 'RdYlGn',
					}, clock_data)
					.render();
			})
		})
```
####Iteration 4 - Fixing the line graph
The multiple line graph that we created in iteration 2 was confusing hard to understand. We planned to fix this in this iteration.

#####Issues with previous iteration
None

#####Resut of this iteration
We changed the way data was graphed so you could no longer select multiple dates. This made the graph much easier to read but we would need another way to compare data. We began to look at ways of comparing however there are no obvious ways and our sketches don't really help with that.

####Iteration 5 - Fixing data comparison
As mentioned in the previous iteration, we removed the feature from our line graph that would allow us to compare multiple days. This comparison is an important part of the website as without it the results can be hard to understand. 

#####Issues with previous iteration
None

##### Result of this iteration
After looking at several sources we decided that we liked how GitHub show
how often someone commits. You can see an image of one of those graphs below:

![](images/visualisation/github.png)

As we are working with data where time is important we cannot simply show the day so we changed it to include hours on the x axis and days on the y axis. You can see the graph we created below:

![](images/visualisation/compare2.png)

####Iteration 6 - Turning graphs into a website

Up until this point all of the graphs had been standalone, pulling the data from the API but all separate. We needed to create a website where all of these could be viewable and make sense together.

#####Issues with previous iteration
There were some issues with aligning the graph labels however this will be left until a future iteration.

#####Result of this iteration
We created a website that was built in laravel and using bootstrap to improve the interface. We created a user accounts system that would allow access control in the future. The code for the website can be found [here](visualisation/web)

##Manufacture / Casing 

[Back to Contents](#contents)

###Initial Research

The project required us to have hardware in the real world meaning that it has to be able to survive in the environment that it is deployed in. We couldn't simply deploy the electronics because they would get damaged. Therefor we have to house all of our pieces of hardware in some form of casing.

There are a few ways to make cases, they include making a custom 3D model of the object and sending it to companies to either be 3D printed, a process where plastic is melted and printed in layers to form the intended 3 dimensional object. Alternatively, injection moulding, a process where a mould is made of the object intended to be created then melted plastic fills the negative space in the mould leaving the object when it has hardened. 

Injection moulding creates a rigid plastic shell when hardened as the piece comes from liquid plastic that hardens into one piece whereas 3D printed pieces can be more brittle as the plastic dries on when each layer is added meaning it can leave pores on the final product.

There are companies that offer custom 3D printing and injection moulding such as [Shapeways](http://www.shapeways.com/) (3D printing) and [Protolabs](http://www.protolabs.co.uk/) (3D printing and injection moulding). The main issues with these places is the cost and time it would take to get an object back. We would have to design the object we want created, each piece is individually quoted, it would be created and we would have to wait for it to arrive. In the case of injection moulding Protolabs have a minimum of 25 parts from one mould, meaning it would be more expensive than 3D printing. If there was a mistake in a 3D model we would have wasted time and money and still have to print another one.

Although, The Shed has specific software for 3D modelling and a 3D printer that we can use for prototyping and final printing of our cases. It is possible to quickly print a prototype and test a design multiple times and print a final when we are happy with it. 

####Conclusion

We decided to use the Sheds facilities to create our cases. It will be much more cost efficient as we do not have to pay for each individual print and the turn around of each piece is much quick as we do not have to wait for it to be posted.

###Hub Case

####Description

The Hub case is 3D printed. It was designed to hold the Raspberry Pi in place through the use of screws and nuts. It is also designed in a manner that made it easy to open incase there were any problems while the hub was deployed. The case comes in two parts, the lid and the base.

The case is meant to be easily modifiable. So that if there are any changes that need to be made it is easy enough to change the 3D model and print off a new one that fits the purpose better.

*Base*

The base is made to be 2mm thick on the longer sides for strength and rigidity. It was made to be slightly bigger than the Raspberry Pi model B+ (5mm in every direction but the one with the ethernet connection). It has holes in the bottom big enough for 2.5mm fixings to fit through both the case and the board using nuts to hold it in place so that the board is secure inside.

There are two grooves on the longer sides of the base, inside the base, that allow the lid to click into place.

PICTURE OF THE BASE 

*Lid* 

The lid is designed to be reversible for ease of use. The longer sides of the lid has sections that sit inside the base. These sections are as long as the inside of the base so that it does not slide around when fitted. These extruded sections have further extruded lines that click into the grooves on the base. To remove the lid squeeze the sides and pull off. It was designed in this way for ease of access.

PICTURE OF THE LID

####Previous Work

#####Iteration 1 - Initial Hub Base.

The FRDM K64F board had no technical specifications that could be found meaning we did not have the measurements for it. Therefore it had to be measured by eye using rulers and electronic calipers. 

INSERT INITIAL SKETCH

As this is the fist time we would be 3D printing anything we had no reference for how strong the result would be. We decided to measure the thickness of the calipers box as that seemed to be quite a strong (2.5mm).

We decided to model the bottom half of the case first. This was done because it was the smaller of the two pieces of the case, we could reprint a new one quickly if there was anything wrong with this one. We wanted the board to be secure in the case so the we designed it in a way that the base, lid and board had holes that lined up so 3mm fixings could be screwed through all three and secured together.

INSERT PICTURE OF PRINTED CASE

######Outcomes of iteration

We 3D printed our first object, learnt how to use the software properly.

#####Iteration 2 - 

###Sensor Case
####Description
####Previous Work
#####Iteration 1

###Clock Case
####Description
####Previous Work
#####Iteration 1
##Clock
###Description

![Final Clock](Images/Clock%20Images/clock_final.jpg)


The clock is our form of ambient data visualisation, and is designed to engage and notify the user. It is the physical counterpart to our front end visualisation, and uses a simplified system of visual data to represent noise levels. It is designed to complement the more technical premise of the web server. 

It uses a series of 24 LEDs arranged in a ring, which, every hour are lit to a colour corresponding to the average sound levels for that hour. This is a lightweight way of giving the user a quick glance at the sound levels, and allows for comparisons and references to be made across a 24 hour period. 

The light display is handled by an Adafruit NeoPixel Ring 24 x WS2812, which is interfaced through an Adafruit Flora used as the microcontroller. The interaction of the clock with the rest of the system involves an XBee device configured as a router. Resultantly the clock can receive values from the hub, and stay up to date in terms of the data it is presenting.  
Every hour, the clock communicates with the hub to receive the average sound level across that hour. The clock turns on a light for that hour, depending upon the corresponding sound level. Over time, this builds a picture of the day’s sound activity, mirroring the data visualisation on the web server as a physical model. 

Components: Adafruit NeoPixel Ring 24 x WS2812, Adafruit Flora, Communication/XBee (Lilypad XBee), Case. 

####Adafruit NeoPixel Ring 24 x WS2812

The central hardware component of the clock is the Adafruit NeoPixel Ring. One of several NeoPixel models provided by Adafruit, the 24 x WS2812 is a collection of 24 addressable LEDs arranged in a ring. The LEDs were directly addressed by the Arduino code written for the Adafruit Flora, allowing direct control over the display, and timings that each LEDs came on. 

####Adafruit Flora

Lightweight and circular in design, the Adafruit Flora was an effective choice for maintaining the streamlined structure of the clock’s components. Since it is typically used in wearable tech, the Flora is a microcontroller which is smaller than the NeoPixel Ring. This meant the overall size of the clock could be kept compact, allowing more focus to be on the visual display of the NeoPixel Ring. Moreover, it offered the functionality we needed of similar microcontrollers such as the Arduino Uno, but stripped away the unnecessary features. Since the clock device could be powered by mains, the power consumption was not too much of an issue. 

####Communication/XBee (Lilypad XBee)

As with the other devices in the network, the clock communicated using the Zigbee protocol; using an XBee RF module attached to its microcontroller. It was configured as a router on the network, allowing it to receive the data transmission it required from the hub. Through the iterations, the XBee was interfaced using either a straight connection in the RX/TX ports, or through a Lilypad XBee board. 

####Case

The clock’s hardware components are housed in a 3D printed case. As well as maintaining its security, this feature allows the clock to be seen more clearly; using a base to keep it upright. As a result, the clock can be viewed like most normal clocks, and from a multitude of angles in a room. The transparent covering holds the components in place, and optimises the appearance of the lights for viewing by using a frosting film. This was used to prevent glare from the LEDs, and to clearly distinguish one light from another. Since the clock is unique in appearance, it was necessary to develop a case which served its requirements and matched its specific dimensions. Towards the later iterations, the case underwent several changes, and was finalised with the above appearance.    

###Previous Work

####Iteration 1: Design and concepting phase
Since we have decided upon a web based method of visualising data, we want to explore several other means for outputting data to our clients. To engage more with the user, we want to explore methods of ambient data visualisation. 

From our bank of data visualisation ideas, the “clock” design incorporates the use of a coloured light system and a clock face display. The clock would receive the average noise level on the hour, and mark it on its face as a coloured segment. Over a 12 hour period, this would produce an overall chart of ambience. To get coverage over 24 hours, we would have two separate clocks displaying data for AM and PM. 

One option for this would be to involve the clock display in the website visualisation; offering the client a more ambient counterpart to graphs and charts. Since a few of our data visualisation for the five sketches phase featured a crossover of similar clock ideas, it is worth us looking further into how we could combine our sketches.  Since the clock design is simple, it could work quite effectively alongside more technical data formats. 

We could also implement something physical in hardware, which could be read similarly to a clock which tells the time. We discussed a few scenarios in which this would prove useful. Firstly, if a client returned home after being away from the house all day, a quick check of the clock could provide a straightforward spread of activity during their absence; drawing their attention to colours of greater intensity. 

In both cases, the red and orange lights could serve as flags to the user, as they indicate a high concentration of noise activity picked up by the sensor. Meanwhile, the lighter colours provide coverage for quieter hours. This offered the user a complete coverage of each 24-hour period, allowing the possibility to view previous hours and draw comparisons between them. 
Overall, we felt that there was an advantage to having a physical clock, as it is a physical artefact and therefore has greater potential to engage with the user. Furthermore, it could provide effective reinforcement to the data displayed on the web server. 

#####Lo-fi prototyping and sketches
In order to visualise a few different clock concepts, we created some sketches of the clock being represented in different ways. This was a way of gauging how the interface for the clock should look, as well as exploring some aspects such as colour, granularity, and the general visual layout for the user. 
Some of the design sketches we produced later in this iteration explored the placement of a clock as a “widget” on a tablet or webpage. Since our client could rely on mobile or tablet, we also concepted how our designs could be scaled and combined depending on where they are displayed. 

####What we need 
The premise behind the clock is to provide a visual stimulus to the user in a simplified data format for quick reference. It also needs to be interconnected with other devices on the network to accurately display data. Since the device is going to be running a series of lights, it is likely that power usage will be high; which is a consideration for how it will be powered in the user’s home. We also need to decide what sort of hardware we are looking at using to implement this idea, and what limitations and/or advantages each particular technology would give us. The main requirements of the clock are therefore: 
To provide an ambient visualisation of data which is engaging with the user 
Be easily implemented with the rest of the system 
Display data in a format that is easily grasped by the user
To have a feasible hardware solution which complements our other means of data visualisation

![Sketch 1](Images/Clock%20Images/IMAGE_1.png)

	Initial design sketches of the clock. Early iterations of the design featured a dual 12 hour display to represent AM and PM time notations respectively. 

![Sketch 2](Images/Clock%20Images/IMAGE_2.jpg)

	Cardboard prototyping of the clock, and sketches of data formats. The cardboard prototype uses coloured panels to represent hourly averages. Using these, we established a colour spectrum to use for the physical display. The right side image explores how averages are processed and visualised.  

![Sketch 3](Images/Clock%20Images/IMAGE_3.jpg)

	Exploring data continuity. The presence of the clock as a simplified data format complements the more technical aspects of the graphs and charts that we concepted. 

![Sketch 4](Images/Clock%20Images/IMAGE_4.jpg)

	Design sketch for clock display options. In this sketch, we looked at the block sizes for data; whether we would work in 10-30-60 minute intervals. We also considered how this format could also be translated into a webpage display.  

![Sketch 5](Images/Clock%20Images/IMAGE_5.jpg)

	Design sketch for the clock on a webpage, or tablet. Since we wanted the data available on different formats, we started to consider how we could scale different designs together. 


This device would in a sense act as an notifier to be coupled alongside the more detail-specific web server, and is designed to be more attention drawing. This was prototyped initially in lo-fidelity using card and coloured paper to simulate time segments, allowing us to explore how frequently data would be output to the clock. Through this prototyping phase, we began to develop our colour spectrum, and specifically how attention can be drawn to noisier time periods. As well as this, we considered whether updates would be formatted as 5/30/60 minute chunks, and how this could be replicated in hardware. 


####Outcome of Iteration
We have produced several different design proposals for the clock, and have began to consider how a physical device could be produced. We have evaluated what benefits the clock can bring to the project, in that it reinforces the more accurate data and makes for an engaging notifier for the user. There is also potential for this to create data continuity - in the sense that data from a physical device can be cross referenced with that on the web server. Overall, this iteration has set up the requirements for the clock, and given us a few interesting paths to take when developing it. 

####Iteration 2: Hardware and setup phase

After having collected our ideas from lo-fi prototyping, we are now exploring how our clock system can be physically implemented with hardware. 
The last iteration saw us investigating some requirements regarding the clock’s transition into hardware. This iteration involves our research into hardware, and comparisons between methods of implementing the system. 

#####Adafruit NeoPixel Ring

![clock models](Images/Clock%20Images/clock_models.png)

	Hardware models for the Adafruit NeoPixel Ring. Above, from left to right are the 24, 16 and 12 LED models. During the project we considered using various sizes, ultimately deciding upon the 24 x WS2812 (left). 

We were directed towards the tech solutions offered by Adafruit (https://www.adafruit.com) which distributes the NeoPixel product; an assortment of addressable miniature LEDs arranged in rings, strips and boards (https://www.adafruit.com/category/168). We feel that this is a good platform for developing our system in hardware.
The Adafruit NeoPixel device is a chainable collection of LEDs which can be interfaced with the NeoPixel Arduino library for support. Example code provided with the library demonstrated several of the device’s capabilities; notably the ability to manipulate timings of individual lights to come on. Conveniently, this was exactly what we were looking for as it provided a loose way of interfacing more complex tasks if we needed to. 

The setup of this device requires the use of a breadboard to interface the NeoPixel ring with an Arduino Uno microcontroller, and the use of a PC to upload code from the Arduino libraries to the Uno. After setup, our first concern was to establish the range of colours we could use to recreate our “ambience” colour spectrum.

We then displayed a spectrum of our proposed colours running from white (least ambient) through green, yellow, and orange to red (most ambient) recreating this colour wheel using the addressable LEDs. 

####Display Model
During our concepting of the clock display, we came up with several different possibilities of data accuracy that we could 
use. The main two directions for this were inspired by the 24 and 60 LED NeoPixel models respectively. 

#####24-Hour Display
The go-to approach that we looked into involved the 24-hour display clock, which averaged data over hourly periods, potentially transitioning to sleep mode between readings to save power. Adafruit’s solution to this offered an LED ring of 2.6” diameter; which is a relatively small display and could be mounted onto a small case or hub and unhooked for inspection. Early low fidelity prototypes of casing for this were modelled using cardboard, with emphasis being placed on the majority of the face being easily visible.  

#####Hour-By-Hour Display
There are also considerations to use other models of NeoPixel Ring. Of note is the NeoPixel Ring 60 x WS2812 model which offered 60 addressable LEDs; with which we can update more frequently to give an hour-by-hour display. A light would come on every minute after the averaged sample data was sent to the device until all 60 were lit; at which point it would rollover 
for the next hour. 

This idea could be combined with an LCD real time digital clock to keep track of which hour the data was referring to. This kind of display could also be interfaced with the clock itself to serve as the rollover point to be synched with the pixel 
reset at each hour. 

####NeoPixel Library and Code Iterations
After having chosen the NeoPixel 24 LED model, we have began to interface with the Arduino library to build a test program. 
From our test program, we intend to evaluate the capabilities of the NeoPixel Ring, and determine whether it could be used for our clock system. 

So far, we have found we can address individual LEDs and their brightnesses, and manipulate timings that certain lights come on. We are also looking into how we could implement our colour spectrum into the system, including the range of colours the hardware offers us. 

We knew the device would somehow have to read in data from our system. Writing a couple of test programs explained below, we require a data reading component to read in decibel values and convert them to a corresponding light
Reading clock data from a file
Initially, we constructed a program using the “Processing” IDE to work as a simple file reader which transmitted data via serial. Interfacing this with the microcontroller, a set of arbitrary values ranging from 0-9 were read into a switch statement on the arduino; 0 representing low ambience with a white light, and red expressing high ambience upwards towards 9.

![Neopixel Ring](Images/Clock%20Images/IMAGE_7.jpg)

	Adafruit NeoPixel Ring 24 x WS2812. Here the ring is powered by an Arduino Uno, and displaying a range of colours. The rings comes with adjustable brightness settings, and each LED is individually addressable. 

The code for this iteration can be found here: [Clock_Cycle_V1b]

#####Reading clock data from a pre-programmed array

Since the clock will be working with real values, we investigated the ways that we could test it without interaction of the real system. This would involve using dummy values, and setting 
A separate program we developed involved reading in dummy values from a pre-programmed array. The program would iterate through a size 24 integer array (consisting of integers from 0-100), and transfer data to a corresponding colour scale in the “setHourColour()” method. To fall within the case statements 0-10, each value was divided by 10 so that it would match a corresponding statement. The index positions of the array, which ranged from 0-23, matched each “hour” that the clock was displaying data for. This way, the clock display was to start from midnight, and iterate round to 11pm providing data coverage for all hours in between. 

The code for this iteration can be found here: [Clock_Cycle_V1b]

![setHourColour Code check](Images/Clock%20Images/IMAGE_8.png)

	Arduino code for “setHourColour()”. If the value exceeded -1 (which was always true unless an error case occurred - see below) then it gets divided by 10 to match the case statement. 

![Dummy code](Images/Clock%20Images/IMAGE_9.png)

	Arduino code for displaying “dummy” data lights. The loop() method simply iterates through the array of dummy values called “clockValues[]”, takes each individual value and converts it to a colour based upon which case it falls into. 

This simple setup will be the basis of a more complicated program, which will involve reading data in over serial, averaging values across an hour’s worth of data and turning on a light. This method of doing things was relatively straightforward to implement once we knew what form the data being transferred to the clock was in.    

For our data to be accurately represented, we had to somehow establish the colour spectrum which we developed in the initial design phase of the clock. Having looked into the NeoPixel library, the main method for handling the colour of individual LEDs was the “setPixelColor()” method, which took 4 parameters. Firstly, the position of the pixel you are addressing, and then RGB values for the colour. 
We determined our RGB parameters by using a HTML colour picker, which allowed us to pick and particular colour and read off the values. Using this, we established each of different parameters corresponding to the colours in our spectrum.  

![Colour picker](Images/Clock%20Images/IMAGE_10.png)

	We chose the colours using a HTML colour picker. Since the NeoPixel Ring method, “setPixelColor” requires RGB values for arguments, we determined which colour values to use based off of this website. (http://www.w3schools.com/colors/colors_picker.asp) 

####Simplifying the colour spectrum

Initially, we found the parameters for 10 different colours which would be used in progressively more intense hues. We will potentially reduce this to 6 different colours which provided the clock with better granularity. 

![Colour Spectrum 1](Images/Clock%20Images/Colour_spec_comparison.png)

	Simplified colour spectrum. Going in a clockwise 
	direction, the colour converges more towards red, 	hinting at greater noise activity. The right image 	is displaying data for arbitrary values to test the 	granularity between colours.

The code for this iteration can be found here: [Clock_Cycle_V1b]

#####Colour-blindness spectrum 

There is an issue with using purely colour based visualisation. When catering for users who might have trouble distinguishing between colours, there is particular difficulty with telling the difference between green and red. Since our spectrum uses this two values as lower and upper bounds, it would be particularly problematic if the user couldn’t tell them apart. 

A method we could use is an intensity spectrum. Choosing one particular colour, the noise intensity would instead be represented by the intensity of each colour shade. For example, with red, quieter hours would be represented with very pale shades, and louder hours by more intense shades. 

![Colour intensity 1](Images/Clock%20Images/Intensity_spec_comparison.png)
		
	NeoPixel Ring displaying the intensity spectrum. 

#####Colour intensity spectrum. 

Similarly to the colour spectrum, the intensity increases as greater noise intensity values are read in. We have opted for red here, but it can be implemented in any colour.

We felt having the option to display data in these varying formats could be useful to the user, and opens up possibilities for new ways our visualisation could be implemented. There are potentially ways that these two formats could be used in conjunction.

The code for this iteration can be found here: [Clock_Cycle_RedIntensity]

####Problems

We faced some issues in this iteration based upon our hardware choices. Although only used for prototyping, the Arduino Uno board has a lot of functionality which the clock doesn’t require, when ideally we want to condense down and use something simpler. Furthermore, dimensions wise the Uno is quite bulky - which may present further issues concerning the casing of the clock. Another problem concerned the starting point of the first LED that is lit. Since the NeoPixel Ring LEDs are addressed by the arduino code using integer index position, the starting LED, which remains fixed at 0, has been a current issue to change. If we can’t change the starting position, there could be potential problems regarding the orientation of the clock. For example, would we have to always have the clock at a fixed orientation? What would happen if it had to be rotated somehow? 

####Outcome of iteration
After this iteration was completed, we had managed to set up the NeoPixel ring to display some spoofed data values. This is promising as far as the full implementation of the clock goes, as we can now use this data format for structuring communications between the clock and other devices. Furthermore, we have decided upon a direction to take the hardware choices. Currently the clock is running off of an Arduino Uno as the NeoPixel ring is supported by Arduino code, but since it won’t be battery dependent, there is room for other microcontrollers to be considered. Also, this iteration has provided some interesting issues for us to consider; which we intend to solve in future iterations. 

####Iteration 3: Interlinking phase

####Adafruit Flora
To alleviate the issue of the Arduino Uno, we decided to change our board choice to the Adafruit Flora; a much more compact device. This significantly reduces the dimensions of the clock components, leading to a much more streamlined layout. This changeover will be particularly important for when we consider case design; during which a more condensed layout will be favoured. Furthermore, the Flora offers us the same functionality required of the Arduino Uno, minus the unnecessary features. 

####Interfacing with XBee and Networking
After we had successfully set the NeoPixel ring up to display some dummy values, and having decided upon a colour spectrum in our last iteration, our next task is to integrate the clock with the rest of the network.

The networking involved hooking up the XBee device to the Adafruit Flora microcontroller using the RX and TX ports, allowing the two devices to communicate over serial. The XBee was attached to an Lilypad board at this point, allowing for easy interfacing with the microcontroller. This was simply to keep the XBee in place. 

![Systems communication](Images/Clock%20Images/IMAGE_15.jpg)

	Hardware setup for clock. Above is the clock interfaced with the Adafruit Flora microcontroller, which, in turn is interfaced with the lilypad board.  

####Networking with the clock

To establish the clock device communicating over a network, we are going to start by writing simple sender-receiver code. This will be uploaded to the clock and a separate microcontroller - both of which will be  interfaced with XBees, so that messages can be sent back and forth between them. This is intended to simulate how clock would communicate with the hub, and pick up on any errors in transition that we may encounter. This will utilise a simple acknowledgement based format, which we could potentially use as foundation for how the clock requests hub data on the hour.

This sender-receiver code will then be implemented into the clock’s real interaction with the hub. The clock will send a request (formatted as “R:!”) which will then be accepted by the hub. The hub  then sends the data over in an integer array - which will be used to populate the clock’s “clockValues[]” array for storing data. 

The code for this iteration can be found here: [Receiver_Code]

![Systems communication](Images/Clock%20Images/IMAGE_16.jpg)

	Communication between the clock,  hub and web server. Once data from the web server has been sent to the clock, the clockValues[] array is populated with the values. 

![Clock hub communication](Images/Clock%20Images/IMAGE_17.png) - 
	
	Arduino code for the prototype clock-hub communication. This involved us establishing serial connections to the XBee device, and reading in values that were received from the sending XBee interfaced with the hub. The hub was simply configured to send the same pre-programmed array values over the network.

####Signposting with the clock
The clock, being a very visual component in the system, should implement some form of user signposting. Before the data display phase begins, we discussed adding a few intermediary stages to show the clock transitioning between states - if for some reason it has trouble reaching the data. 
IMAGE 18 - Clock display. This shows the clock reading in a value every minute from the hub, and plotting it as a light. The architecture pictured shows the NeoPixel ring, Adafruit Flora, and Lilypad interfaced together. 

![signposting flowchart](Images/Clock%20Images/IMAGE_19.png)

	Signposting flowchart. This chart shows that for every reading the clock takes on the hour, it runs the initialisation phase, and moves through the different signposts according to the state. 

We then planned what sort of signposting we might implement. This chart shows that for every reading the clock takes on the hour, it runs the initialisation phase. This phase consists of white lights circling round. After this, if data reading is successful, the first light is plotted. For subsequent readings, the appropriate states are reflected in the clock’s display. Before we implemented signposting, if there were errors in transmission of data, or communication to the hub, the clock would freeze its current display -  instead of reflect the nature of the problem. 

![Arduino error cases](Images/Clock%20Images/IMAGE_20.png)

	Arduino code for “error cases”. Here we introduced the specific cases which might occur. The comments clearly describe which case applies to which scenario. 

Once the modified case statement was developed, we tested the clock in isolation with specific error values, and observed the light output. This was to ensure that the signposting was effective, and clearly conveyed different messages. 

![case 1](Images/Clock%20Images/IMAGE_21.jpg)

	Display for error case 1. The clock outputs a white display of lights and holds it there for a few seconds. 

![case 2](Images/Clock%20Images/IMAGE_22.jpg)

	Display for error case 2 - if the hub cannot be reached. The clock outputs a red “colour wheel” of light to indicate that there is an error. 

![case 3](Images/Clock%20Images/IMAGE_23.jpg)
	
	Display for error case 3 - if the hub cannot be reach the server. The clock outputs a blue “colour wheel” of light to indicate that there is a problem.

The above cases show the clock displaying errors whilst working with dummy values, so our next stage is to make it work with the hub. This is fairly straightforward - we just have to send dummy data packets from the hub over to the clock over the Zigbee network to test it.

The code for this iteration can be found here: [Clock_Cycle_V1b] 

At this point, much of the clock’s functionality is working as intended. So far, we have tested the clock in isolation, and simulated its interactions with the hub device. We have also established a communication platform from our sender-receiver code, which we will adapt to integrate the clock into the system. 

The code for this iteration can be found here: [Clock_Cycle_V1]

####Integrating the clock with the whole system

Now that we have developed the main functionality of the clock, we have to integrate it with the rest of the system. To do this, we must carefully optimise a few of the clock’s features - such as wait times in between reading values; in order to synchronise it with other system events such as the sensor reading in data, or the hub communicating with the web server. This process involves refactoring some of the arduino code for efficiency reasons, and beginning to consider how we could use protective casing when it came to deploying the clock. 

Since the data format for the clock has already been decided upon, the integration of it into the system is more a matter for the other components. Here, there were discussions about how the web server could send packets tailored specifically for the clock via serial, whilst maintaining the format that the clock expects.

The first integration step was to adjust delay times: 

![delay code](Images/Clock%20Images/IMAGE_24.png)

	Arduino code for delays. The variables represent different lengths of time that we could delay the clock for between reading values, as determined by the number of miliseconds. 

The clock is designed to display average readings on an hourly basis. For the sake of testing its functionality over a shorter timescale, we are running the clock in shorter iterations; e.g. minute by minute displays (for a total of 24 minutes) and second by second delays (24 seconds). This reduced time whilst testing, and saved having to wait 24 hours just to see the output of a day’s data. 

There are currently further plans to test the clock over an extended time period, once it has been fully integrated with the whole system.

The code for this iteration can be found here: [Clock_Cycle_V2]

####Previous Problems

<ul>
<li> Arduino Uno board has a lot of functionality which the clock doesn’t require, when ideally we want to condense down and use something simpler. </li>
<li> Starting point of the first LED that is lit. Since the NeoPixel Ring LEDs are addressed by the arduino code using integer index position, the starting LED, which remains fixed at 0, has been a current issue to change. </li>
<li> Lack of error displays if e.g. the clock can’t communicate with the hub, data can’t be transmitted etc.</li>
</ul>

Early in this iteration, we moved from our choice of board for prototyping; the Arduino Uno, over to a more concrete choice. The Adafruit Flora currently fits our needs for a stable, yet compact board, and has the added bonus of fitting inside the NeoPixel Ring. The Flora is compatible with our previous Arduino code, and has exactly the ports we need for interfacing with the NeoPixel Ring. This makes it a more efficient, and aesthetically suitable choice for the clock. 

We resolved the issue of the starting point by making a very simple adjustment to our code. For any iterative structures looping over the LEDs, rather than starting at position 0 (the first LED), we simply offset that number by an amount depending upon where we wish to start (- e.g. + 3 if we wanted to start from the third LED going clockwise), storing that in the “startpos” variable. When it came to iterating from this new start position, we iterated over the LEDs as normal, calculating the shift in LED indexes. (see code below).

To add a degree of error displays, we added a new light system for the clock to provide signposting. These operated similarly to other devices which use warning lights, and intended to direct user attention based on colour. 


![case 1](Images/Clock%20Images/IMAGE_25.png)

	LED index changes


####Current Problems

During this iteration, some of the main challenges concerned setting up the clock on the network, and maintaining the format of the data it received so as to not trigger errors. The clock uses a very specific format in which it expects data, so a particular challenge has been in normalising the structure of packets to match this expectation. Fortunately, however, if there are genuine issues regarding the web server’s connection to the hub, or the hub’s communication with the clock, we have established signposting to inform the user. 

####Outcome of iteration

After this iteration was completed, we had managed to set up the NeoPixel ring to display some pre-calculated data values. This is promising as far as the full implementation of the clock goes, as we can now use this data format for structuring communications between the clock and other devices. Furthermore, we have decided upon a direction to take the hardware choices. Currently the clock is running off of an Arduino Uno as the NeoPixel ring is supported by Arduino code, but since it won’t be battery dependent, there is room for other microcontrollers to be considered. Also, this iteration has provided some interesting issues for us to consider; which we intend to solve in future iterations.

####Iteration 4: Casing and finalisation phase

In the previous the functionality of the clock was integrated with the rest of the system in the previous iteration, 
Since the NeoPixel ring by itself is quite a fragile piece of hardware, it is necessary to build some form of casing to protect it whilst still maintaining its visibility. We came up with a few ideas for this using cardboard to easily mould shapes together; most of the principle designs consisting of a base and a clear perspex glass “face”, to protect the components. 

We also looked into how the device could be mounted, since ideally our focus was on its attention drawing aspect which would be less effective if it had to be picked up or consciously interacted with. This could be achieved with a clip or some form of hook for a wall mount possibility, or perhaps a subtle stand so as to not rely too much on modifying a client’s home to accommodate for it. 

####Designing the case

When it came to designing the case to house the clock, we have several things to bear in mind: 
<ul>
<li> It has to be robust enough to protect the hardware</li>
<li> Easy to mount and/or stand up</li>
<li> Of reasonable size</li> 
<li> Good visibility of the clock display</li>
<li> Feasible to manufacture/3D print</li>
</ul>
With these points, we set about producing some design mockups using google sketchup. Since we weren’t looking at modelling straight away, it was good to use this program to conceptualise some of properties of its general appearance.

#####Iteration 1


![Design 1 a](Images/Clock%20Images/IMAGE_26.jpg) ![Design 1 b](Images/Clock%20Images/IMAGE_27.jpg)

	Sketchup designs of first prototypes. The general shape of the case is established here. The isometric view on the left shows the layers where the NeoPixel Ring could sit.

In this iteration we designed the general shape of the case, and considered a transparent perspex “face” to promote the visibility of the lights. It was designed so the NeoPixel Ring would fit securely around the inner ring, with a space in the middle for the Flora to sit. The purpose of the base here is twofold. Whilst it doesn’t yet stand up, the base holds the components for the XBee module, and features a detachable back.  

#####Iteration 2

![Design 2 a](Images/Clock%20Images/IMAGE_28.jpg) ![Design 2 b](Images/Clock%20Images/IMAGE_29.jpg)

	Iteration 2. Here we began to establish how the case could use a stand to support the clock, and make the viewing angle easier. 

This iteration features our first implementation of a stand. This is important to the evolution of the clock, as it greatly increases visibility of the lights, and therefore aids the user’s engagement with it. The stand here is fairly small, so in future design iterations we will have to consider making more robust changes.

#####Iteration 3

![Design 3 a](Images/Clock%20Images/IMAGE_30.jpg) ![Design 3 b](Images/Clock%20Images/IMAGE_31.jpg)

	Iteration 3. This design uses a pull out stand which would potentially provide greater stability than the stand in the previous iteration. This would also be a useful feature for wall mounting the clock. 

This iteration implements a more sturdy stand to keep the clock upright. We were considering having a flip out stand, which can be put away based on user preference. Besides that, much of the general design is the same. 

#####Final iteration

We finalised our case design to have a more sturdy base and used the 3D printer to construct it. The final case consisted of three major 3D printed parts which slotted together. For more information, see casing. 

####Previous Problems
Setting up the clock on the network, and maintaining the format of the data it received so as to not trigger errors. 

We solved this issue this iteration by incorporating a strict data format that the clock received values in. This was an integer array of 24 values, containing sound averages for each hour of the day. This format was utilised by the hub; meaning that when sending data, the clock received it in a format it “understood”. 

####Outcome of iteration
At the end of this iteration, we had successfully developed a case for the clock; precisely matching its dimensions and storing all the necessary components. 




